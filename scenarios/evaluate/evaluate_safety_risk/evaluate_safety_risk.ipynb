{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Risk and Safety - Protected Material and Indirect Attack Jailbreak\n",
    "\n",
    "## Objective\n",
    "This notebook walks through how to generate a simulated conversation targeting a deployed AzureOpenAI model and then evaluate that conversation test dataset for Protected Material and Indirect Attack Jailbreak (also know as XPIA or cross-domain prompt injected attack) vulnerability. It also references Azure AI Content Safety service's prompt filtering capabilities to help identify and mitigate these vulnerabilities in your AI system.\n",
    "\n",
    "## Time\n",
    "You should expect to spend about 30 minutes running this notebook. If you increase or decrease the number of simulated conversations, the time will vary accordingly.\n",
    "\n",
    "## Before you begin\n",
    "\n",
    "### Installation\n",
    "Install the following packages required to execute this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: openai in c:\\azureai-samples\\venv3\\lib\\site-packages (1.50.2)\n",
      "Requirement already satisfied: azure-ai-evaluation in c:\\azureai-samples\\venv3\\lib\\site-packages (1.0.0b2)\n",
      "Requirement already satisfied: azure-identity in c:\\azureai-samples\\venv3\\lib\\site-packages (1.18.0)\n",
      "Collecting promptflow-azure\n",
      "  Downloading promptflow_azure-1.16.0-py3-none-any.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\azureai-samples\\venv3\\lib\\site-packages (from openai) (4.6.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\azureai-samples\\venv3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\azureai-samples\\venv3\\lib\\site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\azureai-samples\\venv3\\lib\\site-packages (from openai) (0.5.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\azureai-samples\\venv3\\lib\\site-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in c:\\azureai-samples\\venv3\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\azureai-samples\\venv3\\lib\\site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\azureai-samples\\venv3\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: promptflow-devkit>=1.15.0 in c:\\azureai-samples\\venv3\\lib\\site-packages (from azure-ai-evaluation) (1.16.0)\n",
      "Requirement already satisfied: promptflow-core>=1.15.0 in c:\\azureai-samples\\venv3\\lib\\site-packages (from azure-ai-evaluation) (1.16.0)\n",
      "Requirement already satisfied: pyjwt>=2.8.0 in c:\\azureai-samples\\venv3\\lib\\site-packages (from azure-ai-evaluation) (2.9.0)\n",
      "Requirement already satisfied: azure-core>=1.30.2 in c:\\azureai-samples\\venv3\\lib\\site-packages (from azure-ai-evaluation) (1.31.0)\n",
      "Requirement already satisfied: nltk>=3.9.1 in c:\\azureai-samples\\venv3\\lib\\site-packages (from azure-ai-evaluation) (3.9.1)\n",
      "Requirement already satisfied: rouge-score>=0.1.2 in c:\\azureai-samples\\venv3\\lib\\site-packages (from azure-ai-evaluation) (0.1.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\azureai-samples\\venv3\\lib\\site-packages (from azure-ai-evaluation) (2.1.1)\n",
      "Requirement already satisfied: cryptography>=2.5 in c:\\azureai-samples\\venv3\\lib\\site-packages (from azure-identity) (43.0.1)\n",
      "Requirement already satisfied: msal>=1.30.0 in c:\\azureai-samples\\venv3\\lib\\site-packages (from azure-identity) (1.31.0)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in c:\\azureai-samples\\venv3\\lib\\site-packages (from azure-identity) (1.2.0)\n",
      "Collecting azure-ai-ml<2.0.0,>=1.14.0 (from promptflow-azure)\n",
      "  Downloading azure_ai_ml-1.20.0-py3-none-any.whl.metadata (32 kB)\n",
      "Collecting azure-cosmos<5.0.0,>=4.5.1 (from promptflow-azure)\n",
      "  Downloading azure_cosmos-4.7.0-py3-none-any.whl.metadata (70 kB)\n",
      "     ---------------------------------------- 0.0/70.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 70.3/70.3 kB 1.9 MB/s eta 0:00:00\n",
      "Collecting azure-storage-blob<13.0.0,>=12.17.0 (from azure-storage-blob[aio]<13.0.0,>=12.17.0->promptflow-azure)\n",
      "  Downloading azure_storage_blob-12.23.1-py3-none-any.whl.metadata (26 kB)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\azureai-samples\\venv3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: pyyaml>=5.1.0 in c:\\azureai-samples\\venv3\\lib\\site-packages (from azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure) (6.0.2)\n",
      "Requirement already satisfied: msrest>=0.6.18 in c:\\azureai-samples\\venv3\\lib\\site-packages (from azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure) (0.7.1)\n",
      "Collecting azure-mgmt-core>=1.3.0 (from azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure)\n",
      "  Downloading azure_mgmt_core-1.4.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: marshmallow>=3.5 in c:\\azureai-samples\\venv3\\lib\\site-packages (from azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure) (3.22.0)\n",
      "Requirement already satisfied: jsonschema>=4.0.0 in c:\\azureai-samples\\venv3\\lib\\site-packages (from azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure) (4.23.0)\n",
      "Requirement already satisfied: strictyaml in c:\\azureai-samples\\venv3\\lib\\site-packages (from azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure) (1.7.3)\n",
      "Requirement already satisfied: colorama in c:\\azureai-samples\\venv3\\lib\\site-packages (from azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure) (0.4.6)\n",
      "Collecting azure-storage-file-share (from azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure)\n",
      "  Downloading azure_storage_file_share-12.18.0-py3-none-any.whl.metadata (48 kB)\n",
      "     ---------------------------------------- 0.0/48.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 48.2/48.2 kB ? eta 0:00:00\n",
      "Collecting azure-storage-file-datalake>=12.2.0 (from azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure)\n",
      "  Downloading azure_storage_file_datalake-12.17.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: pydash>=6.0.0 in c:\\azureai-samples\\venv3\\lib\\site-packages (from azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure) (7.0.7)\n",
      "Requirement already satisfied: isodate in c:\\azureai-samples\\venv3\\lib\\site-packages (from azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure) (0.6.1)\n",
      "Collecting azure-common>=1.1 (from azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure)\n",
      "  Downloading azure_common-1.1.28-py2.py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting opencensus-ext-azure (from azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure)\n",
      "  Downloading opencensus_ext_azure-1.1.13-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Collecting opencensus-ext-logging (from azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure)\n",
      "  Downloading opencensus_ext_logging-0.1.1-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: requests>=2.21.0 in c:\\azureai-samples\\venv3\\lib\\site-packages (from azure-core>=1.30.2->azure-ai-evaluation) (2.32.3)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\azureai-samples\\venv3\\lib\\site-packages (from azure-core>=1.30.2->azure-ai-evaluation) (1.16.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\azureai-samples\\venv3\\lib\\site-packages (from cryptography>=2.5->azure-identity) (1.17.1)\n",
      "Requirement already satisfied: certifi in c:\\azureai-samples\\venv3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\azureai-samples\\venv3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\azureai-samples\\venv3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: portalocker<3,>=1.4 in c:\\azureai-samples\\venv3\\lib\\site-packages (from msal-extensions>=1.2.0->azure-identity) (2.10.1)\n",
      "Requirement already satisfied: click in c:\\azureai-samples\\venv3\\lib\\site-packages (from nltk>=3.9.1->azure-ai-evaluation) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\azureai-samples\\venv3\\lib\\site-packages (from nltk>=3.9.1->azure-ai-evaluation) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\azureai-samples\\venv3\\lib\\site-packages (from nltk>=3.9.1->azure-ai-evaluation) (2024.9.11)\n",
      "Requirement already satisfied: docstring_parser in c:\\azureai-samples\\venv3\\lib\\site-packages (from promptflow-core>=1.15.0->azure-ai-evaluation) (0.16)\n",
      "Requirement already satisfied: fastapi<1.0.0,>=0.109.0 in c:\\azureai-samples\\venv3\\lib\\site-packages (from promptflow-core>=1.15.0->azure-ai-evaluation) (0.115.0)\n",
      "Requirement already satisfied: filetype>=1.2.0 in c:\\azureai-samples\\venv3\\lib\\site-packages (from promptflow-core>=1.15.0->azure-ai-evaluation) (1.2.0)\n",
      "Requirement already satisfied: flask<4.0.0,>=2.2.3 in c:\\azureai-samples\\venv3\\lib\\site-packages (from promptflow-core>=1.15.0->azure-ai-evaluation) (3.0.3)\n",
      "Requirement already satisfied: promptflow-tracing==1.16.0 in c:\\azureai-samples\\venv3\\lib\\site-packages (from promptflow-core>=1.15.0->azure-ai-evaluation) (1.16.0)\n",
      "Requirement already satisfied: psutil in c:\\azureai-samples\\venv3\\lib\\site-packages (from promptflow-core>=1.15.0->azure-ai-evaluation) (5.9.8)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1.0 in c:\\azureai-samples\\venv3\\lib\\site-packages (from promptflow-core>=1.15.0->azure-ai-evaluation) (2.9.0.post0)\n",
      "Requirement already satisfied: ruamel.yaml<1.0.0,>=0.17.10 in c:\\azureai-samples\\venv3\\lib\\site-packages (from promptflow-core>=1.15.0->azure-ai-evaluation) (0.18.6)\n",
      "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.22.0 in c:\\azureai-samples\\venv3\\lib\\site-packages (from promptflow-tracing==1.16.0->promptflow-core>=1.15.0->azure-ai-evaluation) (1.27.0)\n",
      "Requirement already satisfied: tiktoken>=0.4.0 in c:\\azureai-samples\\venv3\\lib\\site-packages (from promptflow-tracing==1.16.0->promptflow-core>=1.15.0->azure-ai-evaluation) (0.7.0)\n",
      "Requirement already satisfied: argcomplete>=3.2.3 in c:\\azureai-samples\\venv3\\lib\\site-packages (from promptflow-devkit>=1.15.0->azure-ai-evaluation) (3.5.0)\n",
      "Requirement already satisfied: azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21 in c:\\azureai-samples\\venv3\\lib\\site-packages (from promptflow-devkit>=1.15.0->azure-ai-evaluation) (1.0.0b30)\n",
      "Requirement already satisfied: filelock<4.0.0,>=3.4.0 in c:\\azureai-samples\\venv3\\lib\\site-packages (from promptflow-devkit>=1.15.0->azure-ai-evaluation) (3.16.1)\n",
      "Requirement already satisfied: flask-cors<5.0.0,>=4.0.0 in c:\\azureai-samples\\venv3\\lib\\site-packages (from promptflow-devkit>=1.15.0->azure-ai-evaluation) (4.0.2)\n",
      "Requirement already satisfied: flask-restx<2.0.0,>=1.2.0 in c:\\azureai-samples\\venv3\\lib\\site-packages (from promptflow-devkit>=1.15.0->azure-ai-evaluation) (1.3.0)\n",
      "Requirement already satisfied: gitpython<4.0.0,>=3.1.24 in c:\\azureai-samples\\venv3\\lib\\site-packages (from promptflow-devkit>=1.15.0->azure-ai-evaluation) (3.1.43)\n",
      "Requirement already satisfied: keyring<25.0.0,>=24.2.0 in c:\\azureai-samples\\venv3\\lib\\site-packages (from promptflow-devkit>=1.15.0->azure-ai-evaluation) (24.3.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0 in c:\\azureai-samples\\venv3\\lib\\site-packages (from promptflow-devkit>=1.15.0->azure-ai-evaluation) (1.27.0)\n",
      "Requirement already satisfied: pandas<3.0.0,>=1.5.3 in c:\\azureai-samples\\venv3\\lib\\site-packages (from promptflow-devkit>=1.15.0->azure-ai-evaluation) (2.2.3)\n",
      "Requirement already satisfied: pillow<11.0.0,>=10.1.0 in c:\\azureai-samples\\venv3\\lib\\site-packages (from promptflow-devkit>=1.15.0->azure-ai-evaluation) (10.4.0)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in c:\\azureai-samples\\venv3\\lib\\site-packages (from promptflow-devkit>=1.15.0->azure-ai-evaluation) (1.0.1)\n",
      "Requirement already satisfied: pywin32 in c:\\azureai-samples\\venv3\\lib\\site-packages (from promptflow-devkit>=1.15.0->azure-ai-evaluation) (306)\n",
      "Requirement already satisfied: sqlalchemy<3.0.0,>=1.4.48 in c:\\azureai-samples\\venv3\\lib\\site-packages (from promptflow-devkit>=1.15.0->azure-ai-evaluation) (2.0.35)\n",
      "Requirement already satisfied: tabulate<1.0.0,>=0.9.0 in c:\\azureai-samples\\venv3\\lib\\site-packages (from promptflow-devkit>=1.15.0->azure-ai-evaluation) (0.9.0)\n",
      "Requirement already satisfied: waitress<3.0.0,>=2.1.2 in c:\\azureai-samples\\venv3\\lib\\site-packages (from promptflow-devkit>=1.15.0->azure-ai-evaluation) (2.1.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\azureai-samples\\venv3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\azureai-samples\\venv3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "Requirement already satisfied: absl-py in c:\\azureai-samples\\venv3\\lib\\site-packages (from rouge-score>=0.1.2->azure-ai-evaluation) (2.1.0)\n",
      "Collecting aiohttp>=3.0 (from azure-core[aio]>=1.30.0; extra == \"aio\"->azure-storage-blob[aio]<13.0.0,>=12.17.0->promptflow-azure)\n",
      "  Downloading aiohttp-3.10.8-cp311-cp311-win_amd64.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: fixedint==0.1.6 in c:\\azureai-samples\\venv3\\lib\\site-packages (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit>=1.15.0->azure-ai-evaluation) (0.1.6)\n",
      "Requirement already satisfied: opentelemetry-api~=1.26 in c:\\azureai-samples\\venv3\\lib\\site-packages (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit>=1.15.0->azure-ai-evaluation) (1.27.0)\n",
      "Requirement already satisfied: pycparser in c:\\azureai-samples\\venv3\\lib\\site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity) (2.22)\n",
      "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in c:\\azureai-samples\\venv3\\lib\\site-packages (from fastapi<1.0.0,>=0.109.0->promptflow-core>=1.15.0->azure-ai-evaluation) (0.38.6)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\azureai-samples\\venv3\\lib\\site-packages (from flask<4.0.0,>=2.2.3->promptflow-core>=1.15.0->azure-ai-evaluation) (3.0.4)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\azureai-samples\\venv3\\lib\\site-packages (from flask<4.0.0,>=2.2.3->promptflow-core>=1.15.0->azure-ai-evaluation) (3.1.4)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\azureai-samples\\venv3\\lib\\site-packages (from flask<4.0.0,>=2.2.3->promptflow-core>=1.15.0->azure-ai-evaluation) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\azureai-samples\\venv3\\lib\\site-packages (from flask<4.0.0,>=2.2.3->promptflow-core>=1.15.0->azure-ai-evaluation) (1.8.2)\n",
      "Requirement already satisfied: aniso8601>=0.82 in c:\\azureai-samples\\venv3\\lib\\site-packages (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit>=1.15.0->azure-ai-evaluation) (9.0.1)\n",
      "Requirement already satisfied: pytz in c:\\azureai-samples\\venv3\\lib\\site-packages (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit>=1.15.0->azure-ai-evaluation) (2024.2)\n",
      "Requirement already satisfied: importlib-resources in c:\\azureai-samples\\venv3\\lib\\site-packages (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit>=1.15.0->azure-ai-evaluation) (6.4.5)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\azureai-samples\\venv3\\lib\\site-packages (from gitpython<4.0.0,>=3.1.24->promptflow-devkit>=1.15.0->azure-ai-evaluation) (4.0.11)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\azureai-samples\\venv3\\lib\\site-packages (from jsonschema>=4.0.0->azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\azureai-samples\\venv3\\lib\\site-packages (from jsonschema>=4.0.0->azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\azureai-samples\\venv3\\lib\\site-packages (from jsonschema>=4.0.0->azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\azureai-samples\\venv3\\lib\\site-packages (from jsonschema>=4.0.0->azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure) (0.20.0)\n",
      "Requirement already satisfied: jaraco.classes in c:\\azureai-samples\\venv3\\lib\\site-packages (from keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.15.0->azure-ai-evaluation) (3.4.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.11.4 in c:\\azureai-samples\\venv3\\lib\\site-packages (from keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.15.0->azure-ai-evaluation) (8.4.0)\n",
      "Requirement already satisfied: pywin32-ctypes>=0.2.0 in c:\\azureai-samples\\venv3\\lib\\site-packages (from keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.15.0->azure-ai-evaluation) (0.2.3)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\azureai-samples\\venv3\\lib\\site-packages (from marshmallow>=3.5->azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure) (24.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in c:\\azureai-samples\\venv3\\lib\\site-packages (from msrest>=0.6.18->azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure) (2.0.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\azureai-samples\\venv3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.15.0->azure-ai-evaluation) (1.2.14)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\azureai-samples\\venv3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.15.0->azure-ai-evaluation) (1.65.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.27.0 in c:\\azureai-samples\\venv3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.15.0->azure-ai-evaluation) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.27.0 in c:\\azureai-samples\\venv3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.15.0->azure-ai-evaluation) (1.27.0)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.19 in c:\\azureai-samples\\venv3\\lib\\site-packages (from opentelemetry-proto==1.27.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.15.0->azure-ai-evaluation) (4.25.5)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\azureai-samples\\venv3\\lib\\site-packages (from pandas<3.0.0,>=1.5.3->promptflow-devkit>=1.15.0->azure-ai-evaluation) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\azureai-samples\\venv3\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.30.2->azure-ai-evaluation) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\azureai-samples\\venv3\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.30.2->azure-ai-evaluation) (2.2.3)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in c:\\azureai-samples\\venv3\\lib\\site-packages (from ruamel.yaml<1.0.0,>=0.17.10->promptflow-core>=1.15.0->azure-ai-evaluation) (0.2.8)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\azureai-samples\\venv3\\lib\\site-packages (from sqlalchemy<3.0.0,>=1.4.48->promptflow-devkit>=1.15.0->azure-ai-evaluation) (3.1.1)\n",
      "Collecting opencensus<1.0.0,>=0.11.4 (from opencensus-ext-azure->azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure)\n",
      "  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp>=3.0->azure-core[aio]>=1.30.0; extra == \"aio\"->azure-storage-blob[aio]<13.0.0,>=12.17.0->promptflow-azure)\n",
      "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp>=3.0->azure-core[aio]>=1.30.0; extra == \"aio\"->azure-storage-blob[aio]<13.0.0,>=12.17.0->promptflow-azure)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp>=3.0->azure-core[aio]>=1.30.0; extra == \"aio\"->azure-storage-blob[aio]<13.0.0,>=12.17.0->promptflow-azure)\n",
      "  Downloading frozenlist-1.4.1-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp>=3.0->azure-core[aio]>=1.30.0; extra == \"aio\"->azure-storage-blob[aio]<13.0.0,>=12.17.0->promptflow-azure)\n",
      "  Downloading multidict-6.1.0-cp311-cp311-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting yarl<2.0,>=1.12.0 (from aiohttp>=3.0->azure-core[aio]>=1.30.0; extra == \"aio\"->azure-storage-blob[aio]<13.0.0,>=12.17.0->promptflow-azure)\n",
      "  Downloading yarl-1.13.1-cp311-cp311-win_amd64.whl.metadata (52 kB)\n",
      "     ---------------------------------------- 0.0/52.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 52.5/52.5 kB ? eta 0:00:00\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\azureai-samples\\venv3\\lib\\site-packages (from deprecated>=1.2.6->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.15.0->azure-ai-evaluation) (1.16.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\azureai-samples\\venv3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython<4.0.0,>=3.1.24->promptflow-devkit>=1.15.0->azure-ai-evaluation) (5.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\azureai-samples\\venv3\\lib\\site-packages (from importlib-metadata>=4.11.4->keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.15.0->azure-ai-evaluation) (3.20.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\azureai-samples\\venv3\\lib\\site-packages (from Jinja2>=3.1.2->flask<4.0.0,>=2.2.3->promptflow-core>=1.15.0->azure-ai-evaluation) (2.1.5)\n",
      "Collecting opencensus-context>=0.1.3 (from opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure)\n",
      "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting google-api-core<3.0.0,>=1.0.0 (from opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure)\n",
      "  Downloading google_api_core-2.20.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.48b0 in c:\\azureai-samples\\venv3\\lib\\site-packages (from opentelemetry-sdk<2.0.0,>=1.22.0->promptflow-tracing==1.16.0->promptflow-core>=1.15.0->azure-ai-evaluation) (0.48b0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\azureai-samples\\venv3\\lib\\site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.18->azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure) (3.2.2)\n",
      "Requirement already satisfied: more-itertools in c:\\azureai-samples\\venv3\\lib\\site-packages (from jaraco.classes->keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.15.0->azure-ai-evaluation) (10.5.0)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure)\n",
      "  Downloading proto_plus-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-auth<3.0.dev0,>=2.14.1 (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure)\n",
      "  Downloading google_auth-2.35.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\azureai-samples\\venv3\\lib\\site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure) (5.5.0)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure)\n",
      "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure)\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml<2.0.0,>=1.14.0->promptflow-azure)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Downloading promptflow_azure-1.16.0-py3-none-any.whl (725 kB)\n",
      "   ---------------------------------------- 0.0/725.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 725.4/725.4 kB 23.1 MB/s eta 0:00:00\n",
      "Downloading azure_ai_ml-1.20.0-py3-none-any.whl (11.4 MB)\n",
      "   ---------------------------------------- 0.0/11.4 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 1.5/11.4 MB 46.9 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 2.9/11.4 MB 37.7 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 4.2/11.4 MB 33.8 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.7/11.4 MB 33.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.0/11.4 MB 32.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.5/11.4 MB 32.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.8/11.4 MB 31.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.2/11.4 MB 29.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.4/11.4 MB 29.7 MB/s eta 0:00:00\n",
      "Downloading azure_cosmos-4.7.0-py3-none-any.whl (252 kB)\n",
      "   ---------------------------------------- 0.0/252.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 252.1/252.1 kB ? eta 0:00:00\n",
      "Downloading azure_storage_blob-12.23.1-py3-none-any.whl (405 kB)\n",
      "   ---------------------------------------- 0.0/405.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 405.6/405.6 kB ? eta 0:00:00\n",
      "Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
      "Downloading azure_mgmt_core-1.4.0-py3-none-any.whl (27 kB)\n",
      "Downloading azure_storage_file_datalake-12.17.0-py3-none-any.whl (255 kB)\n",
      "   ---------------------------------------- 0.0/255.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 255.7/255.7 kB ? eta 0:00:00\n",
      "Downloading azure_storage_file_share-12.18.0-py3-none-any.whl (274 kB)\n",
      "   ---------------------------------------- 0.0/274.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 274.6/274.6 kB 17.6 MB/s eta 0:00:00\n",
      "Downloading opencensus_ext_azure-1.1.13-py2.py3-none-any.whl (43 kB)\n",
      "   ---------------------------------------- 0.0/43.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 43.4/43.4 kB ? eta 0:00:00\n",
      "Downloading opencensus_ext_logging-0.1.1-py2.py3-none-any.whl (4.0 kB)\n",
      "Downloading aiohttp-3.10.8-cp311-cp311-win_amd64.whl (381 kB)\n",
      "   ---------------------------------------- 0.0/381.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 381.4/381.4 kB 23.2 MB/s eta 0:00:00\n",
      "Downloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
      "   ---------------------------------------- 0.0/128.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 128.2/128.2 kB ? eta 0:00:00\n",
      "Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.4.1-cp311-cp311-win_amd64.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.5/50.5 kB ? eta 0:00:00\n",
      "Downloading google_api_core-2.20.0-py3-none-any.whl (142 kB)\n",
      "   ---------------------------------------- 0.0/142.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 142.2/142.2 kB ? eta 0:00:00\n",
      "Downloading multidict-6.1.0-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
      "Downloading yarl-1.13.1-cp311-cp311-win_amd64.whl (111 kB)\n",
      "   ---------------------------------------- 0.0/111.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 111.7/111.7 kB ? eta 0:00:00\n",
      "Downloading google_auth-2.35.0-py2.py3-none-any.whl (208 kB)\n",
      "   ---------------------------------------- 0.0/209.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 209.0/209.0 kB ? eta 0:00:00\n",
      "Downloading proto_plus-1.24.0-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.1/50.1 kB ? eta 0:00:00\n",
      "Downloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "   ---------------------------------------- 0.0/181.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 181.5/181.5 kB ? eta 0:00:00\n",
      "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "   ---------------------------------------- 0.0/83.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 83.1/83.1 kB ? eta 0:00:00\n",
      "Installing collected packages: opencensus-context, azure-common, pyasn1, proto-plus, multidict, frozenlist, aiohappyeyeballs, yarl, rsa, pyasn1-modules, aiosignal, google-auth, azure-storage-file-share, azure-storage-blob, azure-mgmt-core, azure-cosmos, aiohttp, google-api-core, azure-storage-file-datalake, opencensus, opencensus-ext-logging, opencensus-ext-azure, azure-ai-ml, promptflow-azure\n",
      "Successfully installed aiohappyeyeballs-2.4.3 aiohttp-3.10.8 aiosignal-1.3.1 azure-ai-ml-1.20.0 azure-common-1.1.28 azure-cosmos-4.7.0 azure-mgmt-core-1.4.0 azure-storage-blob-12.23.1 azure-storage-file-datalake-12.17.0 azure-storage-file-share-12.18.0 frozenlist-1.4.1 google-api-core-2.20.0 google-auth-2.35.0 multidict-6.1.0 opencensus-0.11.4 opencensus-context-0.1.3 opencensus-ext-azure-1.1.13 opencensus-ext-logging-0.1.1 promptflow-azure-1.16.0 proto-plus-1.24.0 pyasn1-0.6.1 pyasn1-modules-0.4.1 rsa-4.9 yarl-1.13.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install the packages\n",
    "%pip install openai azure-ai-evaluation azure-identity promptflow-azure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the following environment variables for use in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"AZURE_DEPLOYMENT_NAME\"] = \"gpt-4o-mini\"\n",
    "os.environ[\"AZURE_ENDPOINT\"] = \"https://ai-naarkalgaihub999971652049.openai.azure.com/\"\n",
    "os.environ[\"AZURE_API_VERSION\"] = \"2024-06-01\"\n",
    "os.environ[\"AZURE_API_KEY\"] = \"608401eb7ae84dc48cee0c735c9b7999\"\n",
    "os.environ[\"AZURE_SUBSCRIPTION_ID\"] = \"fac34303-435d-4486-8c3f-7094d82a0b60\"\n",
    "os.environ[\"AZURE_RESOURCE_GROUP\"] = \"rg-naarkalgaihub\"\n",
    "os.environ[\"AZURE_PROJECT_NAME\"] = \"naarkalg-rai-test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "The following simulator and evaluators require an Azure AI Studio project configuration and an Azure credential to use. \n",
    "Your project configuration will be what is used to log your evaluation results in your project after the evaluation run is finished.\n",
    "\n",
    "For this sample, we recommend creating or using a project in East US 2. For full region supportability, see [our documentation](https://learn.microsoft.com/azure/ai-studio/how-to/develop/flow-evaluate-sdk#built-in-evaluators)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.evaluation import evaluate\n",
    "from azure.ai.evaluation import ProtectedMaterialEvaluator, IndirectAttackEvaluator\n",
    "from azure.ai.evaluation.simulator import AdversarialSimulator, AdversarialScenario, IndirectAttackSimulator\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "\n",
    "azure_ai_project = {\n",
    "    \"subscription_id\": os.environ.get(\"AZURE_SUBSCRIPTION_ID\"),\n",
    "    \"resource_group_name\": os.environ.get(\"AZURE_RESOURCE_GROUP\"),\n",
    "    \"project_name\": os.environ.get(\"AZURE_PROJECT_NAME\"),\n",
    "}\n",
    "\n",
    "credential = DefaultAzureCredential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run this example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep this notebook lightweight, let's create a dummy application that calls GPT 3.5 Turbo, which is essentially Chat GPT. When we are testing your application for certain safety metrics like Protected Material or Indirect Attacks, it's important to have a way to automate a basic style of red-teaming to elicit behaviors from a simulated malicious user. We will use the `Simulator` class and this is how we will generate a synthetic test dataset against your application. Once we have the test dataset, we can evaluate them with our `ProtectedMaterialEvaluator` and `IndirectAttackEvaluator` classes.\n",
    "\n",
    "The `Simulator` needs a structured contract with your application in order to simulate conversations or other types of interactions with it. This is achieved via a callback function. This is the function you would rewrite to actually format the response from your generative AI application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Optional\n",
    "\n",
    "\n",
    "async def protected_material_callback(\n",
    "    messages: List[Dict], stream: bool = False, session_state: Optional[str] = None, context: Optional[Dict] = None\n",
    ") -> dict:\n",
    "    deployment = os.environ.get(\"AZURE_DEPLOYMENT_NAME\")\n",
    "    endpoint = os.environ.get(\"AZURE_ENDPOINT\")\n",
    "\n",
    "    # Get a client handle for the model\n",
    "    client = AzureOpenAI(\n",
    "        azure_endpoint=endpoint,\n",
    "        api_version=os.environ.get(\"AZURE_API_VERSION\"),\n",
    "        api_key=os.environ.get(\"AZURE_API_KEY\"),\n",
    "    )\n",
    "    # Call the model\n",
    "    completion = client.chat.completions.create(\n",
    "        model=deployment,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": messages[\"messages\"][0][\"content\"],  # injection of prompt happens here.\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=800,\n",
    "        temperature=0.7,\n",
    "        top_p=0.95,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None,\n",
    "        stream=False,\n",
    "    )\n",
    "\n",
    "    formatted_response = completion.to_dict()[\"choices\"][0][\"message\"]\n",
    "    messages[\"messages\"].append(formatted_response)\n",
    "    return {\n",
    "        \"messages\": messages[\"messages\"],\n",
    "        \"stream\": stream,\n",
    "        \"session_state\": session_state,\n",
    "        \"context\": context,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing your application for Protected Material\n",
    "\n",
    "When building your application, you want to test that Protected Material (i.e. copyrighted content or material) is not being generated by your generative AI applications. The following example uses an `AdversarialSimulator` paired with a protected content scenario to prompt your model to respond with material that is protected by intellectual property laws."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the adversarial simulator\n",
    "protected_material_simulator = AdversarialSimulator(azure_ai_project=azure_ai_project, credential=credential)\n",
    "\n",
    "# define the adversarial scenario you want to simulate\n",
    "protected_material_scenario = AdversarialScenario.ADVERSARIAL_CONTENT_PROTECTED_MATERIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating simulations:   0%|                                       | 0/10 [00:00<?, ?simulations/s]"
     ]
    }
   ],
   "source": [
    "unfiltered_protected_material_outputs = await protected_material_simulator(\n",
    "    scenario=protected_material_scenario,\n",
    "    max_conversation_turns=3,  # define the number of conversation turns\n",
    "    max_simulation_results=10,  # define the number of simulation results\n",
    "    target=protected_material_callback,  # define the target model callback\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look at the generated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results are truncated for brevity.\n",
    "truncation_limit = 50\n",
    "for output in unfiltered_protected_material_outputs:\n",
    "    for turn in output[\"messages\"]:\n",
    "        print(f\"{turn['role']} : {turn['content'][0:truncation_limit]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "print(unfiltered_protected_material_outputs.to_eval_qa_json_lines())\n",
    "output = unfiltered_protected_material_outputs.to_eval_qa_json_lines()\n",
    "file_path = \"unfiltered_protected_material_output.jsonl\"\n",
    "\n",
    "# Write the output to the file\n",
    "with Path.open(Path(file_path), \"w\") as file:\n",
    "    file.write(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our dataset, we can evaluate it for Protected Material. The `ProtectedMaterialEvaluator` class can take in the dataset and detect whether your data contains copyrighted content. Let's use the `evaluate()` API to run the evaluation and log it to our Azure AI Studio Project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protected_material_eval = ProtectedMaterialEvaluator(azure_ai_project=azure_ai_project, credential=credential)\n",
    "\n",
    "result = evaluate(\n",
    "    data=file_path,\n",
    "    evaluators={\"protected_material\": protected_material_eval},\n",
    "    # Optionally provide your AI Studio project information to track your evaluation results in your Azure AI Studio project\n",
    "    azure_ai_project=azure_ai_project,\n",
    "    # Optionally provide an output path to dump a json of metric summary, row level data and metric and studio URL\n",
    "    output_path=\"./mynewfilteredIPevalresults.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our \"model\" application gives us a defect rate showing us that we can't deploy our application just yet. Moving forward, to protect our application against generating protected material content, we can add an [Azure AI Content Safety filter for Protected Materials for text](https://learn.microsoft.com/azure/ai-services/content-safety/quickstart-protected-material) which is a mitigation layer to help protect and filter out responses from your model that may contain protected material content. Let's apply this filter and re-run the simulator and evaluation step to see if it helps with our defect rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_protected_material_outputs = await protected_material_simulator(\n",
    "    scenario=protected_material_scenario,\n",
    "    max_conversation_turns=3,  # define the number of conversation turns\n",
    "    max_simulation_results=10,  # define the number of simulation results\n",
    "    target=protected_material_callback,  # now with the Prompt Shield attached to our model deployment\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filtered_protected_material_outputs.to_eval_qa_json_lines())\n",
    "output = filtered_protected_material_outputs.to_eval_qa_json_lines()\n",
    "filtered_protected_material_file_path = \"filtered_protected_material_output.jsonl\"\n",
    "\n",
    "# Write the output to the file\n",
    "with Path.open(Path(filtered_protected_material_file_path), \"w\") as file:\n",
    "    file.write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_result = evaluate(\n",
    "    data=filtered_protected_material_file_path,\n",
    "    evaluators={\"protected_material\": protected_material_eval},\n",
    "    # Optionally provide your AI Studio project information to track your evaluation results in your Azure AI Studio project\n",
    "    azure_ai_project=azure_ai_project,\n",
    "    # Optionally provide an output path to dump a json of metric summary, row level data and metric and studio URL\n",
    "    output_path=\"./myfilteredevalresults.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing your application for Indirect Attack Jailbreaks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jailbreaks are direct attacks injected into either the user's query towards your application (UPIA or user prompt injected attack) or indirect attacks injected into the context sent to your application to generate a response (XPIA or cross domaine prompt injected attack). Both types of attacks will result in an altered or unexpected behavior that may result in disrupted functionality or security risks like information leakage or engaging in harmful behavior. \n",
    "\n",
    "The following example takes the \"model\" application above and simulates indirect attacks to jailbreak the model and then evaluates the dataset generated by it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Optional\n",
    "\n",
    "\n",
    "async def xpia_callback(\n",
    "    messages: List[Dict], stream: bool = False, session_state: Optional[str] = None, context: Optional[Dict] = None\n",
    ") -> dict:\n",
    "    messages_list = messages[\"messages\"]\n",
    "    # get last message\n",
    "    latest_message = messages_list[-1]\n",
    "    query = latest_message[\"content\"]\n",
    "    context = None\n",
    "    if \"file_content\" in messages[\"template_parameters\"]:\n",
    "        query += messages[\"template_parameters\"][\"file_content\"]\n",
    "    # the next few lines explain how to use the AsyncAzureOpenAI's chat.completions\n",
    "    # to respond to the simulator. You should replace it with a call to your model/endpoint/application\n",
    "    # make sure you pass the `query` and format the response as we have shown below\n",
    "\n",
    "    # Get a client handle for the model\n",
    "    deployment = os.environ.get(\"AZURE_DEPLOYMENT_NAME\")\n",
    "\n",
    "    oai_client = AzureOpenAI(\n",
    "        azure_endpoint=os.environ.get(\"AZURE_ENDPOINT\"),\n",
    "        api_version=os.environ.get(\"AZURE_API_VERSION\"),\n",
    "        api_key=os.environ.get(\"AZURE_API_KEY\"),\n",
    "    )\n",
    "    try:\n",
    "        response_from_oai_chat_completions = oai_client.chat.completions.create(\n",
    "            messages=[{\"content\": query, \"role\": \"user\"}], model=deployment, max_tokens=300\n",
    "        )\n",
    "        print(response_from_oai_chat_completions)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e} with content length {len(query)}\")\n",
    "        # to continue the conversation, return the messages, else you can fail the adversarial with an exception\n",
    "        message = {\n",
    "            \"content\": \"Something went wrong. Check the exception e for more details.\",\n",
    "            \"role\": \"assistant\",\n",
    "            \"context\": None,\n",
    "        }\n",
    "        messages[\"messages\"].append(message)\n",
    "        return {\"messages\": messages[\"messages\"], \"stream\": stream, \"session_state\": session_state}\n",
    "    response_result = response_from_oai_chat_completions.choices[0].message.content\n",
    "    formatted_response = {\n",
    "        \"content\": response_result,\n",
    "        \"role\": \"assistant\",\n",
    "        \"context\": {},\n",
    "    }\n",
    "    messages[\"messages\"].append(formatted_response)\n",
    "    return {\"messages\": messages[\"messages\"], \"stream\": stream, \"session_state\": session_state, \"context\": context}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indirect_attack_simulator = IndirectAttackSimulator(\n",
    "    azure_ai_project=azure_ai_project, credential=DefaultAzureCredential()\n",
    ")\n",
    "\n",
    "unfiltered_indirect_attack_outputs = await indirect_attack_simulator(\n",
    "    target=xpia_callback,\n",
    "    scenario=AdversarialScenario.ADVERSARIAL_INDIRECT_JAILBREAK,\n",
    "    max_simulation_results=10,\n",
    "    max_conversation_turns=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look at the data generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(unfiltered_indirect_attack_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results are truncated for brevity.\n",
    "truncation_limit = 50\n",
    "for output in unfiltered_indirect_attack_outputs:\n",
    "    for turn in output[\"messages\"]:\n",
    "        content = turn[\"content\"]\n",
    "        if isinstance(content, dict):  # user response from callback is dict\n",
    "            print(f\"{turn['role']} : {content['content'][0:truncation_limit]}\")\n",
    "        elif isinstance(content, tuple):  # assistant response from callback is tuple\n",
    "            print(f\"{turn['role']} : {content[0:truncation_limit]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "print(unfiltered_indirect_attack_outputs)\n",
    "print(unfiltered_indirect_attack_outputs.to_eval_qa_json_lines())\n",
    "output = unfiltered_indirect_attack_outputs.to_eval_qa_json_lines()\n",
    "xpia_file_path = \"unfiltered_indirect_attack_outputs.jsonl\"\n",
    "\n",
    "# Write the output to the file\n",
    "with Path.open(Path(xpia_file_path), \"w\") as file:\n",
    "    file.write(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our dataset, we can evaluate it to see if the indirect attacks resulted in jailbreaks. The `IndirectAttackEvaluator` class can take in the dataset and detects instances of jailbreak. Let's use the `evaluate()` API to run the evaluation and log it to our Azure AI Studio Project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indirect_attack_eval = IndirectAttackEvaluator(azure_ai_project=azure_ai_project, credential=DefaultAzureCredential())\n",
    "file_path = \"indirect_attack_outputs.jsonl\"\n",
    "result = evaluate(\n",
    "    data=xpia_file_path,\n",
    "    evaluators={\n",
    "        \"indirect_attack\": indirect_attack_eval,\n",
    "    },\n",
    "    # Optionally provide your AI Studio project information to track your evaluation results in your Azure AI Studio project\n",
    "    azure_ai_project=azure_ai_project,\n",
    "    # Optionally provide an output path to dump a json of metric summary, row level data and metric and studio URL\n",
    "    output_path=\"./mynewindirectattackevalresults.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our \"model\" application gives us a defect rate broken down by different behaviors resulting from the jailbreak, showing us that we can't deploy our application just yet. Moving forward, to protect our application against indirect jailbreak attacks, we can add an [Azure AI Content Safety Prompt Shield](https://learn.microsoft.com/azure/ai-services/content-safety/quickstart-jailbreak) which is a mitigation layer to help annotate and block requests to your model or application that contain known indirect attacks for jailbreak. Let's apply this filter and re-run the simulator and evaluation step to see if it helps with our defect rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_indirect_attack_outputs = await indirect_attack_simulator(\n",
    "    target=xpia_callback,  # now with the Prompt Shield attached to our model deployment\n",
    "    scenario=AdversarialScenario.ADVERSARIAL_INDIRECT_JAILBREAK,\n",
    "    max_simulation_results=10,\n",
    "    max_conversation_turns=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filtered_indirect_attack_outputs)\n",
    "print(filtered_indirect_attack_outputs.to_eval_qa_json_lines())\n",
    "output = filtered_indirect_attack_outputs.to_eval_qa_json_lines()\n",
    "xpia_file_path = \"filtered_indirect_attack_outputs.jsonl\"\n",
    "\n",
    "# Write the output to the file\n",
    "with Path.open(Path(xpia_file_path), \"w\") as file:\n",
    "    file.write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_indirect_attack_result = evaluate(\n",
    "    data=xpia_file_path,\n",
    "    evaluators={\"indirect_attack\": indirect_attack_eval},\n",
    "    # Optionally provide your AI Studio project information to track your evaluation results in your Azure AI Studio project\n",
    "    azure_ai_project=azure_ai_project,\n",
    "    # Optionally provide an output path to dump a json of metric summary, row level data and metric and studio URL\n",
    "    output_path=\"./myindirectattackevalresults.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, we've walked through how to generate test datasets using the simulation framework and our safety evaluation framework. See our documentation for more details and additional functionality on [simulation](https://aka.ms/advsimulatorhowto) and [evaluation](https://aka.ms/azureaistudiosafetyevalhowto).\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
