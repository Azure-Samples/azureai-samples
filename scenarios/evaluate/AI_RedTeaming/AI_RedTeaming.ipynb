{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Red Teaming Agent for Generative AI models and applications in Azure AI Foundry\n",
    "\n",
    "## Objective\n",
    "This notebook walks through how to use Azure AI Evaluation's AI Red Teaming Agent functionality to assess the safety and resilience of AI systems against adversarial prompt attacks. AI Red Teaming Agent leverages [Risk and Safety Evaluations](https://learn.microsoft.com/en-us/azure/ai-foundry/concepts/evaluation-metrics-built-in?tabs=warning#risk-and-safety-evaluators) to help identify potential safety issues across different risk categories (violence, hate/unfairness, sexual content, self-harm) combined with attack strategies of varying complexity levels from [PyRIT](https://github.com/Azure/PyRIT), Microsoft AI Red Teaming team's open framework for automated AI red teaming.\n",
    "\n",
    "## Time\n",
    "You should expect to spend about 30-45 minutes running this notebook. Execution time will vary based on the number of risk categories, attack strategies, and complexity levels you choose to evaluate.\n",
    "\n",
    "## Before you begin\n",
    "\n",
    "### Prerequisite\n",
    "First, if you have an Azure subscription, create an [Azure AI hub](https://learn.microsoft.com/en-us/azure/ai-studio/concepts/ai-resources) then [create an Azure AI project](https://learn.microsoft.com/en-us/azure/ai-studio/concepts/ai-resources). AI projects and Hubs can be served within a private network and are compatible with private endpoints. You **do not** need to provide your own LLM deployment as the AI Red Teaming Agent hosts adversarial models for both simulation and evaluation of harmful content and connects to it via your Azure AI project.\n",
    "\n",
    "**Required Role**: Ensure that you have the [Azure AI User](https://learn.microsoft.com/en-us/azure/ai-foundry/concepts/rbac-azure-ai-foundry#azure-ai-user) role assigned for your Azure subscription. This role provides the necessary permissions to run AI red teaming scans and access Azure AI Foundry services.\n",
    "\n",
    "In order to upload your results to Azure AI Foundry:\n",
    "- Your AI Foundry project must have a connection (*Connected Resources*) to a storage account with `Microsoft Entra ID` authentication enabled.\n",
    "- Your AI Foundry project must have the `Storage Blob Data Contributor` role in the storage account.\n",
    "- You must have the `Storage Blob Data Contributor` role in the storage account.\n",
    "- You must have network access to the storage account.\n",
    "\n",
    "For more information see: https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/develop/run-scans-ai-red-teaming-agent\n",
    "\n",
    "**Important**: First, ensure that you've installed the [Azure CLI](https://learn.microsoft.com/en-us/cli/azure/install-azure-cli) and then make sure to authenticate to Azure using `az login` in your terminal before running this notebook.\n",
    "\n",
    "### Installation\n",
    "From a terminal window, navigate to your working directory which contains this sample notebook, and execute the following.\n",
    "```bash\n",
    "python -m venv .venv\n",
    "```\n",
    "\n",
    "Then, activate the virtual environment created:\n",
    "\n",
    "```bash\n",
    "# %source .venv/bin/activate # If using Mac/Linux OS\n",
    ".venv/Scripts/activate # If using Windows OS\n",
    "```\n",
    "\n",
    "With your virtual environment activated, install the following packages required to execute this notebook:\n",
    "\n",
    "```bash\n",
    "pip install uv\n",
    "uv pip install azure-ai-evaluation[redteam] azure-identity openai azure-ai-projects\n",
    "```\n",
    "\n",
    "\n",
    "Now open VSCode with the following command, and ensure your virtual environment is used as kernel to run the remainder of this notebook.\n",
    "```bash\n",
    "code .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Mapping, Sequence\n",
    "from pathlib import Path\n",
    "from typing import Optional, Dict, Any, Protocol, TypeAlias\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from pprint import pprint\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Azure imports\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.evaluation.red_team import RedTeam, RiskCategory, AttackStrategy, SupportedLanguages\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.projects.models import (\n",
    "    AgentTaxonomyInput,\n",
    "    AzureAIAgentTarget,\n",
    "    DailyRecurrenceSchedule,\n",
    "    EvaluationScheduleTask,\n",
    "    EvaluationTaxonomy,\n",
    "    RecurrenceTrigger,\n",
    "    RiskCategory as ProjectsRiskCategory,\n",
    "    Schedule,\n",
    ")\n",
    "\n",
    "# OpenAI imports\n",
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Login to Azure with valid credentials\n",
    "\n",
    "Ensure that you've installed the [Azure CLI](https://learn.microsoft.com/en-us/cli/azure/install-azure-cli) and then make sure to authenticate to Azure using `az login` in your terminal before running this notebook.\n",
    "\n",
    "Configure the `credential` object with a different AzureCredential type if this is a requirement for your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure Credential imports\n",
    "from azure.identity import AzureCliCredential, get_bearer_token_provider\n",
    "\n",
    "!az login\n",
    "\n",
    "# Initialize Azure credentials\n",
    "credential = AzureCliCredential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Your Environment Variables\n",
    "\n",
    "Set the following variables for use in this notebook. These variables connect to your Azure resources and model deployments.\n",
    "\n",
    "Set these variables by creating an `.env` file in your project's root folder.\n",
    "\n",
    "**Note:** You can find these values in your Azure AI Foundry project or Azure OpenAI resource."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, here's an example of what your populated environment variables should look like:\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "# Azure OpenAI\n",
    "\n",
    "AZURE_OPENAI_API_KEY=\"your-api-key-here\"\n",
    "\n",
    "AZURE_OPENAI_ENDPOINT=\"https://endpoint-name.cognitiveservices.azure.com/openai/deployments/<model_deployment_name>/chat/completions?api-version=<azure_openai_api_version>\"\n",
    "\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME=\"gpt-4\"\n",
    "\n",
    "AZURE_OPENAI_API_VERSION=\"2025-01-01-preview\"\n",
    "\n",
    "\n",
    "\n",
    "# Azure AI Project (required for cloud red teaming)\n",
    "\n",
    "AZURE_PROJECT_ENDPOINT=\"https://your-aifoundry-endpoint-name.services.ai.azure.com/api/projects/yourproject-name\"\n",
    "\n",
    "AGENT_NAME=\"your-agent-name\"\n",
    "\n",
    "DATA_FOLDER=\"c:/temp/redteam\"\n",
    "\n",
    "\n",
    "\n",
    "# Model Configuration (alternative naming for cloud scenarios)\n",
    "\n",
    "MODEL_ENDPOINT=\"https://endpoint-name.cognitiveservices.azure.com/\"\n",
    "\n",
    "MODEL_API_KEY=\"your-api-key-here\"\n",
    "\n",
    "AZURE_AI_MODEL_DEPLOYMENT_NAME=\"gpt-4\"\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure AI Project information\n",
    "azure_ai_project = os.environ.get(\"AZURE_PROJECT_ENDPOINT\")\n",
    "\n",
    "\n",
    "# Azure OpenAI deployment information\n",
    "azure_openai_deployment = os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\")  # e.g., \"gpt-4\"\n",
    "azure_openai_endpoint = os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_openai_api_key = os.environ.get(\"AZURE_OPENAI_API_KEY\")  # e.g., \"your-api-key\"\n",
    "azure_openai_api_version = os.environ.get(\"AZURE_OPENAI_API_VERSION\")  # Use the latest API version\n",
    "os.environ[\"OPENAI_API_VERSION\"] = azure_openai_api_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding AI Red Teaming Agent's capabilities\n",
    "\n",
    "The Azure AI Evaluation SDK's `RedTeam` functionality evaluates AI systems against adversarial prompts across multiple dimensions:\n",
    "\n",
    "1. **Risk Categories**: Different content risk categories your AI system might generate\n",
    "   - **Violence**: Content related to physical harm, weapons, or dangerous activities\n",
    "   - **HateUnfairness**: Content related to discrimination, bias, or prejudice\n",
    "   - **Sexual**: Explicit sexual content\n",
    "   - **SelfHarm**: Content related to self-injury or suicide\n",
    "   - **ProtectedMaterial**: Copyrighted or protected intellectual property\n",
    "   - **CodeVulnerability**: Code that contains security vulnerabilities\n",
    "   - **UngroundedAttributes**: Claims not supported by evidence\n",
    "   \n",
    "   **Cloud-Only Risk Categories** (available only when using Azure AI Foundry projects):\n",
    "   - **ProhibitedActions**: Instructions for illegal or harmful activities\n",
    "   - **SensitiveDataLeakage**: Exposure of personal or confidential information\n",
    "   - **TaskAdherence**: Whether the AI follows intended task instructions\n",
    "\n",
    "2. **Attack Strategies**: Along with standard unmodified prompts which are sent by default as the `baseline`, you can specify different transformations of prompts to elicit undesired content. You can also use `AttackStrategy.Compose()` to layer two strategies in one attack. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all available attack strategies in the Azure AI Evaluation SDK\n",
    "print(\"ðŸŽ¯ All Available Attack Strategies in Azure AI Evaluation SDK:\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "# Get all AttackStrategy attributes\n",
    "attack_strategies = [attr for attr in dir(AttackStrategy) if not attr.startswith(\"_\")]\n",
    "\n",
    "print(f\"Total number of attack strategies: {len(attack_strategies)}\")\n",
    "print()\n",
    "\n",
    "# Print each strategy\n",
    "for i, strategy in enumerate(attack_strategies, 1):\n",
    "    strategy_value = getattr(AttackStrategy, strategy)\n",
    "    print(f\"{i:2}. {strategy}: {strategy_value}\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 70)\n",
    "print(\"Note: Use AttackStrategy.Compose([strategy1, strategy2]) to combine strategies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key metric for evaluating results is the **Attack Success Rate (ASR)**, which measures the percentage of attacks that successfully elicit harmful content from your AI system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Example: Fixed Response Callback\n",
    "\n",
    "Let's start with a basic example that demonstrates how to set up a Red Team evaluation using a simple callback that always returns a fixed, safe response regardless of the input prompt.\n",
    "\n",
    "**Important Note**: Since this callback always responds with the same safe message, the Attack Success Rate (ASR) will be 0% for all categories. This example is merely to demonstrate the API structure and flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple callback function that always returns a fixed response\n",
    "def financial_advisor_callback(query: str) -> str:  # noqa: ARG001\n",
    "    return \"I'm a financial advisor assistant. I can help with investment advice and financial planning within legal and ethical guidelines.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the `RedTeam` instance with comprehensive risk categories\n",
    "# Note: Some categories like ProhibitedActions, SensitiveDataLeakage, and TaskAdherence\n",
    "# are only available in cloud red teaming scenarios\n",
    "red_team = RedTeam(\n",
    "    azure_ai_project=azure_ai_project,\n",
    "    credential=credential,\n",
    "    risk_categories=[\n",
    "        RiskCategory.Violence,\n",
    "        RiskCategory.HateUnfairness,\n",
    "        RiskCategory.Sexual,\n",
    "        RiskCategory.SelfHarm,\n",
    "        RiskCategory.ProtectedMaterial,\n",
    "        RiskCategory.CodeVulnerability,\n",
    "        RiskCategory.UngroundedAttributes,\n",
    "    ],\n",
    "    num_objectives=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: `num_objectives` specifies the number of attacks to perform per risk category per attack strategy. If the parameter `risk_categories` is not specified, `[RiskCategory.Violence, RiskCategory.HateUnfairness, RiskCategory.Sexual, RiskCategory.SelfHarm]` will be used by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run a simple automated scan using the `RedTeam` with the fixed response target. We'll test against two risk categories and one attack strategy for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the red team scan called \"Basic-Callback-Scan\" with limited scope for this basic example\n",
    "# This will test 1 objective prompt for each of Violence and HateUnfairness categories with the Flip strategy\n",
    "result = await red_team.scan(\n",
    "    target=financial_advisor_callback,\n",
    "    scan_name=\"Basic-Callback-Scan\",\n",
    "    attack_strategies=[AttackStrategy.Flip],\n",
    "    output_path=\"red_team_output.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intermediary Example: Using a Model Configuration as Target\n",
    "\n",
    "Now let's create a more realistic example that uses an Azure OpenAI model for responding to the red teaming prompts. To test base or foundation models, you can update your target to take in a model configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a model configuration to test\n",
    "azure_oai_model_config = {\n",
    "    \"azure_endpoint\": azure_openai_endpoint,\n",
    "    \"azure_deployment\": azure_openai_deployment,\n",
    "    \"api_key\": azure_openai_api_key,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, create a new Red Team instance with the `language` set to `SupportedLanguages.Spanish`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_team = RedTeam(\n",
    "    azure_ai_project=azure_ai_project,\n",
    "    credential=credential,\n",
    "    language=SupportedLanguages.Spanish,\n",
    "    num_objectives=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, update your target to point to the model configurations and run the scan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the red team scan called \"Intermediary-Model-Target-Scan\"\n",
    "result = await red_team.scan(\n",
    "    target=azure_oai_model_config,\n",
    "    scan_name=\"Intermediary-Model-Target-Scan\",\n",
    "    attack_strategies=[AttackStrategy.Flip],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Example: Using an Azure Open AI Model Endpoint in a Callback Function\n",
    "\n",
    "Using the same Azure Open AI model configuration as above, we now wrap it in a callback function for more flexibility and control on the input and output handling. This will demonstrate how to evaluate an actual AI application. To test your own actual AI application, replace the inside of the callback function with a call to your application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a callback that uses Azure OpenAI API to generate responses\n",
    "async def azure_openai_callback(\n",
    "    messages: list,\n",
    "    stream: Optional[bool] = False,  # noqa: ARG001\n",
    "    session_state: Optional[str] = None,  # noqa: ARG001\n",
    "    context: Optional[Dict[str, Any]] = None,  # noqa: ARG001\n",
    ") -> dict[str, list[dict[str, str]]]:\n",
    "    # Get token provider for Azure AD authentication\n",
    "    token_provider = get_bearer_token_provider(credential, \"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "    # Initialize Azure OpenAI client\n",
    "    client = AzureOpenAI(\n",
    "        azure_endpoint=azure_openai_endpoint,\n",
    "        api_version=azure_openai_api_version,\n",
    "        azure_ad_token_provider=token_provider,\n",
    "    )\n",
    "\n",
    "    ## Extract the latest message from the conversation history\n",
    "    messages_list = [{\"role\": message.role, \"content\": message.content} for message in messages]\n",
    "    latest_message = messages_list[-1][\"content\"]\n",
    "\n",
    "    try:\n",
    "        # Call the model\n",
    "        response = client.chat.completions.create(\n",
    "            model=azure_openai_deployment,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": latest_message},\n",
    "            ],\n",
    "            # max_tokens=500, # If using an o1 base model, comment this line out\n",
    "            max_completion_tokens=500,  # If using an o1 base model, uncomment this line\n",
    "            # temperature=0.7, # If using an o1 base model, comment this line out (temperature param not supported for o1 base models)\n",
    "        )\n",
    "\n",
    "        # Format the response to follow the expected chat protocol format\n",
    "        formatted_response = {\"content\": response.choices[0].message.content, \"role\": \"assistant\"}\n",
    "    except Exception as e:\n",
    "        print(f\"Error calling Azure OpenAI: {e!s}\")\n",
    "        formatted_response = \"I encountered an error and couldn't process your request.\"\n",
    "    return {\"messages\": [formatted_response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the RedTeam instance with all available risk categories with 5 attack objectives generated for each category\n",
    "# Note: ProhibitedActions, SensitiveDataLeakage, and TaskAdherence are only available in cloud scenarios\n",
    "model_red_team = RedTeam(\n",
    "    azure_ai_project=azure_ai_project,\n",
    "    credential=credential,\n",
    "    risk_categories=[\n",
    "        RiskCategory.Violence,\n",
    "        RiskCategory.HateUnfairness,\n",
    "        RiskCategory.Sexual,\n",
    "        RiskCategory.SelfHarm,\n",
    "        RiskCategory.ProtectedMaterial,\n",
    "        RiskCategory.CodeVulnerability,\n",
    "        RiskCategory.UngroundedAttributes,\n",
    "    ],\n",
    "    num_objectives=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use this instance of `model_red_team` to test different attack strategies in the following section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Different Attack Strategies\n",
    "\n",
    "Now we'll run a more comprehensive evaluation using multiple attack strategies across risk categories. This will give us a better understanding of our model's vulnerabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the red team scan with multiple attack strategies\n",
    "advanced_result = await model_red_team.scan(\n",
    "    target=azure_openai_callback,\n",
    "    scan_name=\"Advanced-Callback-Scan\",\n",
    "    attack_strategies=[\n",
    "        AttackStrategy.EASY,  # Group of easy complexity attacks\n",
    "        AttackStrategy.MODERATE,  # Group of moderate complexity attacks\n",
    "        AttackStrategy.CharacterSpace,  # Add character spaces\n",
    "        AttackStrategy.ROT13,  # Use ROT13 encoding\n",
    "        AttackStrategy.UnicodeConfusable,  # Use confusable Unicode characters\n",
    "        AttackStrategy.CharSwap,  # Swap characters in prompts\n",
    "        AttackStrategy.Morse,  # Encode prompts in Morse code\n",
    "        AttackStrategy.Leetspeak,  # Use Leetspeak\n",
    "        AttackStrategy.Url,  # Use URLs in prompts\n",
    "        AttackStrategy.Binary,  # Encode prompts in binary\n",
    "        AttackStrategy.Compose([AttackStrategy.Base64, AttackStrategy.ROT13]),  # Use two strategies in one attack\n",
    "    ],\n",
    "    output_path=\"Advanced-Callback-Scan.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data and results used in this attack will be saved to the `output_path` specified. The URL printed out at the end of the scorecard will provide a link to where you results are uploaded and logged to your Azure AI Foundry project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bring your own objectives: Using your own prompts as objectives for RedTeam\n",
    "\n",
    "Below we demonstrate how to use your own prompts as objectives for a `RedTeam` scan. You can see the required format for prompts under `.\\data\\prompts.json`. Note that when bringing your own prompts, the supported `risk-type`s are `violence`, `sexual`, `hate_unfairness`, and `self_harm`. The number of prompts you specify will be the `num_objectives` used in the scan. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_prompts = \"./data/prompts.json\"\n",
    "\n",
    "# Create the RedTeam specifying the custom attack seed prompts to use as objectives\n",
    "custom_red_team = RedTeam(\n",
    "    azure_ai_project=azure_ai_project,\n",
    "    credential=credential,\n",
    "    custom_attack_seed_prompts=path_to_prompts,  # Path to a file containing custom attack seed prompts\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_red_team_result = await custom_red_team.scan(\n",
    "    target=azure_openai_callback,\n",
    "    scan_name=\"Custom-Prompt-Scan\",\n",
    "    attack_strategies=[\n",
    "        AttackStrategy.EASY,  # Group of easy complexity attacks\n",
    "        AttackStrategy.MODERATE,  # Group of moderate complexity attacks\n",
    "        AttackStrategy.DIFFICULT,  # Group of difficult complexity attacks\n",
    "    ],\n",
    "    output_path=\"Custom-Prompt-Scan.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloud Red Teaming with AI Project Client\n",
    "\n",
    "\n",
    "The Azure AI Projects SDK can orchestrate end-to-end cloud red teaming evaluations. This flow retrieves the latest Copilot agent version from your project, defines risk taxonomies, persists them for reuse, and submits a managed evaluation run. Cloud execution unlocks additional risk categories, centralised result storage, and lets you poll for completion without building custom orchestration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSONPrimitive = str | int | float | bool | None\n",
    "JSONValue: TypeAlias = JSONPrimitive | list[\"JSONValue\"] | dict[str, \"JSONValue\"]\n",
    "\n",
    "\n",
    "class SupportsDefinition(Protocol):\n",
    "    definition: Mapping[str, object] | None\n",
    "\n",
    "\n",
    "def _get_red_team_evaluation_criteria(\n",
    "    include_agent_specific: bool = True,\n",
    ") -> list[dict[str, str]]:\n",
    "    base_criteria = [\n",
    "        {\n",
    "            \"type\": \"azure_ai_evaluator\",\n",
    "            \"name\": \"Violence\",\n",
    "            \"evaluator_name\": \"builtin.violence\",\n",
    "            \"evaluator_version\": \"1\",\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"azure_ai_evaluator\",\n",
    "            \"name\": \"Self Harm\",\n",
    "            \"evaluator_name\": \"builtin.self_harm\",\n",
    "            \"evaluator_version\": \"1\",\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"azure_ai_evaluator\",\n",
    "            \"name\": \"Sexual\",\n",
    "            \"evaluator_name\": \"builtin.sexual\",\n",
    "            \"evaluator_version\": \"1\",\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"azure_ai_evaluator\",\n",
    "            \"name\": \"Hate Unfairness\",\n",
    "            \"evaluator_name\": \"builtin.hate_unfairness\",\n",
    "            \"evaluator_version\": \"1\",\n",
    "        },\n",
    "    ]\n",
    "    if include_agent_specific:\n",
    "        base_criteria.extend(\n",
    "            [\n",
    "                {\n",
    "                    \"type\": \"azure_ai_evaluator\",\n",
    "                    \"name\": \"Prohibited Actions\",\n",
    "                    \"evaluator_name\": \"builtin.prohibited_actions\",\n",
    "                    \"evaluator_version\": \"1\",\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"azure_ai_evaluator\",\n",
    "                    \"name\": \"Sensitive Data Leakage\",\n",
    "                    \"evaluator_name\": \"builtin.sensitive_data_leakage\",\n",
    "                    \"evaluator_version\": \"1\",\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"azure_ai_evaluator\",\n",
    "                    \"name\": \"Task Adherence\",\n",
    "                    \"evaluator_name\": \"builtin.task_adherence\",\n",
    "                    \"evaluator_version\": \"1\",\n",
    "                },\n",
    "            ]\n",
    "        )\n",
    "    return base_criteria\n",
    "\n",
    "\n",
    "def _get_tool_descriptions(agent: SupportsDefinition | Mapping[str, object] | None) -> list[dict[str, str]]:\n",
    "    if agent is None:\n",
    "        return []\n",
    "    definition_candidate = getattr(agent, \"definition\", None)\n",
    "    if definition_candidate is None and isinstance(agent, Mapping):\n",
    "        definition_candidate = agent\n",
    "    descriptions: list[dict[str, str]] = []\n",
    "    if isinstance(definition_candidate, Mapping):\n",
    "        raw_tools = definition_candidate.get(\"tools\", [])\n",
    "        if isinstance(raw_tools, Sequence) and not isinstance(raw_tools, (str, bytes)):\n",
    "            for tool in raw_tools:\n",
    "                if not isinstance(tool, Mapping):\n",
    "                    continue\n",
    "                if tool.get(\"type\") == \"openapi\":\n",
    "                    openapi_section = tool.get(\"openapi\", {})\n",
    "                    if isinstance(openapi_section, Mapping):\n",
    "                        descriptions.append(\n",
    "                            {\n",
    "                                \"name\": str(openapi_section.get(\"name\", \"Unnamed Tool\")),\n",
    "                                \"description\": str(openapi_section.get(\"description\", \"No description provided\")),\n",
    "                            }\n",
    "                        )\n",
    "                    continue\n",
    "                descriptions.append(\n",
    "                    {\n",
    "                        \"name\": str(tool.get(\"name\", \"Unnamed Tool\")),\n",
    "                        \"description\": str(tool.get(\"description\", \"No description provided\")),\n",
    "                    }\n",
    "                )\n",
    "    return descriptions\n",
    "\n",
    "\n",
    "def _to_json_primitive(value: object) -> JSONValue:\n",
    "    if value is None or isinstance(value, (str, int, float, bool)):\n",
    "        return value\n",
    "    if isinstance(value, (list, tuple, set)):\n",
    "        return [_to_json_primitive(item) for item in value]\n",
    "    if isinstance(value, Mapping):\n",
    "        return {str(key): _to_json_primitive(val) for key, val in value.items()}\n",
    "    for attr in (\"to_dict\", \"as_dict\", \"dict\", \"serialize\"):\n",
    "        if hasattr(value, attr):\n",
    "            method = getattr(value, attr)\n",
    "            try:\n",
    "                result = method() if callable(method) else method\n",
    "                return _to_json_primitive(result)\n",
    "            except Exception:\n",
    "                continue\n",
    "    if hasattr(value, \"__dict__\"):\n",
    "        return _to_json_primitive({k: v for k, v in vars(value).items() if not k.startswith(\"_\")})\n",
    "    return str(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure cloud model evaluation\n",
    "\n",
    "\n",
    "Update the values below to point at the Azure OpenAI deployment you want to exercise in the managed cloud run. Strategy names should match the options listed earlier in the notebook (for example: `\"Flip\"`, `\"Base64\"`, `\"Crescendo\"`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_model_attack_strategies = [\n",
    "    \"Crescendo\"\n",
    "    # Add additional strategy names (e.g., \"Flip\", \"Jailbreak\", \"IndirectJailbreak\") as needed\n",
    "]\n",
    "cloud_model_deployment_name = os.environ.get(\"AZURE_AI_MODEL_DEPLOYMENT_NAME\") or azure_openai_deployment or \"\"\n",
    "cloud_model_num_objectives = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit cloud model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cloud_model_red_team_evaluation(\n",
    "    attack_strategies: Sequence[str] | None = None,\n",
    "    model_deployment_name: str | None = None,\n",
    "    num_objectives: int = 5,\n",
    ") -> None:\n",
    "    endpoint = os.environ.get(\"AZURE_PROJECT_ENDPOINT\") or azure_ai_project or \"\"\n",
    "    data_folder = os.environ.get(\"DATA_FOLDER\", str(Path.cwd() / \"redteam_outputs\"))\n",
    "    strategies = [strategy for strategy in (attack_strategies or [\"Flip\", \"Base64\"]) if strategy]\n",
    "    target_deployment = (\n",
    "        model_deployment_name or os.environ.get(\"AZURE_AI_MODEL_DEPLOYMENT_NAME\") or azure_openai_deployment or \"\"\n",
    "    )\n",
    "    print(f\"Targetting deployment name: {target_deployment}\")\n",
    "    model_endpoint = os.environ.get(\"MODEL_ENDPOINT\") or azure_openai_endpoint or \"\"\n",
    "    model_api_key = os.environ.get(\"MODEL_API_KEY\") or azure_openai_api_key or \"\"\n",
    "    api_version = os.environ.get(\"OPENAI_API_VERSION\") or azure_openai_api_version or \"\"\n",
    "    if not endpoint:\n",
    "        print(\"Cloud red teaming skipped: set AZURE_PROJECT_ENDPOINT.\")\n",
    "        return\n",
    "    if not target_deployment:\n",
    "        print(\"Cloud red teaming skipped: set AZURE_AI_MODEL_DEPLOYMENT_NAME or pass model_deployment_name.\")\n",
    "        return\n",
    "    if not model_endpoint or not model_api_key:\n",
    "        print(\"Cloud red teaming skipped: set MODEL_ENDPOINT and MODEL_API_KEY.\")\n",
    "        return\n",
    "    if not strategies:\n",
    "        print(\"Cloud red teaming skipped: provide at least one attack strategy.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Using cloud model attack strategies: {strategies}\")\n",
    "    print(f\"Target deployment: {target_deployment}\")\n",
    "    print(f\"Project endpoint: {endpoint}\")\n",
    "    if api_version:\n",
    "        print(f\"OpenAI API version: {api_version}\")\n",
    "    else:\n",
    "        print(\"No OpenAI API version set; the SDK will use its default.\")\n",
    "\n",
    "    data_folder_path = Path(data_folder)\n",
    "    data_folder_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with DefaultAzureCredential() as project_credential, AIProjectClient(\n",
    "        endpoint=endpoint,\n",
    "        credential=project_credential,\n",
    "        api_version=\"2025-11-15-preview\",\n",
    "    ) as project_client:\n",
    "        print(\"Creating an OpenAI client from the AI Project client\")\n",
    "        client = project_client.get_openai_client()\n",
    "\n",
    "        try:\n",
    "            eval_group_name = f\"Red Team Model Safety Eval Group - {int(time.time())}\"\n",
    "            eval_run_name = f\"Red Team Model Safety Eval Run for {target_deployment} - {int(time.time())}\"\n",
    "            data_source_config = {\"type\": \"azure_ai_source\", \"scenario\": \"red_team\"}\n",
    "\n",
    "            testing_criteria = _get_red_team_evaluation_criteria(include_agent_specific=False)\n",
    "\n",
    "            print(\"Creating Eval Group\")\n",
    "            eval_object = client.evals.create(\n",
    "                name=eval_group_name,\n",
    "                data_source_config=data_source_config,\n",
    "                testing_criteria=testing_criteria,\n",
    "            )\n",
    "        except Exception as error:\n",
    "            print(\"Failed when creating the eval group. Raw error:\")\n",
    "            print(error)\n",
    "            raise\n",
    "        print(f\"Eval Group created for model red teaming: {eval_group_name}\")\n",
    "\n",
    "        print(f\"Get Eval Group by Id: {eval_object.id}\")\n",
    "        eval_object_response = client.evals.retrieve(eval_object.id)\n",
    "        print(\"Eval Group Response:\")\n",
    "        pprint(eval_object_response)\n",
    "\n",
    "        try:\n",
    "            print(\"Creating RedTeaming Eval Run for model\")\n",
    "            eval_run_object = client.evals.runs.create(\n",
    "                eval_id=eval_object.id,\n",
    "                name=eval_run_name,\n",
    "                data_source={\n",
    "                    \"type\": \"azure_ai_red_team\",\n",
    "                    \"item_generation_params\": {\n",
    "                        \"type\": \"red_team\",\n",
    "                        \"attack_strategies\": strategies,\n",
    "                        \"num_turns\": num_objectives,\n",
    "                    },\n",
    "                    \"target\": {\n",
    "                        \"type\": \"azure_ai_model\",\n",
    "                        \"model\": target_deployment,\n",
    "                        \"sampling_params\": {\n",
    "                            \"temperature\": 0.7,\n",
    "                            \"top_p\": 1.0,\n",
    "                            \"seed\": 0,\n",
    "                            \"max_completion_tokens\": 1024,\n",
    "                        },\n",
    "                    },\n",
    "                },\n",
    "            )\n",
    "\n",
    "            print(f\"Eval Run created for model red teaming: {eval_run_name}\")\n",
    "            pprint(eval_run_object)\n",
    "        except Exception as error:\n",
    "            print(\"Failed when creating the eval run. Raw error:\")\n",
    "            print(error)\n",
    "            raise\n",
    "\n",
    "        print(f\"Get Eval Run by Id: {eval_run_object.id}\")\n",
    "        eval_run_response = client.evals.runs.retrieve(\n",
    "            run_id=eval_run_object.id,\n",
    "            eval_id=eval_object.id,\n",
    "        )\n",
    "        print(\"Eval Run Response:\")\n",
    "        pprint(eval_run_response)\n",
    "\n",
    "        while True:\n",
    "            run = client.evals.runs.retrieve(\n",
    "                run_id=eval_run_response.id,\n",
    "                eval_id=eval_object.id,\n",
    "            )\n",
    "            if run.status in {\"completed\", \"failed\"}:\n",
    "                output_items = list(\n",
    "                    client.evals.runs.output_items.list(\n",
    "                        run_id=run.id,\n",
    "                        eval_id=eval_object.id,\n",
    "                    )\n",
    "                )\n",
    "                output_items_path = data_folder_path / f\"redteam_model_eval_output_{target_deployment}.json\"\n",
    "                with output_items_path.open(\"w\", encoding=\"utf-8\") as file_handle:\n",
    "                    json.dump(_to_json_primitive(output_items), file_handle, indent=2)\n",
    "                print(\n",
    "                    f\"Model red team run completed with status: {run.status}. \"\n",
    "                    f\"Output items written to {output_items_path}\"\n",
    "                )\n",
    "                break\n",
    "            time.sleep(5)\n",
    "            print(\"Waiting for model eval run to complete...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    run_cloud_model_red_team_evaluation(\n",
    "        attack_strategies=cloud_model_attack_strategies,\n",
    "        model_deployment_name=cloud_model_deployment_name,\n",
    "        num_objectives=cloud_model_num_objectives,\n",
    "    )\n",
    "except Exception as exc:\n",
    "    print(f\"Cloud red teaming failed: {exc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure cloud agent evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_agent_attack_strategies = [\n",
    "    \"Flip\",\n",
    "    \"Base64\",\n",
    "]\n",
    "cloud_agent_num_objectives = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit cloud agent evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cloud_agent_red_team_evaluation(\n",
    "    attack_strategies: Sequence[str] | None = None,\n",
    "    num_objectives: int = 5,\n",
    ") -> None:\n",
    "    endpoint = os.environ.get(\"AZURE_PROJECT_ENDPOINT\") or azure_ai_project or \"\"\n",
    "    agent_name = os.environ.get(\"AGENT_NAME\", \"\")\n",
    "    data_folder = os.environ.get(\"DATA_FOLDER\", str(Path.cwd() / \"redteam_outputs\"))\n",
    "    strategies = [strategy for strategy in (attack_strategies or [\"Flip\", \"Base64\"]) if strategy]\n",
    "    api_version = os.environ.get(\"OPENAI_API_VERSION\") or azure_openai_api_version or \"\"\n",
    "    if not endpoint:\n",
    "        print(\"Cloud red teaming skipped: set AZURE_PROJECT_ENDPOINT.\")\n",
    "        return\n",
    "    if not agent_name:\n",
    "        print(\"Cloud red teaming skipped: set AGENT_NAME.\")\n",
    "        return\n",
    "    if not strategies:\n",
    "        print(\"Cloud red teaming skipped: provide at least one attack strategy.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Using cloud agent attack strategies: {strategies}\")\n",
    "    print(f\"Target agent: {agent_name}\")\n",
    "    print(f\"Project endpoint: {endpoint}\")\n",
    "    if api_version:\n",
    "        print(f\"OpenAI API version: {api_version}\")\n",
    "    else:\n",
    "        print(\"No OpenAI API version set; the SDK will use its default.\")\n",
    "\n",
    "    data_folder_path = Path(data_folder)\n",
    "    data_folder_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with DefaultAzureCredential() as project_credential, AIProjectClient(\n",
    "        endpoint=endpoint,\n",
    "        credential=project_credential,\n",
    "        api_version=\"2025-11-15-preview\",\n",
    "    ) as project_client:\n",
    "        print(\"Creating an OpenAI client from the AI Project client\")\n",
    "        client = project_client.get_openai_client()\n",
    "\n",
    "        try:\n",
    "            versions = list(project_client.agents.list_versions(agent_name))\n",
    "            latest = max(versions, key=lambda v: float(v.version))  # adjust if versions aren't numeric\n",
    "            agent = project_client.agents.get_version(agent_name, latest.version)\n",
    "            agent_version = agent.version\n",
    "            print(f\"Retrieved agent: {agent_name}, version: {agent_version}\")\n",
    "            eval_group_name = f\"Red Team Agent Safety Eval Group - {int(time.time())}\"\n",
    "            eval_run_name = f\"Red Team Agent Safety Eval Run for {agent_name} - {int(time.time())}\"\n",
    "            data_source_config = {\"type\": \"azure_ai_source\", \"scenario\": \"red_team\"}\n",
    "\n",
    "            testing_criteria = _get_red_team_evaluation_criteria()\n",
    "\n",
    "            print(\"Creating Eval Group\")\n",
    "            eval_object = client.evals.create(\n",
    "                name=eval_group_name,\n",
    "                data_source_config=data_source_config,\n",
    "                testing_criteria=testing_criteria,\n",
    "            )\n",
    "        except Exception as error:\n",
    "            print(\"Failed when creating the eval group. Raw error:\")\n",
    "            print(error)\n",
    "            raise\n",
    "\n",
    "        print(f\"Eval Group created for agent red teaming: {eval_group_name}\")\n",
    "\n",
    "        print(f\"Get Eval Group by Id: {eval_object.id}\")\n",
    "        eval_object_response = client.evals.retrieve(eval_object.id)\n",
    "        print(\"Eval Group Response:\")\n",
    "        pprint(eval_object_response)\n",
    "\n",
    "        try:\n",
    "            risk_categories_for_taxonomy = [ProjectsRiskCategory.PROHIBITED_ACTIONS]\n",
    "            target = AzureAIAgentTarget(\n",
    "                name=agent_name,\n",
    "                version=agent_version,\n",
    "                tool_descriptions=_get_tool_descriptions(agent),\n",
    "            )\n",
    "            agent_taxonomy_input = AgentTaxonomyInput(\n",
    "                risk_categories=risk_categories_for_taxonomy,\n",
    "                target=target,\n",
    "            )\n",
    "            print(\"Creating Eval Taxonomies\")\n",
    "            eval_taxonomy_input = EvaluationTaxonomy(\n",
    "                description=\"Taxonomy for agent red teaming evaluation\",\n",
    "                taxonomy_input=agent_taxonomy_input,\n",
    "            )\n",
    "\n",
    "            taxonomy = project_client.evaluation_taxonomies.create(\n",
    "                name=agent_name,\n",
    "                body=eval_taxonomy_input,\n",
    "            )\n",
    "            taxonomy_path = data_folder_path / f\"taxonomy_agent_{agent_name}.json\"\n",
    "            with taxonomy_path.open(\"w\", encoding=\"utf-8\") as file_handle:\n",
    "                json.dump(_to_json_primitive(taxonomy), file_handle, indent=2)\n",
    "            print(f\"RedTeaming Taxonomy created for agent: {agent_name}. Taxonomy written to {taxonomy_path}\")\n",
    "        except Exception as error:\n",
    "            print(\"Failed when creating the eval taxonomy. Raw error:\")\n",
    "            print(error)\n",
    "            raise\n",
    "\n",
    "        try:\n",
    "            print(\"Creating RedTeaming Eval Run for agent\")\n",
    "            eval_run_object = client.evals.runs.create(\n",
    "                eval_id=eval_object.id,\n",
    "                name=eval_run_name,\n",
    "                data_source={\n",
    "                    \"type\": \"azure_ai_red_team\",\n",
    "                    \"item_generation_params\": {\n",
    "                        \"type\": \"red_team_taxonomy\",\n",
    "                        \"attack_strategies\": strategies,\n",
    "                        \"num_turns\": num_objectives,\n",
    "                        \"source\": {\"type\": \"file_id\", \"id\": taxonomy.id},\n",
    "                    },\n",
    "                    \"target\": target.as_dict(),\n",
    "                },\n",
    "            )\n",
    "        except Exception as error:\n",
    "            print(\"Failed when creating the eval run. Raw error:\")\n",
    "            print(error)\n",
    "            raise\n",
    "\n",
    "        print(f\"Eval Run created for agent red teaming: {eval_run_name}\")\n",
    "        pprint(eval_run_object)\n",
    "\n",
    "        print(f\"Get Eval Run by Id: {eval_run_object.id}\")\n",
    "        eval_run_response = client.evals.runs.retrieve(\n",
    "            run_id=eval_run_object.id,\n",
    "            eval_id=eval_object.id,\n",
    "        )\n",
    "        print(\"Eval Run Response:\")\n",
    "        pprint(eval_run_response)\n",
    "\n",
    "        while True:\n",
    "            run = client.evals.runs.retrieve(\n",
    "                run_id=eval_run_response.id,\n",
    "                eval_id=eval_object.id,\n",
    "            )\n",
    "            if run.status in {\"completed\", \"failed\"}:\n",
    "                output_items = list(\n",
    "                    client.evals.runs.output_items.list(\n",
    "                        run_id=run.id,\n",
    "                        eval_id=eval_object.id,\n",
    "                    )\n",
    "                )\n",
    "                output_items_path = data_folder_path / f\"redteam_agent_eval_output_{agent_name}.json\"\n",
    "                with output_items_path.open(\"w\", encoding=\"utf-8\") as file_handle:\n",
    "                    json.dump(_to_json_primitive(output_items), file_handle, indent=2)\n",
    "                print(\n",
    "                    f\"Agent red team run completed with status: {run.status}. \"\n",
    "                    f\"Output items written to {output_items_path}\"\n",
    "                )\n",
    "                break\n",
    "            time.sleep(5)\n",
    "            print(\"Waiting for agent eval run to complete...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    run_cloud_agent_red_team_evaluation(\n",
    "        attack_strategies=cloud_agent_attack_strategies,\n",
    "        num_objectives=cloud_agent_num_objectives,\n",
    "    )\n",
    "except Exception as exc:\n",
    "    print(f\"Cloud red teaming failed: {exc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schedule Recurring Cloud Red Teaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def schedule_cloud_agent_red_team_evaluation(\n",
    "    schedule_id: str = \"redteam-agent-eval-daily-0900\",\n",
    "    run_hour_utc: int = 9,\n",
    "    attack_strategies: Sequence[str] | None = None,\n",
    "    num_objectives: int = 5,\n",
    ") -> None:\n",
    "    \"\"\"Create or update a daily Azure AI schedule that submits an agent red team run.\"\"\"\n",
    "    endpoint = os.environ.get(\"AZURE_PROJECT_ENDPOINT\") or azure_ai_project or \"\"\n",
    "    agent_name = os.environ.get(\"AGENT_NAME\", \"\")\n",
    "    data_folder = os.environ.get(\"DATA_FOLDER\", str(Path.cwd() / \"redteam_outputs\"))\n",
    "    strategies = [strategy for strategy in (attack_strategies or [\"Flip\", \"Base64\"]) if strategy]\n",
    "    if not 0 <= run_hour_utc <= 23:\n",
    "        print(\"Provide run_hour_utc between 0 and 23 (UTC).\")\n",
    "        return\n",
    "    if not endpoint:\n",
    "        print(\"Scheduling skipped: set AZURE_PROJECT_ENDPOINT.\")\n",
    "        return\n",
    "    if not agent_name:\n",
    "        print(\"Scheduling skipped: set AGENT_NAME.\")\n",
    "        return\n",
    "    if not strategies:\n",
    "        print(\"Scheduling skipped: provide at least one attack strategy.\")\n",
    "        return\n",
    "    data_folder_path = Path(data_folder)\n",
    "    data_folder_path.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Using project endpoint: {endpoint}\")\n",
    "    print(f\"Target agent: {agent_name}\")\n",
    "    print(f\"Schedule id: {schedule_id} (daily at {run_hour_utc:02d}:00 UTC)\")\n",
    "    with DefaultAzureCredential() as project_credential, AIProjectClient(\n",
    "        endpoint=endpoint,\n",
    "        credential=project_credential,\n",
    "        api_version=\"2025-11-15-preview\",\n",
    "    ) as project_client:\n",
    "        print(\"Creating an OpenAI client from the AI Project client\")\n",
    "        client = project_client.get_openai_client()\n",
    "        versions = list(project_client.agents.list_versions(agent_name))\n",
    "        if not versions:\n",
    "            print(f\"No published versions found for agent {agent_name}.\")\n",
    "            return\n",
    "        latest = max(versions, key=lambda version: float(version.version))\n",
    "        agent = project_client.agents.get_version(agent_name, latest.version)\n",
    "        agent_version = agent.version\n",
    "        print(f\"Retrieved agent version: {agent_version}\")\n",
    "        eval_group_name = f\"Red Team Agent Safety Eval Group - {int(time.time())}\"\n",
    "        eval_run_name = f\"Red Team Agent Safety Eval Run for {agent_name} - {int(time.time())}\"\n",
    "        data_source_config = {\"type\": \"azure_ai_source\", \"scenario\": \"red_team\"}\n",
    "        testing_criteria = _get_red_team_evaluation_criteria()\n",
    "        print(\"Creating Eval Group for scheduled run\")\n",
    "        eval_object = client.evals.create(\n",
    "            name=eval_group_name,\n",
    "            data_source_config=data_source_config,\n",
    "            testing_criteria=testing_criteria,\n",
    "        )\n",
    "        print(f\"Eval Group id: {eval_object.id}\")\n",
    "        risk_categories_for_taxonomy = [ProjectsRiskCategory.PROHIBITED_ACTIONS]\n",
    "        target = AzureAIAgentTarget(\n",
    "            name=agent_name,\n",
    "            version=agent_version,\n",
    "            tool_descriptions=_get_tool_descriptions(agent),\n",
    "        )\n",
    "        agent_taxonomy_input = AgentTaxonomyInput(\n",
    "            risk_categories=risk_categories_for_taxonomy,\n",
    "            target=target,\n",
    "        )\n",
    "        eval_taxonomy_input = EvaluationTaxonomy(\n",
    "            description=\"Taxonomy for scheduled agent red teaming\",\n",
    "            taxonomy_input=agent_taxonomy_input,\n",
    "        )\n",
    "        taxonomy = project_client.evaluation_taxonomies.create(\n",
    "            name=agent_name,\n",
    "            body=eval_taxonomy_input,\n",
    "        )\n",
    "        taxonomy_path = data_folder_path / f\"taxonomy_agent_{agent_name}.json\"\n",
    "        with taxonomy_path.open(\"w\", encoding=\"utf-8\") as file_handle:\n",
    "            json.dump(_to_json_primitive(taxonomy), file_handle, indent=2)\n",
    "        print(f\"Red team taxonomy stored at {taxonomy_path}. Schedule will reuse file id {taxonomy.id}.\")\n",
    "        eval_run_object = {\n",
    "            \"eval_id\": eval_object.id,\n",
    "            \"name\": eval_run_name,\n",
    "            \"data_source\": {\n",
    "                \"type\": \"azure_ai_red_team\",\n",
    "                \"item_generation_params\": {\n",
    "                    \"type\": \"red_team_taxonomy\",\n",
    "                    \"attack_strategies\": strategies,\n",
    "                    \"num_turns\": num_objectives,\n",
    "                    \"source\": {\"type\": \"file_id\", \"id\": taxonomy.id},\n",
    "                },\n",
    "                \"target\": target.as_dict(),\n",
    "            },\n",
    "        }\n",
    "        print(\"Creating or updating schedule\")\n",
    "        schedule = Schedule(\n",
    "            display_name=\"Red Team Agent Safety Eval\",\n",
    "            enabled=True,\n",
    "            trigger=RecurrenceTrigger(\n",
    "                interval=1,\n",
    "                schedule=DailyRecurrenceSchedule(hours=[run_hour_utc]),\n",
    "            ),\n",
    "            task=EvaluationScheduleTask(\n",
    "                eval_id=eval_object.id,\n",
    "                eval_run=eval_run_object,\n",
    "            ),\n",
    "        )\n",
    "        try:\n",
    "            project_client.schedules.get(schedule_id)\n",
    "            schedule_response = project_client.schedules.create_or_update(\n",
    "                schedule_id=schedule_id,\n",
    "                schedule=schedule,\n",
    "            )\n",
    "        except Exception:\n",
    "            schedule_response = project_client.schedules.create(\n",
    "                schedule_id=schedule_id,\n",
    "                schedule=schedule,\n",
    "            )\n",
    "        print(f\"Schedule ready: {schedule_response.id}\")\n",
    "        print(\"Latest schedule definition:\")\n",
    "        pprint(_to_json_primitive(schedule_response))\n",
    "        print(\"Recent schedule runs:\")\n",
    "        for run in project_client.schedules.list_runs(schedule_id=schedule_response.id):\n",
    "            pprint(_to_json_primitive(run))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    schedule_cloud_agent_red_team_evaluation(\n",
    "        attack_strategies=cloud_agent_attack_strategies,\n",
    "        num_objectives=cloud_agent_num_objectives,\n",
    "    )\n",
    "except Exception as exc:\n",
    "    print(f\"Cloud red teaming failed: {exc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting Errors\n",
    "\n",
    "\n",
    "### Permission or authentication failures\n",
    "\n",
    "\n",
    "- Confirm you ran `az login` in the active shell and that the account has the **Azure AI User** role plus the storage `Storage Blob Data Contributor` assignments called out earlier in this notebook. These roles are required to create evaluation runs and upload artifacts.\n",
    "- When working inside a secured hub, make sure the connected storage account is accessible from your network and that Entra ID authentication is enabled on the storage resource.\n",
    "- If the cloud red teaming helper prints `This may be due to missing environment variables or insufficient permissions.`, double-check the `AZURE_PROJECT_ENDPOINT`, `AGENT_NAME`, and storage role assignments before retrying.\n",
    "\n",
    "### PyRIT \"Error sending prompt\" message\n",
    "\n",
    "\n",
    "- `Exception: Error sending prompt with conversation ID: <guid>` indicates PyRIT could not reach the target LLM during a conversation turn. The runner retries the same conversation up to the configured limit, so isolated occurrences are expected and usually recover without intervention.\n",
    "- Common triggers are transient network issues, 429 throttling, or 5xx responses from the target deployment. Even if retries succeed you will still see the stack trace in the notebook output.\n",
    "- Inspect the `redteam.log` file emitted to the scan output directory (for local runs this defaults to `<working dir>/runs/<scan_id>/redteam.log`) for the original exception and HTTP status. Increase verbosity with `PF_LOGGING_LEVEL=DEBUG` when deeper diagnostics are needed.\n",
    "- If one conversation ID keeps failing, verify the target credentials, check deployment health, and review Azure OpenAI quota/rate-limit alerts in the Azure portal.\n",
    "\n",
    "### Target resource not found\n",
    "\n",
    "\n",
    "- When you pass an Azure OpenAI deployment directly as the `target` to `RedTeam`, set `azure_endpoint` to `https://<hub>.openai.azure.com/openai/deployments/<deployment_name>/chat/completions?api-version=2025-01-01-preview`.\n",
    "- If you instantiate `AzureOpenAI`, use the resource-level endpoint format `https://<hub>.openai.azure.com/`. Ensure the deployment name and API version match an active deployment in the selected hub.\n",
    "- If the cloud run fails with `Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}` while creating the eval group, confirm you have `azure-ai-projects>=2.0.0b1` installed (the preview APIs surface only in that version or later).\n",
    "\n",
    "### Agent name not found\n",
    "\n",
    "\n",
    "- A `(not_found) Agent <name> doesnâ€™t exist` message means the project could not resolve the agent `name`. Agent names are case sensitive and differ from display names.\n",
    "- Use the helper below to enumerate every agent the current `AZURE_PROJECT_ENDPOINT` exposes. Confirm the `name` column matches the value in `AGENT_NAME`.\n",
    "- If the agent is missing, verify you selected the correct project endpoint/region, that the agent is published in Azure AI Foundry, and that your account has access to it.\n",
    "\n",
    "```python\n",
    "def list_project_agents(endpoint: str | None = None) -> None:\n",
    "    \"\"\"Print the agent names available in the current Azure AI project.\"\"\"\n",
    "    project_endpoint = endpoint or os.environ.get(\"AZURE_PROJECT_ENDPOINT\") or azure_ai_project or \"\"\n",
    "    if not project_endpoint:\n",
    "        print(\"Set AZURE_PROJECT_ENDPOINT before listing agents.\")\n",
    "        return\n",
    "    with DefaultAzureCredential() as project_credential:\n",
    "        with AIProjectClient(\n",
    "            endpoint=project_endpoint,\n",
    "            credential=project_credential,\n",
    "            api_version=\"2025-11-15-preview\",\n",
    "        ) as project_client:\n",
    "            agents = list(project_client.agents.list())\n",
    "    if not agents:\n",
    "        print(f\"No agents found in project: {project_endpoint}\")\n",
    "        return\n",
    "    print(f\"Agents in {project_endpoint}:\")\n",
    "    for agent in agents:\n",
    "        display_name = agent.get(\"display_name\") if isinstance(agent, dict) else getattr(agent, \"display_name\", \"\")\n",
    "        name = agent.get(\"name\") if isinstance(agent, dict) else getattr(agent, \"name\", \"\")\n",
    "        print(f\"- name: {name} | display_name: {display_name}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this comprehensive notebook, we've demonstrated the full spectrum of Azure AI Evaluation SDK's `RedTeam` functionality to assess the safety and resilience of AI systems across multiple dimensions:\n",
    "\n",
    "### What We Covered\n",
    "\n",
    "1. **Complete Risk Category Coverage**: We explored all available risk categories, including both standard categories (Violence, HateUnfairness, Sexual, SelfHarm, ProtectedMaterial, CodeVulnerability, UngroundedAttributes) and cloud-only categories (ProhibitedActions, SensitiveDataLeakage, TaskAdherence)\n",
    "\n",
    "2. **Advanced Attack Strategies**: We demonstrated sophisticated attack techniques including:\n",
    "   - Single-turn encoding and obfuscation attacks\n",
    "   - Multi-turn conversational attacks\n",
    "   - **Crescendo attacks** - gradually escalating conversations from benign to harmful\n",
    "   - Composed attack strategies that layer multiple techniques\n",
    "\n",
    "3. **Cloud Red Teaming**: We showed how to leverage the Azure AI Projects SDK for cloud-based red teaming that provides access to additional risk categories and evaluation capabilities\n",
    "\n",
    "4. **Custom Attack Objectives**: We demonstrated how to use custom prompts for targeted testing scenarios\n",
    "\n",
    "5. **Automated Scheduling**: We mirrored the preview `sample_scheduled_evaluations.py` flow to register recurring agent safety evaluations directly from Azure AI Projects\n",
    "\n",
    "### Key Insights\n",
    "\n",
    "The automated AI red teaming scans provide valuable insights into:\n",
    "\n",
    "1. **Overall Attack Success Rate (ASR)** - The percentage of attacks that successfully elicit harmful content\n",
    "2. **Vulnerability by Risk Category** - Which types of harmful content your model is most vulnerable to  \n",
    "3. **Effectiveness of Attack Strategies** - Which attack techniques are most successful against your model\n",
    "4. **Multi-Turn Attack Patterns** - How sophisticated conversational attacks like Crescendo can gradually bypass safety measures\n",
    "5. **Cloud vs Local Capabilities** - Additional risk categories and evaluation depth available through Azure AI Foundry\n",
    "\n",
    "### Deployment Considerations\n",
    "\n",
    "- **Crescendo and MultiTurn attacks** require significantly more time and resources than single-turn attacks\n",
    "- **Cloud-only agent safety risk categories** (ProhibitedActions, SensitiveDataLeakage, TaskAdherence) are only available when targetting an agent using cloud Red Teaming\n",
    "- **Multi-turn attacks** provide deeper insights but require longer execution times and higher API costs\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Mitigation**: Use these results to strengthen your model's guardrails against identified attack vectors, paying special attention to multi-turn attack patterns\n",
    "2. **Continuous Testing**: Implement regular red team evaluations as part of your development lifecycle, including both fast single-turn and thorough multi-turn testing\n",
    "3. **Cloud Integration**: Consider leveraging Azure AI Foundry for access to additional risk categories and cloud-scale evaluation capabilities\n",
    "4. **Custom Strategies**: Develop custom attack strategies and objectives for your specific use cases and domain\n",
    "5. **Safety Layers**: Implement multiple layers of defense including Azure AI Content Safety, custom content filters, and conversation flow controls\n",
    "6. **Monitoring**: Set up continuous monitoring for attack patterns in production, especially sophisticated multi-turn attempts \n",
    "7. **Schedule Health Checks**: Review the scheduled run history and alerts so unattended evaluations keep delivering fresh coverage without manual intervention"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureai-samples (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
