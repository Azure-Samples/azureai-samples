{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Simulate Queries and Responses from Azure Search Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "Use the Simulator to generate high-quality queries and responses from your data in Azure Search using LLMs.\n",
    "\n",
    "This tutorial uses the following Azure AI services:\n",
    "\n",
    "- Access to Azure OpenAI Service - you can apply for access [here](https://go.microsoft.com/fwlink/?linkid=2222006)\n",
    "- An Azure AI Search service - go to [aka.ms/azuresearch](https://aka.ms/azuresearch) to create a service "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time\n",
    "\n",
    "You should expect to spend 5-10 minutes running this sample. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this example\n",
    "\n",
    "Large Language Models (LLMs) can help you create query and response datasets from your existing data sources such as text or index. These datasets can be useful for various tasks, such as testing your retrieval capabilities, evaluating and improving your RAG workflows, tuning your prompts and more. In this sample, we will explore how to use the Simulator to generate high-quality query and response pairs from your search index using LLMs and simulate interactions with your application with them. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "In this sample we will generate text data from an Azure Search index called `realestate-us-sample-index`.  You can follow the same steps replacing the index with any other index in your Azure Search service. To create the index used in this sample, go to **Import data** when creating an index in your Azure Search Service, and select the *realestate-us-sample* data source.\n",
    "\n",
    "The `realestate-us-sample-index` contains the following fields:\n",
    "\n",
    "\n",
    "| Field Name       | Type              |\n",
    "|------------------|-------------------|\n",
    "| listingId        | String            |\n",
    "| beds             | Int32             |\n",
    "| baths            | Int32             |\n",
    "| description      | String            |\n",
    "| description_de   | String            | \n",
    "| description_fr   | String            |\n",
    "| description_it   | String            |\n",
    "| description_es   | String            |\n",
    "| description_pl   | String            |\n",
    "| description_nl   | String            |\n",
    "| sqft             | Int32             |\n",
    "| daysOnMarket     | Int32             |\n",
    "| status           | String            |\n",
    "| source           | String            |\n",
    "| number           | String            |\n",
    "| street           | String            |\n",
    "| unit             | String            | \n",
    "| type             | String            |\n",
    "| city             | String            |\n",
    "| region           | String            |\n",
    "| countryCode      | String            |\n",
    "| postCode         | String            |\n",
    "| location         | GeographyPoint    |\n",
    "| price            | Int64             |\n",
    "| thumbnail        | String            | \n",
    "| tags             | StringCollection  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you begin\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation\n",
    "\n",
    "Install the following packages required to execute this notebook. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the packages\n",
    "%pip install azure-identity azure-ai-evaluation\n",
    "%pip install azure-search-documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "Lets initialize some variables. We need a way to connect to a LLM to use the notebook. This sample suggests a way to use `gpt-4o-mini` deployment in your Azure AI project. Replace the `azure_endpoint` with a link to your endpoint. If your applications calls `AzureOpenAI`'s chat completion endpoint, you will need to replace the values in `<>` with your `AzureOpenAI` deployment details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_DEPLOYMENT\"] = \"<your-deployment>\"\n",
    "os.environ[\"AZURE_OPENAI_API_VERSION\"] = \"<api version>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# project details\n",
    "azure_endpoint = \"https://<ai-hub>.openai.azure.com\"\n",
    "azure_deployment = \"gpt-4o-mini\"  # replace with your deployment name, if different\n",
    "\n",
    "should_cleanup: bool = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to your project\n",
    "\n",
    "To start with let us create a config file with your project details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "model_config = {\n",
    "    \"azure_endpoint\": azure_endpoint,\n",
    "    \"azure_deployment\": azure_deployment,\n",
    "}\n",
    "\n",
    "# JSON mode supported model preferred to avoid errors ex. gpt-4o-mini, gpt-4o, gpt-4 (1106)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to your Azure Search index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_endpoint = \"<your-search-endpoint>\"\n",
    "index_name = \"<your-index-name>\"\n",
    "api_key = \"<your-api-key>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us connect to the project. DefaultAzureCredentails will be picked up by the SDK which runs the prompty files to authenticate your requests. If you want to use your AzureOpenAI key to authenticate, you can do so by setting the `api_key` in your `model_config`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.evaluation.simulator import Simulator\n",
    "\n",
    "simulator = Simulator(model_config=model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connecting the simulator to your application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any, Optional\n",
    "from openai import AzureOpenAI\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "\n",
    "\n",
    "def call_to_your_ai_application(query: str) -> str:\n",
    "    # logic to call your application\n",
    "    # use a try except block to catch any errors\n",
    "\n",
    "    token_provider = get_bearer_token_provider(DefaultAzureCredential(), \"https://cognitiveservices.azure.com/.default\")\n",
    "    deployment = os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\")\n",
    "    endpoint = os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    client = AzureOpenAI(\n",
    "        azure_endpoint=endpoint,\n",
    "        api_version=os.environ.get(\"AZURE_OPENAI_API_VERSION\"),\n",
    "        azure_ad_token_provider=token_provider,\n",
    "    )\n",
    "    completion = client.chat.completions.create(\n",
    "        model=deployment,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query,\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=800,\n",
    "        temperature=0.7,\n",
    "        top_p=0.95,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None,\n",
    "        stream=False,\n",
    "    )\n",
    "    message = completion.to_dict()[\"choices\"][0][\"message\"]\n",
    "    # change this to return the response from your application\n",
    "    return message[\"content\"]\n",
    "\n",
    "\n",
    "async def callback(\n",
    "    messages: List[Dict],\n",
    "    stream: bool = False,\n",
    "    session_state: Any = None,  # noqa: ANN401\n",
    "    context: Optional[Dict[str, Any]] = None,\n",
    ") -> dict:\n",
    "    messages_list = messages[\"messages\"]\n",
    "    # get last message\n",
    "    latest_message = messages_list[-1]\n",
    "    query = latest_message[\"content\"]\n",
    "    context = None\n",
    "    # call your endpoint or ai application here\n",
    "    response = call_to_your_ai_application(query)\n",
    "    # we are formatting the response to follow the openAI chat protocol format\n",
    "    formatted_response = {\n",
    "        \"content\": response,\n",
    "        \"role\": \"assistant\",\n",
    "        \"context\": {\n",
    "            \"citations\": None,\n",
    "        },\n",
    "    }\n",
    "    messages[\"messages\"].append(formatted_response)\n",
    "    return {\"messages\": messages[\"messages\"], \"stream\": stream, \"session_state\": session_state, \"context\": context}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Generate Query Responses from index\n",
    "In this example we use the `description` field from the `realestate-us-sample-index` search index as raw text to generate Query Response pairs. For any index you use to generate Query Responses, you must identify from which field from `result` in the code below you would like to generate.\n",
    "\n",
    "\n",
    "Below is what a search for the term `New York` might return:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"@odata.context\": \"https://<your-search-service-name>.search.windows.net/indexes('realestate-us-sample-index')/$metadata#docs(*)\",\n",
    "  \"@odata.count\": 4959,\n",
    "  \"@search.nextPageParameters\": {\n",
    "    \"search\": \"*\",\n",
    "    \"count\": true,\n",
    "    \"skip\": 50\n",
    "  },\n",
    "  \"value\": [\n",
    "    {\n",
    "      \"@search.score\": 1,\n",
    "      \"listingId\": \"OTM4MjI2NQ2\",\n",
    "      \"beds\": 5,\n",
    "      \"baths\": 4,\n",
    "      \"description\": \"This is a apartment residence and is perfect for entertaining.  This home provides lakefront property located close to parks and features a detached garage, beautiful bedroom floors and lots of storage.\",\n",
    "      \"description_de\": \"Dies ist eine Wohnanlage und ist perfekt für Unterhaltung.  Dieses Haus bietet Seeliegenschaft Parks in der Nähe und verfügt über eine freistehende Garage schöne Zimmer-Etagen and viel Stauraum.\",\n",
    "      \"description_fr\": \"Il s’agit d’un appartement de la résidence et est parfait pour se divertir.  Cette maison offre propriété au bord du lac Situé à proximité de Parcs et dispose d’un garage détaché, planchers de belle chambre and beaucoup de rangement.\",\n",
    "      \"description_it\": \"Si tratta di un appartamento residence ed è perfetto per intrattenere.  Questa casa fornisce proprietà lungolago Situato vicino ai parchi e dispone di un garage indipendente, piani di bella camera da letto and sacco di stoccaggio.\",\n",
    "      \"description_es\": \"Se trata de una residencia Apartamento y es perfecto para el entretenimiento.  Esta casa ofrece propiedad de lago situado cerca de parques y cuenta con un garaje independiente, pisos de dormitorio hermoso and montón de almacenamiento.\",\n",
    "      \"description_pl\": \"Jest to apartament residence i jest idealny do zabawy.  Ten dom zapewnia lakefront Wlasciwosc usytuowany w poblizu parków i oferuje garaz wolnostojacy, piekna sypialnia podlogi and mnóstwo miejsca do przechowywania.\",\n",
    "      \"description_nl\": \"Dit is een appartement Residentie en is perfect voor entertaining.  Dit huis biedt lakefront eigenschap vlakbij parken en beschikt over een vrijstaande garage, mooie slaapkamer vloeren and veel opslag.\",\n",
    "      \"sqft\": 12960,\n",
    "      \"daysOnMarket\": 9,\n",
    "      \"status\": \"sold\",\n",
    "      \"source\": \"Pérez Realty\",\n",
    "      \"number\": \"19339\",\n",
    "      \"street\": \"Linden Avenue North\",\n",
    "      \"unit\": \"658\",\n",
    "      \"type\": \"Apartment\",\n",
    "      \"city\": \"Shoreline\",\n",
    "      \"region\": \"wa\",\n",
    "      \"countryCode\": \"us\",\n",
    "      \"postCode\": \"98133\",\n",
    "      \"location\": {\n",
    "        \"type\": \"Point\",\n",
    "        \"coordinates\": [\n",
    "          -122.35,\n",
    "          47.7699\n",
    "        ],\n",
    "        \"crs\": {\n",
    "          \"type\": \"name\",\n",
    "          \"properties\": {\n",
    "            \"name\": \"EPSG:4326\"\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"price\": 3693600,\n",
    "      \"thumbnail\": \"https://searchdatasets.blob.core.windows.net/images/bd5bt4apt.jpg\",\n",
    "      \"tags\": [\n",
    "        \"apartment residence\",\n",
    "        \"entertaining\",\n",
    "        \"lakefront property\",\n",
    "        \"parks\",\n",
    "        \"detached garage\",\n",
    "        \"beautiful bedroom floors\",\n",
    "        \"lots of storage\"\n",
    "      ]\n",
    "    },\n",
    "    ...\n",
    "  ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "def generate_text_from_index(search_term: str) -> str:\n",
    "    url = f\"{search_endpoint}/indexes/{index_name}/docs/search?api-version=2024-07-01\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    search_query = {\"search\": search_term, \"top\": 10}\n",
    "    response = requests.post(url=url, headers=headers, data=json.dumps(search_query))\n",
    "\n",
    "    text = \"\"\n",
    "    if response.status_code == 200:\n",
    "        results = response.json()\n",
    "        for result in results[\"value\"]:\n",
    "            text += result[\"description\"]\n",
    "\n",
    "    return text[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_estate_search_term = \"New York\"\n",
    "text = generate_text_from_index(real_estate_search_term)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call to simulator\n",
    "This call to the simulator generates 4 query response pairs in its first pass.\n",
    "In the second pass, it picks up one task, pairs it with a query (generated in previous pass) and sends it to the configured llm to build the first user turn. This user turn is then passed to the `callback` method. The conversation continutes till the `max_conversation_turns` turns.\n",
    "\n",
    "The output of the simulator will have the original task, original query, the original query and the response generated from the first turn as expected response. You can find them in the `context` key of the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = await simulator(\n",
    "    target=callback,\n",
    "    text=text,\n",
    "    num_queries=4,\n",
    "    max_conversation_turns=3,\n",
    "    tasks=[\n",
    "        f\"I am a prospective buyer and I want to learn more about {real_estate_search_term}\",\n",
    "        f\"I am a real estate agent and I want to inform potential buyers about {real_estate_search_term}\",\n",
    "        f\"I am a researcher and I want to do a detailed research on {real_estate_search_term}\",\n",
    "        f\"I am a statistician and I want to do a detailed table of factual data concerning {real_estate_search_term}\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the generated data for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = Path(\"output.json\")\n",
    "with output_file.open(\"a\") as f:\n",
    "    json.dump(outputs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up\n",
    "\n",
    "To clean up all Azure ML resources used in this example, you can delete the individual resources you created in this tutorial.\n",
    "\n",
    "If you made a resource group specifically to run this example, you could instead [delete the resource group](https://learn.microsoft.com/en-us/azure/azure-resource-manager/management/delete-resource-group)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "notebook_template.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
