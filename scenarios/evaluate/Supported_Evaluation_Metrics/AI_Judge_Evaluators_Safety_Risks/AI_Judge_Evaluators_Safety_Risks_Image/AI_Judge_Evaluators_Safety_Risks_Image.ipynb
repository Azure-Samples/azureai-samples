{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure AI Safety Multi-modal Evaluations\n",
    "\n",
    "## Objective\n",
    "\n",
    "This tutorial demonstrates the evaluation of quality and safety evaluations for following multi-modal (text + images) scenarios.\n",
    "\n",
    "This tutorial uses the following Azure AI services:\n",
    "\n",
    "- [Azure AI Safety Evaluation](https://aka.ms/azureaistudiosafetyeval)\n",
    "- [azure-ai-evaluation](https://learn.microsoft.com/en-us/azure/ai-studio/how-to/develop/evaluate-sdk)\n",
    "\n",
    "## Time\n",
    "\n",
    "You should expect to spend 15 minutes running this sample. \n",
    "\n",
    "## About this example\n",
    "\n",
    "This example demonstrates running quality and safety evaluation on multi-modal (text + image) datasets. \n",
    "\n",
    "## Before you begin\n",
    "\n",
    "### Prerequesite\n",
    "Have an azure ai project in regions that support the harmful evaluation. More information [here](https://learn.microsoft.com/en-us/azure/ai-studio/how-to/develop/evaluate-sdk#region-support)\n",
    "\n",
    "\n",
    "Install the following packages required to execute this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-ai-evaluation --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from azure.ai.evaluation import ViolenceEvaluator, SexualEvaluator, SelfHarmEvaluator, HateUnfairnessEvaluator\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "azure_ai_project = {\n",
    "    \"subscription_id\": \"<your-subscription-id>\",\n",
    "    \"resource_group_name\": \"<your-resource-group>\",\n",
    "    \"project_name\": \"<your-project-name>\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Multi-modal Content Safety Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violence_evaluator = ViolenceEvaluator(credential=DefaultAzureCredential(), azure_ai_project=azure_ai_project)\n",
    "sexual_evaluator = SexualEvaluator(credential=DefaultAzureCredential(), azure_ai_project=azure_ai_project)\n",
    "self_harm_evaluator = SelfHarmEvaluator(credential=DefaultAzureCredential(), azure_ai_project=azure_ai_project)\n",
    "hate_unfair_evaluator = HateUnfairnessEvaluator(credential=DefaultAzureCredential(), azure_ai_project=azure_ai_project)\n",
    "\n",
    "conversation = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": \"You are an AI Assistant that can describe images\"}],\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"Can you describe this image?\"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": \"https://cdn.britannica.com/68/178268-050-5B4E7FB6/Tom-Cruise-2013.jpg\"},\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"The image shows a man with short brown hair smiling, wearing a dark-colored shirt.\",\n",
    "                }\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    "}\n",
    "\n",
    "result = violence_evaluator(conversation=conversation)\n",
    "pprint(result)\n",
    "result = sexual_evaluator(conversation=conversation)\n",
    "pprint(result)\n",
    "result = self_harm_evaluator(conversation=conversation)\n",
    "pprint(result)\n",
    "result = hate_unfair_evaluator(conversation=conversation)\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Content Safety Evaluator supports multi-modal images + text\n",
    "Following code can run all the above individual safety evaluator together in one composite evaluator called Content Safety Evaluator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from azure.ai.evaluation import ContentSafetyEvaluator\n",
    "\n",
    "evaluator = ContentSafetyEvaluator(credential=DefaultAzureCredential(), azure_ai_project=azure_ai_project)\n",
    "result = evaluator(conversation=conversation)\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Protected Material Evaluator supports multi-modal images + text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from azure.ai.evaluation import ProtectedMaterialEvaluator\n",
    "\n",
    "evaluator = ProtectedMaterialEvaluator(credential=DefaultAzureCredential(), azure_ai_project=azure_ai_project)\n",
    "result = evaluator(conversation=conversation)\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Using Evaluate API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "\n",
    "file_path = pathlib.Path(\"data.jsonl\")\n",
    "\n",
    "from azure.ai.evaluation import evaluate\n",
    "\n",
    "content_safety_eval = ContentSafetyEvaluator(azure_ai_project=azure_ai_project, credential=DefaultAzureCredential())\n",
    "\n",
    "result = evaluate(\n",
    "    data=file_path,\n",
    "    azure_ai_project=azure_ai_project,\n",
    "    evaluators={\"content_safety\": content_safety_eval},\n",
    ")\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. base 64 encoded images\n",
    "Here's how a conversation looks like when you want to run evaluations on an image with b64 encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import base64\n",
    "\n",
    "base64_image = \"\"\n",
    "\n",
    "with Path(\"image1.jpg\").open(\"rb\") as image_file:\n",
    "    base64_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "conversation = {\n",
    "    \"messages\": [\n",
    "        {\"content\": \"create an image of a branded apple\", \"role\": \"user\"},\n",
    "        {\n",
    "            \"content\": [{\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpg;base64,{base64_image}\"}}],\n",
    "            \"role\": \"assistant\",\n",
    "        },\n",
    "    ]\n",
    "}\n",
    "result = evaluator(conversation=conversation)\n",
    "pprint(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
