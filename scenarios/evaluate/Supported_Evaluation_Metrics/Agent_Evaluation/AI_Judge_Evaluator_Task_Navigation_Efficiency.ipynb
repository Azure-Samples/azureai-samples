{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28c2bc93",
   "metadata": {},
   "source": [
    "# Task Navigation Efficiency Evaluator\n",
    "\n",
    "## Objective\n",
    "This sample demonstrates how to use task navigation efficiency evaluator on agent data. The supported input formats include:\n",
    "- simple data such as strings and `dict` describing task responses;\n",
    "- user-agent conversations in the form of list of agent messages. \n",
    "\n",
    "## Time\n",
    "\n",
    "You should expect to spend about 20 minutes running this notebook. \n",
    "\n",
    "## Before you begin\n",
    "This is a deterministic evaluator that compares navigation paths.\n",
    "\n",
    "### Prerequisite\n",
    "```bash\n",
    "pip install azure-ai-projects azure-identity openai\n",
    "```\n",
    "Set these environment variables with your own values:\n",
    "1) **AZURE_AI_PROJECT_ENDPOINT** - Your Azure AI project endpoint in format: `https://<account_name>.services.ai.azure.com/api/projects/<project_name>`\n",
    "2) **AZURE_AI_MODEL_DEPLOYMENT_NAME** - The deployment name of the model for this AI-assisted evaluator (e.g., gpt-4o-mini)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61cd511",
   "metadata": {},
   "source": [
    "The Task Navigation Efficiency Evaluator measures how efficiently an agent navigates through a sequence of actions compared to an optimal task completion path.\n",
    "\n",
    "The evaluator provides comprehensive evaluation with both binary matching results and additional detailed P\\R\\F1 results:\n",
    "\n",
    "**Primary Result:**\n",
    "- **Binary Match Result**: Pass/Fail based on the selected matching mode\n",
    "\n",
    "**Available Matching Modes:**\n",
    "- **Exact Match**: Agent's tool calls must exactly match the ground truth (default)\n",
    "- **In-Order Match**: All ground truth steps must appear in correct order (allows extra steps)\n",
    "- **Any-Order Match**: All ground truth steps must appear with sufficient frequency (most lenient)\n",
    "\n",
    "**Properties Bag Additional Metrics (0.0 - 1.0):**\n",
    "- **Precision**: How many of the agent's steps were necessary (relevant to ground truth)\n",
    "- **Recall**: How many of the required steps were executed by the agent  \n",
    "- **F1 Score**: Harmonic mean of precision and recall\n",
    "\n",
    "The evaluation requires the following inputs:\n",
    "- **Response**: The agent's response containing tool calls as a list of messages or string\n",
    "- **Ground Truth**: List of expected tool/action steps as strings, or tuple with parameters for matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4e0a1d",
   "metadata": {},
   "source": [
    "### Initialize Task Navigation Efficiency Evaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3726cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai.types.evals.create_eval_jsonl_run_data_source_param import SourceFileContentContent\n",
    "from pprint import pprint\n",
    "from agent_utils import run_evaluator\n",
    "\n",
    "# Get environment variables\n",
    "deployment_name = os.environ[\"AZURE_AI_MODEL_DEPLOYMENT_NAME\"]\n",
    "\n",
    "# Data source configuration (defines the schema for evaluation inputs)\n",
    "data_source_config = {\n",
    "    \"type\": \"custom\",\n",
    "    \"item_schema\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"response\": {\n",
    "                \"type\": \"array\"\n",
    "            },\n",
    "            \"ground_truth\": {\n",
    "                \"type\": \"array\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"response\", \"ground_truth\"]\n",
    "    },\n",
    "    \"include_sample_schema\": True\n",
    "}\n",
    "\n",
    "# Data mapping (maps evaluation inputs to evaluator parameters)\n",
    "data_mapping = {\n",
    "    \"response\": \"{{item.response}}\",\n",
    "    \"ground_truth\": \"{{item.ground_truth}}\"\n",
    "}\n",
    "\n",
    "# Initialization parameters for the evaluator\n",
    "initialization_parameters = {\n",
    "    \"matching_mode\": \"exact_match\"  # Can be \"exact_match\", \"in_order_match\", or \"any_order_match\"\n",
    "}\n",
    "\n",
    "# Initialize the evaluation_contents list - we'll append all test cases here\n",
    "evaluation_contents = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a53227",
   "metadata": {},
   "source": [
    "### Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d75457a",
   "metadata": {},
   "source": [
    "#### Sample 1: Perfect Path (Exact Match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cae15fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Case 1: Perfect Path (Exact Match) - Agent follows the exact optimal path\n",
    "response_perfect = [\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [{\"type\": \"tool_call\", \"tool_call_id\": \"call_1\", \"name\": \"search\", \"arguments\": {}}],\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\", \n",
    "        \"content\": [{\"type\": \"tool_call\", \"tool_call_id\": \"call_2\", \"name\": \"analyze\", \"arguments\": {}}],\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [{\"type\": \"tool_call\", \"tool_call_id\": \"call_3\", \"name\": \"report\", \"arguments\": {}}],\n",
    "    },\n",
    "]\n",
    "\n",
    "ground_truth_perfect = [\"search\", \"analyze\", \"report\"]\n",
    "\n",
    "# Append to evaluation_contents\n",
    "evaluation_contents.append(\n",
    "    SourceFileContentContent(\n",
    "        item={\n",
    "            \"response\": response_perfect,\n",
    "            \"ground_truth\": ground_truth_perfect\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9c5e69",
   "metadata": {},
   "source": [
    "#### Sample 2: Efficient Path with Extra Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53dde31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Case 2: Path with Extra Steps - Agent performs all required steps but with extra unnecessary step\n",
    "response_extra = [\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [{\"type\": \"tool_call\", \"tool_call_id\": \"call_1\", \"name\": \"search\", \"arguments\": {}}],\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [{\"type\": \"tool_call\", \"tool_call_id\": \"call_2\", \"name\": \"validate\", \"arguments\": {}}],\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\", \n",
    "        \"content\": [{\"type\": \"tool_call\", \"tool_call_id\": \"call_3\", \"name\": \"analyze\", \"arguments\": {}}],\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [{\"type\": \"tool_call\", \"tool_call_id\": \"call_4\", \"name\": \"report\", \"arguments\": {}}],\n",
    "    },\n",
    "]\n",
    "\n",
    "ground_truth_extra = [\"search\", \"analyze\", \"report\"]\n",
    "\n",
    "# Append to evaluation_contents\n",
    "evaluation_contents.append(\n",
    "    SourceFileContentContent(\n",
    "        item={\n",
    "            \"response\": response_extra,\n",
    "            \"ground_truth\": ground_truth_extra\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fa5757",
   "metadata": {},
   "source": [
    "#### Sample 3: Inefficient Path (Wrong Order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2226715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Case 3: Wrong Order - Agent performs all required steps but in wrong order\n",
    "response_wrong_order = [\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [{\"type\": \"tool_call\", \"tool_call_id\": \"call_1\", \"name\": \"report\", \"arguments\": {}}],\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [{\"type\": \"tool_call\", \"tool_call_id\": \"call_2\", \"name\": \"search\", \"arguments\": {}}],\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\", \n",
    "        \"content\": [{\"type\": \"tool_call\", \"tool_call_id\": \"call_3\", \"name\": \"analyze\", \"arguments\": {}}],\n",
    "    },\n",
    "]\n",
    "\n",
    "ground_truth_wrong_order = [\"search\", \"analyze\", \"report\"]\n",
    "\n",
    "# Append to evaluation_contents\n",
    "evaluation_contents.append(\n",
    "    SourceFileContentContent(\n",
    "        item={\n",
    "            \"response\": response_wrong_order,\n",
    "            \"ground_truth\": ground_truth_wrong_order\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae74ac8e",
   "metadata": {},
   "source": [
    "#### Sample 4: Incomplete Path (Missing Steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd95640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Case 4: Missing Steps - Agent performs only some of the required steps (incomplete)\n",
    "response_missing = [\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [{\"type\": \"tool_call\", \"tool_call_id\": \"call_1\", \"name\": \"search\", \"arguments\": {}}],\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [{\"type\": \"tool_call\", \"tool_call_id\": \"call_2\", \"name\": \"analyze\", \"arguments\": {}}],\n",
    "    },\n",
    "]\n",
    "\n",
    "ground_truth_missing = [\"search\", \"analyze\", \"report\"]\n",
    "\n",
    "# Append to evaluation_contents\n",
    "evaluation_contents.append(\n",
    "    SourceFileContentContent(\n",
    "        item={\n",
    "            \"response\": response_missing,\n",
    "            \"ground_truth\": ground_truth_missing\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9111ef",
   "metadata": {},
   "source": [
    "#### Sample 5: Real-World Customer Service Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bd7b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Case 5: Customer Service Scenario - Real-world example: Customer service agent handling a refund request\n",
    "response_service = [\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [{\"type\": \"tool_call\", \"tool_call_id\": \"call_1\", \"name\": \"lookup_order\", \"arguments\": {\"order_id\": \"12345\"}}],\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [{\"type\": \"tool_call\", \"tool_call_id\": \"call_2\", \"name\": \"check_inventory\", \"arguments\": {\"product_id\": \"ABC123\"}}],\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\", \n",
    "        \"content\": [{\"type\": \"tool_call\", \"tool_call_id\": \"call_3\", \"name\": \"calculate_refund\", \"arguments\": {\"order_id\": \"12345\"}}],\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [{\"type\": \"tool_call\", \"tool_call_id\": \"call_4\", \"name\": \"process_refund\", \"arguments\": {\"order_id\": \"12345\", \"amount\": \"29.99\"}}],\n",
    "    },\n",
    "]\n",
    "\n",
    "ground_truth_service = [\"lookup_order\", \"check_inventory\", \"calculate_refund\", \"process_refund\"]\n",
    "\n",
    "# Append to evaluation_contents\n",
    "evaluation_contents.append(\n",
    "    SourceFileContentContent(\n",
    "        item={\n",
    "            \"response\": response_service,\n",
    "            \"ground_truth\": ground_truth_service\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf2e0ee",
   "metadata": {},
   "source": [
    "#### Sample 6: Complex Path with Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dcf585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Case 6: Complex Path with Duplicates - Agent repeats some steps and includes extra ones\n",
    "response_duplicates = [\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [{\"type\": \"tool_call\", \"tool_call_id\": \"call_1\", \"name\": \"search\", \"arguments\": {}}],\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [{\"type\": \"tool_call\", \"tool_call_id\": \"call_2\", \"name\": \"search\", \"arguments\": {}}],  # duplicate\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [{\"type\": \"tool_call\", \"tool_call_id\": \"call_4\", \"name\": \"analyze\", \"arguments\": {}}],\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [{\"type\": \"tool_call\", \"tool_call_id\": \"call_5\", \"name\": \"report\", \"arguments\": {}}],\n",
    "    },\n",
    "]\n",
    "\n",
    "ground_truth_duplicates = [\"search\", \"analyze\", \"report\"]\n",
    "\n",
    "# Append to evaluation_contents\n",
    "evaluation_contents.append(\n",
    "    SourceFileContentContent(\n",
    "        item={\n",
    "            \"response\": response_duplicates,\n",
    "            \"ground_truth\": ground_truth_duplicates\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478c00fb",
   "metadata": {},
   "source": [
    "#### Sample 7: Tuple Format with Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7404f830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Case 7: Tuple Format with Parameters - Supports exact parameter matching\n",
    "response_params = [\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [{\"type\": \"tool_call\", \"tool_call_id\": \"call_1\", \"name\": \"search\", \"arguments\": {\"query\": \"test\"}}],\n",
    "    },\n",
    "]\n",
    "\n",
    "# Ground truth using tuple format: (tool_names, parameters_dict)\n",
    "# Parameters must match exactly for tools to be considered matching\n",
    "ground_truth_params = [[\"search\"], {\"search\": {\"query\": \"test\"}}]\n",
    "\n",
    "# Append to evaluation_contents\n",
    "evaluation_contents.append(\n",
    "    SourceFileContentContent(\n",
    "        item={\n",
    "            \"response\": response_params,\n",
    "            \"ground_truth\": ground_truth_params\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a11522",
   "metadata": {},
   "source": [
    "### Execute Batch Evaluation\n",
    "Run all test cases together using the batch evaluation approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1185d9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_evaluator(\n",
    "    evaluator_name=\"task_navigation_efficiency\",\n",
    "    evaluation_contents=evaluation_contents,\n",
    "    data_source_config=data_source_config,\n",
    "    initialization_parameters=initialization_parameters,\n",
    "    data_mapping=data_mapping\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed16d6c",
   "metadata": {},
   "source": [
    "### Results Display\n",
    "Display the evaluation results for each test case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c0bd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "samples",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
