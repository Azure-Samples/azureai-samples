{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f372fc3-d2ad-49a8-87da-e3b092b6b5ae",
   "metadata": {},
   "source": [
    "# Document Retrieval Evaluation in Azure AI Foundry\n",
    "\n",
    "## Summary\n",
    "This notebook sample demonstrates how to perform evaluation of an Azure AI Search index using Azure AI Evaluation.  The evaluator used in this example, `DocumentRetrievalEvaluator` requires a list of ground truth labeled documents (sometimes referred to as \"qrels\") and a list of actual search results obtained from a search index as inputs for calculating the evaluation metrics.  This sample will walk through the steps of data preparation, gathering search results for different search configurations, running evaluation and comparing results of each run.\n",
    "\n",
    "### Explanation of Document Retrieval Metrics \n",
    "The metrics that will be generated in the output of the evaluator include:\n",
    "| Metric               | Category            | Description                                                                                     |\n",
    "|-----------------------|---------------------|-------------------------------------------------------------------------------------------------|\n",
    "| Fidelity             | Search Fidelity    | How well the top n retrieved chunks reflect the content for a given query; number of good documents returned out of the total number of known good documents in a dataset |\n",
    "| NDCG                 | Search NDCG        | How good are the rankings to an ideal order where all relevant items are at the top of the list.        |\n",
    "| XDCG                 | Search XDCG        | How good the results are in the top-k documents regardless of scoring of other index documents |\n",
    "| Max Relevance N      | Search Max Relevance | Maximum relevance in the top-k chunks                                                          |\n",
    "| Holes      | Search Label Sanity | Number of documents with missing query relevance judgments (Ground truth) |\n",
    "\n",
    "It's important to note that some metrics, particularly NDCG, XDCG and Fidelity, are sensitive to holes.  Ideally the count of holes for a given evaluation should be zero, otherwise results for these metrics may not be accurate.  It is recommended to iteratively check results against current known ground truth to fill holes to improve accuracy of the evaluation metrics.  This process is not covered explicitly in the sample but is important to mention."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de22faf1-878a-4619-aaf0-e26a05a19867",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c33b6e-be25-4331-a6ca-8156fe6c11b2",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "Before running this notebook, be sure you have fulfilled the following prerequisites:\n",
    "* Create or get access to an [Azure Subscription](https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/ready/azure-best-practices/initial-subscriptions), and assign yourself the Owner or Contributor role for creating resources in this subscription.\n",
    "* `az` CLI is installed in the current environment, and you have run `az login` to gain access to your resources.\n",
    "* Read and understand the documentation covering [assigning RBAC roles between resources](https://learn.microsoft.com/en-us/azure/role-based-access-control/role-assignments-cli) using the `az` CLI.\n",
    "* Create [Azure AI Search resource](https://learn.microsoft.com/en-us/azure/search/search-create-service-portal), and assign yourself the \"Search Index Data Contributor\" role for the resource.  \n",
    "* Create an [Azure AI Foundry project](https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/create-projects?tabs=ai-studio).\n",
    "* [Optional] Deploy a text embedding model in the Azure AI Foundry project for testing vector-based search scenarios in this example, and assign yourself the \"Cognitive Services OpenAI User\" role for the Azure AI Services resource created for your project.  For integrated vectorization support, you will also need to ensure that your Azure AI Search resource has the \"Cognitive Services OpenAI User\" role assigned for the Azure AI Services resource as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7da7c8c-e0bb-47d0-9f1e-72e1e545f95f",
   "metadata": {},
   "source": [
    "### Install Python requirements\n",
    "Run the following command to install the python requirements for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0137b5aa-9837-4d74-b9a3-96b36e6c301a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt\n",
    "!pip freeze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e452701f-1faa-4715-8bd9-ad5a4231bd6f",
   "metadata": {},
   "source": [
    "### Import all modules\n",
    "For convenience, all modules needed for the rest of the notebook can be imported all at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba11028d-33ca-49e9-b106-86f0e4316182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import json\n",
    "import logging\n",
    "import pathlib, os\n",
    "import pandas as pd\n",
    "import random\n",
    "import string\n",
    "import time\n",
    "\n",
    "# Azure SDK\n",
    "from azure.ai.evaluation import DocumentRetrievalEvaluator\n",
    "from azure.ai.projects.models import (\n",
    "    Dataset,\n",
    "    Evaluation,\n",
    "    EvaluatorConfiguration,\n",
    ")\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizedQuery, VectorizableTextQuery\n",
    "from azure.search.documents.indexes.models import (\n",
    "    ComplexField,\n",
    "    SearchIndex,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SemanticConfiguration,\n",
    "    SemanticField,\n",
    "    SemanticPrioritizedFields,\n",
    "    SemanticSearch,\n",
    "    VectorSearch,\n",
    "    VectorSearchProfile,\n",
    "    VectorSearchAlgorithmConfiguration,\n",
    "    AzureOpenAIVectorizer,\n",
    "    AzureOpenAIVectorizerParameters,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    HnswParameters\n",
    ")\n",
    "\n",
    "# Other open source packages\n",
    "from dotenv import load_dotenv\n",
    "from beir import util, LoggingHandler\n",
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "from openai import AzureOpenAI\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa63828-44da-4b4a-9270-ac31288d9477",
   "metadata": {},
   "source": [
    "### Load resource connection configuration\n",
    "The following cell will load the necessary resource connection configuration for the sample. Copy the contents of `.env.sample` into a new file named `.env`, and fill in the values corresponding to your own service resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c802f08c-0423-49bc-a7b3-389e9628fd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12d8a40-8a00-4979-9400-9b36ed9a6ee5",
   "metadata": {},
   "source": [
    "### Create client objects for managing resources and set other helpful variables\n",
    "We will also create all of the client objects and other variables needed for the rest of the notebook in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aab177-5a0b-48b8-b721-62d9197cc1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Azure AI Search service clients\n",
    "search_service_endpoint = os.environ[\"AZURE_AI_SEARCH_ENDPOINT\"]\n",
    "search_service_key = os.environ[\"AZURE_AI_SEARCH_KEY\"]\n",
    "index_name = \"trec-covid-vector\"\n",
    "\n",
    "if not search_service_key:\n",
    "    search_credential = DefaultAzureCredential()\n",
    "\n",
    "else:\n",
    "    search_credential = AzureKeyCredential(search_service_key)\n",
    "    \n",
    "search_index_client = SearchIndexClient(search_service_endpoint, search_credential)\n",
    "search_client = SearchClient(search_service_endpoint, index_name, search_credential)\n",
    "\n",
    "# Create the Azure AI Project client\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    conn_str=os.environ[\"AZURE_PROJECT_CONNECTION_STRING\"]\n",
    ")\n",
    "\n",
    "# Set other helpful variables\n",
    "data_directory = os.path.join(\".\", \"beir\")\n",
    "data_ids = None\n",
    "\n",
    "# search parameters\n",
    "search_top_k = 50\n",
    "search_select = \"doc_id\"\n",
    "\n",
    "# vector search parameters, if using vector search\n",
    "vector_field_name = \"title_text_ada002\"\n",
    "search_vectorizer_endpoint = os.environ[\"AZURE_AI_SEARCH_VECTORIZER_ENDPOINT\"]\n",
    "search_vectorizer_key = os.environ[\"AZURE_AI_SEARCH_VECTORIZER_KEY\"]\n",
    "search_vectorizer_model_name = os.environ[\"AZURE_AI_SEARCH_VECTORIZER_MODEL_NAME\"]\n",
    "search_vectorizer_deployment_name = os.environ[\"AZURE_AI_SEARCH_VECTORIZER_DEPLOYMENT_NAME\"]\n",
    "search_vectorizer_model_dimensions = os.environ[\"AZURE_AI_SEARCH_VECTORIZER_MODEL_DIMENSIONS\"]\n",
    "use_integrated_vectorization = (search_vectorizer_endpoint and \\\n",
    "                                search_vectorizer_key and \\\n",
    "                                search_vectorizer_model_name and \\\n",
    "                                search_vectorizer_deployment_name and \\\n",
    "                                search_vectorizer_model_dimensions)\n",
    "doc_chunk_size = 1024 if use_integrated_vectorization else None\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "aoai_client = None\n",
    "if use_integrated_vectorization:\n",
    "    print(\"Creating AOAI client for vectorizing index data\")\n",
    "    ad_token_provider = get_bearer_token_provider(\n",
    "        DefaultAzureCredential(),\n",
    "        \"https://cognitiveservices.azure.com/.default\"\n",
    "    )\n",
    "    aoai_client = AzureOpenAI(\n",
    "        azure_endpoint=search_vectorizer_endpoint,\n",
    "        api_version=\"2024-06-01\",\n",
    "        azure_ad_token_provider=ad_token_provider\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f00d41-7174-41bd-96ae-8690d409f565",
   "metadata": {},
   "source": [
    "### Create search configurations\n",
    "In the next cell, we will set some additional configuration values for configuring document search using Azure AI Search.  We can select from these configurations later on when we generate search results for evaluation, and then compare the results of each run after the evaluations are finished to determine which configuration performs best for the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597f3f3d-139c-44e2-bedc-9dda79fe15c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full-text search\n",
    "text_search_configuration = {\n",
    "    \"name\": \"text\",\n",
    "    \"query_language\": \"en\",\n",
    "    \"select\": search_select,\n",
    "    \"top\": search_top_k,\n",
    "    \"api_version\": \"2024-11-01-preview\",\n",
    "    \"score_field\": \"@search.score\"\n",
    "}\n",
    "\n",
    "# Semantic search\n",
    "semantic_search_configuration = {\n",
    "    \"name\": \"semantic\",\n",
    "    \"query_type\": \"semantic\",\n",
    "    \"select\": search_select,\n",
    "    \"top\": search_top_k,\n",
    "    \"semantic_configuration_name\": \"en-semantic-config\",\n",
    "    \"query_language\": \"en\",\n",
    "    \"api_version\": \"2024-11-01-preview\",\n",
    "    \"score_field\": \"@search.reranker_score\"\n",
    "}\n",
    "\n",
    "# Vector search -- requires setting values for environment variables AZURE_AI_SEARCH_VECTORIZER_ENDPOINT, AZURE_AI_SEARCH_VECTORIZER_KEY, and\n",
    "# AZURE_AI_SEARCH_VECTORIZER_MODEL\n",
    "vector_search_configuration = {\n",
    "    \"name\": \"vector\",\n",
    "    \"select\": search_select,\n",
    "    \"top\": search_top_k,\n",
    "    \"vector_queries\": [\n",
    "        {\n",
    "            \"kind\": \"text\",\n",
    "            \"fields\": vector_field_name,\n",
    "            \"k_nearest_neighbors\": search_top_k\n",
    "        }\n",
    "    ],\n",
    "    \"score_field\": \"@search.score\"\n",
    "}\n",
    "\n",
    "# Semantic vector hybrid search\n",
    "semantic_vector_hybrid_search_configuration = {\n",
    "    \"name\": \"hybrid\",\n",
    "    \"query_type\": \"semantic\",\n",
    "    \"select\": search_select,\n",
    "    \"top\": search_top_k,\n",
    "    \"semantic_configuration_name\": \"en-semantic-config\",\n",
    "    \"vector_queries\": [\n",
    "        {\n",
    "            \"kind\": \"text\",\n",
    "            \"fields\": vector_field_name,\n",
    "            \"k_nearest_neighbors\": search_top_k\n",
    "        }\n",
    "    ],\n",
    "    \"score_field\": \"@search.score\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4618d1-0015-4cc4-a2bd-d77cd85184f9",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123a1864-dfb6-4d56-bac8-300712f50c17",
   "metadata": {},
   "source": [
    "### Download the TREC-COVID (Beir) dataset\n",
    "In the next cell, we will download an open source dataset to perform evaluation on. We will use the TREC-COVID dataset from BeIR, which contains a corpus we can index into Azure AI Search, as well as a set of queries to run through our search service and a set of ground truth qrels for evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be27e9bf-df26-426c-80c5-edb4a605fafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function was adapted from the original sample here:\n",
    "# https://github.com/beir-cellar/beir?tab=readme-ov-file#beers-quick-example\n",
    "\n",
    "def download_beir(dataset_name: str, output_directory: str):\n",
    "    #### Just some code to print debug information to stdout\n",
    "    logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "                        datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                        level=logging.INFO,\n",
    "                        handlers=[LoggingHandler()])\n",
    "\n",
    "    #### Download scifact.zip dataset and unzip the dataset\n",
    "    url = \"https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/{}.zip\".format(dataset_name)\n",
    "    out_dir = os.path.join(output_directory, \"datasets\")\n",
    "    data_path = util.download_and_unzip(url, out_dir)\n",
    "\n",
    "    #### Provide the data_path where scifact has been downloaded and unzipped\n",
    "    corpus, queries, qrels = GenericDataLoader(data_folder=data_path).load(split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15281a8-47c6-410f-8f0a-b28025b6cb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_beir(\"trec-covid\", data_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2b2e1e-4db7-45bc-98e2-bd5ee070d236",
   "metadata": {},
   "source": [
    "### Create an Azure AI Search index from the dataset corpus\n",
    "Next, we will create an Azure AI Search index using the BeIR TREC-COVID dataset downloaded in the previous cell.  If integrated vectorization is enabled in the configuration settings, we will also add a vector field for our index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2a9b8f-3dfd-4c9f-ba4e-e1bf95e8329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_or_update_index(search_index_client: SearchIndexClient):\n",
    "    fields = [\n",
    "        SearchField(\n",
    "            name=\"chunk_id\",\n",
    "            type=SearchFieldDataType.String,\n",
    "            key=True,\n",
    "            searchable=True,\n",
    "            hidden=False,\n",
    "            stored=True,\n",
    "            filterable=True,\n",
    "            sortable=True,\n",
    "            facetable=False,\n",
    "            analyzer_name=\"standard.lucene\"\n",
    "        ),\n",
    "        SearchField(\n",
    "            name=\"doc_id\",\n",
    "            type=SearchFieldDataType.String,\n",
    "            key=False,\n",
    "            searchable=True,\n",
    "            hidden=False,\n",
    "            stored=True,\n",
    "            filterable=True,\n",
    "            sortable=True,\n",
    "            facetable=False,\n",
    "            analyzer_name=\"standard.lucene\"\n",
    "        ),\n",
    "        SearchField(\n",
    "            name=\"title\",\n",
    "            type=SearchFieldDataType.String,\n",
    "            searchable=True,\n",
    "            hidden=False,\n",
    "            stored=True,\n",
    "            filterable=True,\n",
    "            sortable=False,\n",
    "            facetable=False,\n",
    "            analyzer_name=\"standard.lucene\"\n",
    "        ),\n",
    "        SearchField(\n",
    "            name=\"text\",\n",
    "            type=SearchFieldDataType.String,\n",
    "            searchable=True,\n",
    "            hidden=False,\n",
    "            stored=True,\n",
    "            filterable=True,\n",
    "            sortable=False,\n",
    "            facetable=False,\n",
    "            analyzer_name=\"standard.lucene\"\n",
    "        ),\n",
    "        ComplexField(\n",
    "            name=\"metadata\",\n",
    "            fields=[\n",
    "                SearchField(name=\"url\", type=SearchFieldDataType.String, searchable=True, hidden=False, stored=True, filterable=True, sortable=False, facetable=False, analyzer_name=\"standard.lucene\"),\n",
    "                SearchField(name=\"pubmed_id\", type=SearchFieldDataType.String, searchable=True, hidden=False, stored=True, filterable=True, sortable=False, facetable=False, analyzer_name=\"standard.lucene\")\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    "    semantic_prioritized_fields = SemanticPrioritizedFields(\n",
    "        title_field=SemanticField(field_name=\"title\"),\n",
    "        content_fields=[SemanticField(field_name=\"text\")],\n",
    "        keywords_fields=[SemanticField(field_name=\"metadata/url\")]\n",
    "    )\n",
    "    semantic_configuration = SemanticConfiguration(name=\"en-semantic-config\", prioritized_fields=semantic_prioritized_fields)\n",
    "    semantic_search = SemanticSearch(default_configuration_name=\"en-semantic-config\", configurations=[semantic_configuration])\n",
    "\n",
    "    vector_search = None\n",
    "    if use_integrated_vectorization:\n",
    "        algorithm = HnswAlgorithmConfiguration(\n",
    "            name=\"hnsw-1\",\n",
    "            parameters=HnswParameters(\n",
    "                m=4, ef_construction=400, ef_search=500, metric=\"cosine\"\n",
    "            )\n",
    "        )\n",
    "        vectorizer = AzureOpenAIVectorizer(\n",
    "            vectorizer_name=\"aoai-vectorizer-1\",\n",
    "            parameters=AzureOpenAIVectorizerParameters(\n",
    "                resource_url=search_vectorizer_endpoint,\n",
    "                deployment_name=search_vectorizer_deployment_name,\n",
    "                api_key=search_vectorizer_key,\n",
    "                model_name=search_vectorizer_deployment_name\n",
    "            )\n",
    "        )\n",
    "        profile = VectorSearchProfile(\n",
    "            name=\"vector-profile-1\",\n",
    "            algorithm_configuration_name=algorithm.name,\n",
    "            vectorizer_name=vectorizer.vectorizer_name\n",
    "        )\n",
    "        vector_search = VectorSearch(\n",
    "            profiles=[profile],\n",
    "            algorithms=[algorithm],\n",
    "            vectorizers=[vectorizer]\n",
    "        )\n",
    "        fields.append(\n",
    "            SearchField(\n",
    "                name=vector_field_name,\n",
    "                type=\"Collection(Edm.Single)\",\n",
    "                searchable=True,\n",
    "                hidden=True,\n",
    "                stored=False,\n",
    "                filterable=False,\n",
    "                sortable=False,\n",
    "                facetable=False,\n",
    "                vector_search_dimensions=search_vectorizer_model_dimensions,\n",
    "                vector_search_profile_name=profile.name\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    index = SearchIndex(name=index_name, fields=fields, semantic_search=semantic_search, vector_search=vector_search)\n",
    "\n",
    "    result = search_index_client.create_or_update_index(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce8dd13-c943-4ce6-b0e4-e309506d29a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_or_update_index(search_index_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc742f6-fbb4-4385-bceb-2ef54f0c291e",
   "metadata": {},
   "source": [
    "### Index the documents from the dataset corpus\n",
    "Once we have the data downloaded and the index created, we will ingest the documents from the local file into the index.  If integrated vectorization is configured, we will also create embeddings for the input data to include in the ingestion payload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c29fe3a-a63f-463e-a30c-dad772127df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(text, max_tokens):\n",
    "    tokens = tokenizer.encode(text)\n",
    "    chunks = []\n",
    "    startIndex = 0\n",
    "    while startIndex < len(tokens):\n",
    "        endIndex = startIndex + max_tokens\n",
    "        chunks.append(tokens[startIndex:endIndex])\n",
    "        startIndex = endIndex\n",
    "    return [tokenizer.decode(chunk) for chunk in chunks]\n",
    "\n",
    "def get_embedding(\n",
    "    aoai_client: AzureOpenAI,\n",
    "    embedding_model: str,\n",
    "    doc_id: str,\n",
    "    title: str,\n",
    "    content: str\n",
    "):\n",
    "    time.sleep(0.01)\n",
    "\n",
    "    text_to_embed = [\" \".join([title, content])]\n",
    "    chunk_ids = [doc_id]\n",
    "    \n",
    "    if doc_chunk_size:\n",
    "        text_to_embed = split_text(text_to_embed[0], doc_chunk_size)\n",
    "        # create random chunk IDs for each chunk\n",
    "        chars = string.ascii_lowercase\n",
    "        chunk_id_length = 8\n",
    "        chunk_ids = [''.join(random.choice(chars) for i in range(chunk_id_length)) for _ in text_to_embed]\n",
    "\n",
    "    text_embeddings = [x.embedding for x in aoai_client.embeddings.create(\n",
    "            input=text_to_embed,\n",
    "            model=embedding_model\n",
    "        ).data\n",
    "    ]\n",
    "    \n",
    "    return chunk_ids, text_to_embed, text_embeddings\n",
    "\n",
    "def index_dataset(search_client: SearchClient):\n",
    "    doc_chunks_count = 0\n",
    "    for df in pd.read_json(os.path.join(data_directory, \"datasets\", \"trec-covid\", \"corpus.jsonl\"), lines=True, orient=\"records\", chunksize=100):\n",
    "        _df = df.copy()\n",
    "        _df.rename(columns={\"_id\":\"doc_id\"}, inplace=True)\n",
    "        _df.set_index(\"doc_id\")\n",
    "\n",
    "        # If integrated vectorization is enabled, we'll chunk the data and vectorize it before uploading.\n",
    "        if use_integrated_vectorization:\n",
    "            start = time.time()\n",
    "            _df[[\"chunk_id\", \"chunk\", vector_field_name]] = _df.apply(\n",
    "                    lambda q: get_embedding(\n",
    "                        aoai_client,\n",
    "                        search_vectorizer_model_name,\n",
    "                        q[\"doc_id\"],\n",
    "                        q[\"title\"],\n",
    "                        q[\"text\"]\n",
    "                    ),\n",
    "                    axis=1,\n",
    "                    result_type=\"expand\"\n",
    "                )\n",
    "            end = time.time()\n",
    "            doc_chunks_count += 1\n",
    "            print(f\"Successfully chunked and vectorized {doc_chunks_count * len(_df)} documents (elapsed time: {end - start})\")\n",
    "            _df = _df.explode([\"chunk_id\", \"chunk\", vector_field_name])\n",
    "            _df.drop(\"text\", axis=1, inplace=True)\n",
    "            _df.rename(columns={\"chunk\":\"text\"}, inplace=True)\n",
    "            _df.set_index(\"chunk_id\")\n",
    "        else:\n",
    "            _df[\"chunk_id\"] = _df[\"doc_id\"]\n",
    "\n",
    "        documents = _df.to_dict(orient=\"records\")\n",
    "        search_client.upload_documents(documents=_df.to_dict(orient=\"records\"))\n",
    "        del _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056e87de-7829-4bee-bdd8-df0cb015dcb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index_dataset(search_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6524a243-30e3-42dc-9e13-2ace764be286",
   "metadata": {},
   "source": [
    "### Get search results and merge with qrels\n",
    "The `DocumentRetrievalEvaluator` from the Azure AI Evaluations SDK requires both search results and groundtruth labels in JSON-lines format.  In the next section, we will choose a search configuration to evaluate, generate search results for that configuration, and join the search results with their corresponding qrels from the TREC-COVID dataset to form our JSON-lines input for the evaluator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eb0cd4-e6d6-48a5-b20b-cadcd7d679ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def search(query: str, search_client: SearchClient, score_field: str = \"@search.score\", **search_configuration):\n",
    "    search_text = query\n",
    "    vector_queries = None\n",
    "    if \"vector_queries\" in search_configuration.keys():\n",
    "        search_text = None\n",
    "        vector_queries = [VectorizableTextQuery(text=query, **vector_query_config) for vector_query_config in search_configuration[\"vector_queries\"]]\n",
    "        search_configuration.pop(\"vector_queries\")\n",
    "        \n",
    "    results = search_client.search(search_text=search_text, vector_queries=vector_queries, **search_configuration)\n",
    "    return [{\"document_id\": result[\"doc_id\"], \"relevance_score\": result.get(score_field, None)} for result in results]\n",
    "\n",
    "def prepare_dataset(search_configuration):\n",
    "    # Load the queryset and qrels\n",
    "    queryset = pd.read_json(os.path.join(data_directory, \"datasets\", \"trec-covid\", \"queries.jsonl\"), lines=True, orient=\"records\")\n",
    "    qrels = pd.read_csv(os.path.join(data_directory, \"datasets\", \"trec-covid\", \"qrels\", \"test.tsv\"), delimiter=\"\\t\")\n",
    "    \n",
    "    # Drop negative qrels values and duplicates, and rename columns\n",
    "    qrels = qrels.loc[qrels[\"score\"] >= 0]\n",
    "    qrels.drop_duplicates(subset=[\"query-id\", \"corpus-id\"], inplace=True)\n",
    "    qrels.rename(columns={\"corpus-id\": \"document_id\", \"score\": \"query_relevance_label\"}, inplace=True)\n",
    "    \n",
    "    # Group qrels by query ID and generate groundtruth set per query\n",
    "    qrels_grouped = qrels.groupby(\"query-id\")\n",
    "    qrels_aggregated = qrels_grouped[[\"document_id\", \"query_relevance_label\"]].agg(lambda x: list(x))\n",
    "    qrels_aggregated[\"retrieval_ground_truth\"] = qrels_aggregated.apply(lambda x: json.dumps([{\"document_id\": doc_id, \"query_relevance_label\": label} for (doc_id, label) in zip(x[\"document_id\"], x[\"query_relevance_label\"])]), axis=1)\n",
    "    \n",
    "    # Join the queryset and qrels on query ID and doc ID\n",
    "    merged = queryset.merge(qrels_aggregated, left_on=\"_id\", right_on=\"query-id\")\n",
    "    \n",
    "    # Generate search results for each query\n",
    "    search_configuration_name = search_configuration.pop(\"name\")\n",
    "    score_field = search_configuration.pop(\"score_field\")\n",
    "    merged[\"retrieved_documents\"] = merged.apply(\n",
    "        lambda x: json.dumps(search(\n",
    "            query=x[\"text\"],\n",
    "            search_client=search_client,\n",
    "            score_field=score_field,\n",
    "            **search_configuration\n",
    "        )), axis=1)\n",
    "    \n",
    "    merged_final = merged[[\"retrieved_documents\", \"retrieval_ground_truth\"]]\n",
    "    # Save final dataset to a local file in JSON-lines format\n",
    "    jsonl_path = os.path.join(\".\", f\"evaluate-beir-{search_configuration_name}.jsonl\")\n",
    "    merged_final.to_json(jsonl_path, lines=True, orient=\"records\")\n",
    "    \n",
    "    return (merged_final, jsonl_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b25e4e3-d5a4-41d8-8f41-daef9fd1f18f",
   "metadata": {},
   "source": [
    "### Upload dataset to Azure AI Foundry\n",
    "To run an evaluation in the cloud, we need to uploud our evaluation data to the specified Azure AI Foundry project.\n",
    "\n",
    "We will run the data preparation for each search configuration specified earlier in the notebook, so we can compare evaluation runs to determine which configuration performs best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a0102b-1738-4115-a25e-83a924c65d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ids = []\n",
    "for config in [\n",
    "    text_search_configuration,\n",
    "    semantic_search_configuration,\n",
    "    vector_search_configuration,\n",
    "    semantic_vector_hybrid_search_configuration\n",
    "]:\n",
    "    config_name = config['name']\n",
    "    print(f\"Preparing data for config '{config_name}'\")\n",
    "    dataset, jsonl_path = prepare_dataset(config)\n",
    "    data_id, _ = project_client.upload_file(jsonl_path)\n",
    "    data_ids.append((config_name, data_id))\n",
    "\n",
    "    print(f\"File {jsonl_path} was uploaded successfully!\")\n",
    "    print(f\"Data ID: {data_id}\")\n",
    "    print(f\"Data content summary:\")\n",
    "    print(dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb22d6c7-91f2-47f1-a07e-caf42855e6cb",
   "metadata": {},
   "source": [
    "## Run document retrieval evaluation\n",
    "After our datasets are uploaded, we will configure and run the document retrieval evaluator for each uploaded dataset.  The init params `groundtruth_label_min` and `groundtruth_label_max` help us to configure the qrels scaling for some metrics which depend on a count of labels, such as Fidelity.  In this case, the TREC-COVID dataset groundtruth set has 0, 1, and 2 as possible labels, so we set the values of those init params accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92853ecf-61b2-4ce9-81d2-b2afcb784529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evaluation(evaluation_name, evaluation_description, dataset_id):\n",
    "    # Create an evaluation\n",
    "    evaluation = Evaluation(\n",
    "        display_name=evaluation_name,\n",
    "        description=evaluation_description,\n",
    "        data=Dataset(id=dataset_id),\n",
    "        evaluators={\n",
    "            \"documentretrievalevaluator\": EvaluatorConfiguration(\n",
    "                id=DocumentRetrievalEvaluator().id,\n",
    "                data_mapping={\n",
    "                    \"retrieval_ground_truth\": \"${data.retrieval_ground_truth}\",\n",
    "                    \"retrieved_documents\": \"${data.retrieved_documents}\"\n",
    "                },\n",
    "                init_params={\n",
    "                    \"ground_truth_label_min\": 0,\n",
    "                    \"ground_truth_label_max\": 2\n",
    "                }\n",
    "            )\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Create evaluation\n",
    "    evaluation_response = project_client.evaluations.create(\n",
    "        evaluation=evaluation,\n",
    "    )\n",
    "\n",
    "    # Get evaluation\n",
    "    get_evaluation_response = project_client.evaluations.get(evaluation_response.id)\n",
    "\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    print(\"Created evaluation, evaluation ID: \", get_evaluation_response.id)\n",
    "    print(\"Evaluation status: \", get_evaluation_response.status)\n",
    "    print(\"AI project URI: \", get_evaluation_response.properties[\"AiStudioEvaluationUri\"])\n",
    "    print(\"----------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501552c3-722d-4912-9393-e8c63257f523",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (config_name, data_id) in data_ids:\n",
    "    run_evaluation(f\"TREC-COVID evaluation - {config_name}\", \"Document retrieval evaluation using the TREC-COVID dataset from BeIR\", data_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c616e48-2fab-4493-977e-ec51c7e6951b",
   "metadata": {},
   "source": [
    "## Comparing results\n",
    "\n",
    "Once the evaluations are complete, you can compare the results by clicking the \"Evaluations\" tab on the left-side of the Azure AI Foundry project page, select the runs for comparison, and then click the \"Compare\" button to see metric results side-by-side.\n",
    "\n",
    "![Azure AI Foundry project evaluations page](eval-results-select.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
