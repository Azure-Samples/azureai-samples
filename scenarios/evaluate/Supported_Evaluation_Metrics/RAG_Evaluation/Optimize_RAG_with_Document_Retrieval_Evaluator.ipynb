{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f372fc3-d2ad-49a8-87da-e3b092b6b5ae",
   "metadata": {},
   "source": [
    "# Document Retrieval Evaluation in Azure AI Foundry\n",
    "\n",
    "## Objective\n",
    "This notebook sample demonstrates how to perform evaluation of an Azure AI Search index using Azure AI Evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de22faf1-878a-4619-aaf0-e26a05a19867",
   "metadata": {},
   "source": [
    "## Time\n",
    "\n",
    "You should expect to spend about 20 minutes running this notebook, after the below setup steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec713f8-ef98-4ed1-99b6-7669b3687fd2",
   "metadata": {},
   "source": [
    "## About This Example\n",
    "This notebook sample demonstrates how to perform evaluation of an Azure AI Search index using Azure AI Evaluation.  The evaluator used in this example, `DocumentRetrievalEvaluator` requires a list of ground truth labeled documents (sometimes referred to as \"qrels\") and a list of actual search results obtained from a search index as inputs for calculating the evaluation metrics.  This sample will walk through the steps of data preparation, gathering search results for different search configurations, running evaluation and comparing results of each run.\n",
    "\n",
    "#### Explanation of Document Retrieval Metrics \n",
    "The metrics that will be generated in the output of the evaluator include:\n",
    "| Metric               | Category            | Description                                                                                     |\n",
    "|-----------------------|---------------------|-------------------------------------------------------------------------------------------------|\n",
    "| Fidelity             | Search Fidelity    | How well the top n retrieved chunks reflect the content for a given query; number of good documents returned out of the total number of known good documents in a dataset |\n",
    "| NDCG                 | Search NDCG        | How good are the rankings to an ideal order where all relevant items are at the top of the list.        |\n",
    "| XDCG                 | Search XDCG        | How good the results are in the top-k documents regardless of scoring of other index documents |\n",
    "| Max Relevance N      | Search Max Relevance | Maximum relevance in the top-k chunks                                                          |\n",
    "| Holes      | Search Label Sanity | Number of documents with missing query relevance judgments (Ground truth) |\n",
    "\n",
    "It's important to note that some metrics, particularly NDCG, XDCG and Fidelity, are sensitive to holes.  Ideally the count of holes for a given evaluation should be zero, otherwise results for these metrics may not be accurate.  It is recommended to iteratively check results against current known ground truth to fill holes to improve accuracy of the evaluation metrics.  This process is not covered explicitly in the sample but is important to mention."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba1be7f-0270-4011-9ab1-ee170ebef24c",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "This example will use the open source BEIR/scidocs dataset, hosted publically on [HuggingFace](https://huggingface.co/datasets/BeIR/scidocs#dataset-summary), which contains a corpus we can index into Azure AI Search, as well as a set of queries to run through our search service and a set of ground truth qrels for evaluation. The download is about 25MB.\n",
    "\n",
    "To speed up future indexing, we will downsample the dataset for the purposes of this demo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c33b6e-be25-4331-a6ca-8156fe6c11b2",
   "metadata": {},
   "source": [
    "## Before You Begin\n",
    "Before running this notebook, be sure you have fulfilled the following prerequisites:\n",
    "* Create or get access to an [Azure Subscription](https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/ready/azure-best-practices/initial-subscriptions), and assign yourself the Owner or Contributor role for creating resources in this subscription.\n",
    "* `az` CLI is installed in the current environment, and you have run `az login` to gain access to your resources.\n",
    "* Read and understand the documentation covering [assigning RBAC roles between resources](https://learn.microsoft.com/en-us/azure/role-based-access-control/role-assignments-cli) using the `az` CLI.\n",
    "* Create [Azure AI Search resource](https://learn.microsoft.com/en-us/azure/search/search-create-service-portal), and assign yourself the \"Search Index Data Contributor\" role for the resource.  \n",
    "* Create an [Azure AI Foundry project](https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/create-projects?tabs=ai-studio).\n",
    "* [Connect](https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/evaluations-storage-account) the Azure AI Foundry project to a storage account.\n",
    "* [Optional] Deploy a text embedding model in the Azure AI Foundry project for testing vector-based search scenarios in this example, and assign yourself the \"Cognitive Services OpenAI User\" role for the Azure AI Services resource created for your project.  For integrated vectorization support, you will also need to ensure that your Azure AI Search resource has the \"Cognitive Services OpenAI User\" role assigned for the Azure AI Services resource as well.\n",
    "* Copy the contents of `.env.sample` into a new file named `.env`, and fill in the values corresponding to your own service resources.\n",
    "* It is recommended to create all needed resources within a single resource group for easier deletion\n",
    "\n",
    "Set these environment variables with your own values:\n",
    "\n",
    "**AZURE_AI_SEARCH_ENDPOINT** - Search API endpoint for search service \n",
    "\n",
    "**AZURE_AI_SEARCH_KEY** - Search API key for search service \n",
    "\n",
    "**AZURE_AI_SEARCH_VECTORIZER_ENDPOINT** - Embedding model endpoint to be used for vectorization of your corpus \n",
    "\n",
    "**AZURE_AI_SEARCH_VECTORIZER_KEY** - Embedding model API key to be used for vectorization of your corpus \n",
    "\n",
    "**AZURE_AI_SEARCH_VECTORIZER_MODEL_NAME** - Embedding model name to be used for vectorization of your corpus \n",
    "\n",
    "**AZURE_AI_SEARCH_VECTORIZER_DEPLOYMENT_NAME** - Embedding model deployment name to be used for vectorization of your corpus \n",
    "\n",
    "**AZURE_AI_SEARCH_VECTORIZER_MODEL_DIMENSIONS** - Embedding model dimensions to be used for vectorization of your corpus \n",
    "\n",
    "**AZURE_PROJECT_ENDPOINT** - The Azure AI Foundry project endpoint, as found in the overview page of your Azure AI Foundry project. \n",
    "\n",
    "Example: AZURE_PROJECT_ENDPOINT=https://your-account.services.ai.azure.com/api/projects/your-project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7da7c8c-e0bb-47d0-9f1e-72e1e545f95f",
   "metadata": {},
   "source": [
    "### Installation\n",
    "Run the following command to install the python requirements for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0137b5aa-9837-4d74-b9a3-96b36e6c301a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install azure-core azure-identity azure-search-documents azure-ai-evaluation openai pandas dotenv tiktoken \"datasets<4.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa63828-44da-4b4a-9270-ac31288d9477",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "The following cell will load the necessary resource connection configuration for the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c802f08c-0423-49bc-a7b3-389e9628fd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3561ffb0-35ce-4faf-b767-9f28d4318b84",
   "metadata": {},
   "source": [
    "## Run The Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e452701f-1faa-4715-8bd9-ad5a4231bd6f",
   "metadata": {},
   "source": [
    "### Import all modules\n",
    "For convenience, all modules needed for the rest of the notebook can be imported all at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba11028d-33ca-49e9-b106-86f0e4316182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import copy\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "\n",
    "# Azure SDK\n",
    "from azure.ai.evaluation import DocumentRetrievalEvaluator, evaluate\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizableTextQuery\n",
    "from azure.search.documents.indexes.models import (\n",
    "    ComplexField,\n",
    "    SearchIndex,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SemanticConfiguration,\n",
    "    SemanticField,\n",
    "    SemanticPrioritizedFields,\n",
    "    SemanticSearch,\n",
    "    VectorSearch,\n",
    "    VectorSearchProfile,\n",
    "    AzureOpenAIVectorizer,\n",
    "    AzureOpenAIVectorizerParameters,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    HnswParameters,\n",
    ")\n",
    "\n",
    "# Other open source packages\n",
    "from datasets import load_dataset\n",
    "from openai import AzureOpenAI\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12d8a40-8a00-4979-9400-9b36ed9a6ee5",
   "metadata": {},
   "source": [
    "### Create client objects for managing resources and set other helpful variables\n",
    "We will also create all of the client objects and other variables needed for the rest of the notebook in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aab177-5a0b-48b8-b721-62d9197cc1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Azure AI Search service clients\n",
    "search_service_endpoint = os.environ[\"AZURE_AI_SEARCH_ENDPOINT\"]\n",
    "search_service_key = os.environ[\"AZURE_AI_SEARCH_KEY\"]\n",
    "index_name = \"scidocs-vector\"\n",
    "search_credential = AzureKeyCredential(search_service_key)\n",
    "search_index_client = SearchIndexClient(search_service_endpoint, search_credential)\n",
    "search_client = SearchClient(search_service_endpoint, index_name, search_credential)\n",
    "\n",
    "# Create the Azure AI Project client\n",
    "azure_project_endpoint = os.environ[\"AZURE_PROJECT_ENDPOINT\"]\n",
    "\n",
    "# search parameters\n",
    "search_top_k = 50\n",
    "search_select = \"doc_id\"\n",
    "\n",
    "# vector search parameters, if using vector search\n",
    "vector_field_name = \"title_text_ada002\"\n",
    "search_vectorizer_endpoint = os.environ[\"AZURE_AI_SEARCH_VECTORIZER_ENDPOINT\"]\n",
    "search_vectorizer_key = os.environ[\"AZURE_AI_SEARCH_VECTORIZER_KEY\"]\n",
    "search_vectorizer_model_name = os.environ[\"AZURE_AI_SEARCH_VECTORIZER_MODEL_NAME\"]\n",
    "search_vectorizer_deployment_name = os.environ[\"AZURE_AI_SEARCH_VECTORIZER_DEPLOYMENT_NAME\"]\n",
    "search_vectorizer_model_dimensions = os.environ[\"AZURE_AI_SEARCH_VECTORIZER_MODEL_DIMENSIONS\"]\n",
    "use_integrated_vectorization = (\n",
    "    search_vectorizer_endpoint\n",
    "    and search_vectorizer_key\n",
    "    and search_vectorizer_model_name\n",
    "    and search_vectorizer_deployment_name\n",
    "    and search_vectorizer_model_dimensions\n",
    ")\n",
    "doc_chunk_size = 1024 if use_integrated_vectorization else None\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "aoai_client = None\n",
    "if use_integrated_vectorization:\n",
    "    ad_token_provider = get_bearer_token_provider(\n",
    "        DefaultAzureCredential(), \"https://cognitiveservices.azure.com/.default\"\n",
    "    )\n",
    "    aoai_client = AzureOpenAI(\n",
    "        azure_endpoint=search_vectorizer_endpoint, api_version=\"2024-06-01\", azure_ad_token_provider=ad_token_provider\n",
    "    )\n",
    "    print(\"Using integrated vectorization with Azure OpenAI model:\", search_vectorizer_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f00d41-7174-41bd-96ae-8690d409f565",
   "metadata": {},
   "source": [
    "### Create search configurations\n",
    "In the next cell, we will set some additional configuration values for configuring document search using Azure AI Search.  We can select from these configurations later on when we generate search results for evaluation, and then compare the results of each run after the evaluations are finished to determine which configuration performs best for the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597f3f3d-139c-44e2-bedc-9dda79fe15c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full-text search\n",
    "text_search_configuration = {\n",
    "    \"name\": \"text\",\n",
    "    \"select\": search_select,\n",
    "    \"top\": search_top_k,\n",
    "    \"api_version\": \"2024-11-01-preview\",\n",
    "    \"score_field\": \"@search.score\",\n",
    "}\n",
    "\n",
    "# Semantic search\n",
    "semantic_search_configuration = {\n",
    "    \"name\": \"semantic\",\n",
    "    \"query_type\": \"semantic\",\n",
    "    \"select\": search_select,\n",
    "    \"top\": search_top_k,\n",
    "    \"semantic_configuration_name\": \"en-semantic-config\",\n",
    "    \"api_version\": \"2024-11-01-preview\",\n",
    "    \"score_field\": \"@search.reranker_score\",\n",
    "}\n",
    "\n",
    "# Vector search -- requires setting values for environment variables AZURE_AI_SEARCH_VECTORIZER_ENDPOINT, AZURE_AI_SEARCH_VECTORIZER_KEY, and\n",
    "# AZURE_AI_SEARCH_VECTORIZER_MODEL\n",
    "vector_search_configuration = {\n",
    "    \"name\": \"vector\",\n",
    "    \"select\": search_select,\n",
    "    \"top\": search_top_k,\n",
    "    \"vector_queries\": [{\"kind\": \"text\", \"fields\": vector_field_name, \"k_nearest_neighbors\": search_top_k}],\n",
    "    \"score_field\": \"@search.score\",\n",
    "}\n",
    "\n",
    "# Semantic vector hybrid search\n",
    "semantic_vector_hybrid_search_configuration = {\n",
    "    \"name\": \"hybrid\",\n",
    "    \"query_type\": \"semantic\",\n",
    "    \"select\": search_select,\n",
    "    \"top\": search_top_k,\n",
    "    \"semantic_configuration_name\": \"en-semantic-config\",\n",
    "    \"vector_queries\": [{\"kind\": \"text\", \"fields\": vector_field_name, \"k_nearest_neighbors\": search_top_k}],\n",
    "    \"score_field\": \"@search.score\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4618d1-0015-4cc4-a2bd-d77cd85184f9",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123a1864-dfb6-4d56-bac8-300712f50c17",
   "metadata": {},
   "source": [
    "### Download the Scidocs (Beir) dataset\n",
    "In the next cell, we will download an open source dataset to perform evaluation on. We will use the Scidocs dataset from BeIR hosted on [HuggingFace](https://huggingface.co/datasets/BeIR/scidocs#dataset-summary), which contains a corpus we can index into Azure AI Search, as well as a set of queries to run through our search service and a set of ground truth qrels for evaluation. The download is about 25MB.\n",
    "\n",
    "To speed up future indexing, we will downsample the dataset for the purposes of this demo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aceebfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = load_dataset(\"BeIR/scidocs\", \"corpus\")[\"corpus\"]\n",
    "queries = load_dataset(\"BeIR/scidocs\", \"queries\")[\"queries\"].to_pandas()\n",
    "qrels = load_dataset(\"BeIR/scidocs-qrels\", \"default\")[\"test\"].to_pandas()\n",
    "\n",
    "# Downsample queries to 1/10th of the original size\n",
    "queries = queries.sample(frac=0.1, random_state=42)\n",
    "downsampled_query_ids = queries[\"_id\"].tolist()\n",
    "qrels = qrels[qrels[\"query-id\"].isin(downsampled_query_ids)]\n",
    "qrels_doc_ids = qrels[\"corpus-id\"].unique().tolist()\n",
    "# Filter the corpus to documents that are in the filtered qrels. You might want to include more documents for a more realistic retrieval task.\n",
    "# This truncation is simply to make vectorizing run faster for demo purposes.\n",
    "corpus = corpus.filter(lambda example: example[\"_id\"] in qrels_doc_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2b2e1e-4db7-45bc-98e2-bd5ee070d236",
   "metadata": {},
   "source": [
    "### Create an Azure AI Search index from the dataset corpus\n",
    "Next, we will create an Azure AI Search index using the BeIR Scidocs dataset downloaded in the previous cell.  If integrated vectorization is enabled in the configuration settings, we will also add a vector field for our index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2a9b8f-3dfd-4c9f-ba4e-e1bf95e8329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_or_update_index(search_index_client: SearchIndexClient) -> None:\n",
    "    fields = [\n",
    "        SearchField(\n",
    "            name=\"chunk_id\", type=SearchFieldDataType.String, key=True, facetable=False, analyzer_name=\"standard.lucene\"\n",
    "        ),\n",
    "        SearchField(name=\"doc_id\", type=SearchFieldDataType.String, facetable=False, analyzer_name=\"standard.lucene\"),\n",
    "        SearchField(\n",
    "            name=\"title\",\n",
    "            type=SearchFieldDataType.String,\n",
    "            sortable=False,\n",
    "            facetable=False,\n",
    "            analyzer_name=\"standard.lucene\",\n",
    "        ),\n",
    "        SearchField(\n",
    "            name=\"text\",\n",
    "            type=SearchFieldDataType.String,\n",
    "            sortable=False,\n",
    "            facetable=False,\n",
    "            analyzer_name=\"standard.lucene\",\n",
    "        ),\n",
    "        ComplexField(\n",
    "            name=\"metadata\",\n",
    "            fields=[\n",
    "                SearchField(\n",
    "                    name=\"url\",\n",
    "                    type=SearchFieldDataType.String,\n",
    "                    sortable=False,\n",
    "                    facetable=False,\n",
    "                    analyzer_name=\"standard.lucene\",\n",
    "                ),\n",
    "                SearchField(\n",
    "                    name=\"pubmed_id\",\n",
    "                    type=SearchFieldDataType.String,\n",
    "                    sortable=False,\n",
    "                    facetable=False,\n",
    "                    analyzer_name=\"standard.lucene\",\n",
    "                ),\n",
    "            ],\n",
    "        ),\n",
    "    ]\n",
    "    semantic_prioritized_fields = SemanticPrioritizedFields(\n",
    "        title_field=SemanticField(field_name=\"title\"),\n",
    "        content_fields=[SemanticField(field_name=\"text\")],\n",
    "        keywords_fields=[SemanticField(field_name=\"metadata/url\")],\n",
    "    )\n",
    "    semantic_configuration = SemanticConfiguration(\n",
    "        name=\"en-semantic-config\", prioritized_fields=semantic_prioritized_fields\n",
    "    )\n",
    "    semantic_search = SemanticSearch(\n",
    "        default_configuration_name=\"en-semantic-config\", configurations=[semantic_configuration]\n",
    "    )\n",
    "\n",
    "    vector_search = None\n",
    "    if use_integrated_vectorization:\n",
    "        algorithm = HnswAlgorithmConfiguration(\n",
    "            name=\"hnsw-1\", parameters=HnswParameters(m=4, ef_construction=400, ef_search=500, metric=\"cosine\")\n",
    "        )\n",
    "        vectorizer = AzureOpenAIVectorizer(\n",
    "            vectorizer_name=\"aoai-vectorizer-1\",\n",
    "            parameters=AzureOpenAIVectorizerParameters(\n",
    "                resource_url=search_vectorizer_endpoint,\n",
    "                deployment_name=search_vectorizer_deployment_name,\n",
    "                api_key=search_vectorizer_key,\n",
    "                model_name=search_vectorizer_model_name,\n",
    "            ),\n",
    "        )\n",
    "        profile = VectorSearchProfile(\n",
    "            name=\"vector-profile-1\",\n",
    "            algorithm_configuration_name=algorithm.name,\n",
    "            vectorizer_name=vectorizer.vectorizer_name,\n",
    "        )\n",
    "        vector_search = VectorSearch(profiles=[profile], algorithms=[algorithm], vectorizers=[vectorizer])\n",
    "        fields.append(\n",
    "            SearchField(\n",
    "                name=vector_field_name,\n",
    "                type=\"Collection(Edm.Single)\",\n",
    "                searchable=True,\n",
    "                hidden=True,\n",
    "                stored=False,\n",
    "                filterable=False,\n",
    "                sortable=False,\n",
    "                facetable=False,\n",
    "                vector_search_dimensions=search_vectorizer_model_dimensions,\n",
    "                vector_search_profile_name=profile.name,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    index = SearchIndex(name=index_name, fields=fields, semantic_search=semantic_search, vector_search=vector_search)\n",
    "\n",
    "    search_index_client.create_or_update_index(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce8dd13-c943-4ce6-b0e4-e309506d29a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_or_update_index(search_index_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc742f6-fbb4-4385-bceb-2ef54f0c291e",
   "metadata": {},
   "source": [
    "### Index the documents from the dataset corpus\n",
    "Once we have the data downloaded and the index created, we will ingest the documents from the local file into the index.  If integrated vectorization is configured, we will also create embeddings for the input data to include in the ingestion payload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c29fe3a-a63f-463e-a30c-dad772127df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(text: str, max_tokens: int) -> list[object]:\n",
    "    tokens = tokenizer.encode(text)\n",
    "    chunks = []\n",
    "    startIndex = 0\n",
    "    while startIndex < len(tokens):\n",
    "        endIndex = startIndex + max_tokens\n",
    "        chunks.append(tokens[startIndex:endIndex])\n",
    "        startIndex = endIndex\n",
    "    return [tokenizer.decode(chunk) for chunk in chunks]\n",
    "\n",
    "\n",
    "def get_embedding(\n",
    "    aoai_client: AzureOpenAI, embedding_model: str, doc_id: str, title: str, content: str\n",
    ") -> tuple[list[str], list[str], list[list[float]]]:\n",
    "    text_to_embed = [\" \".join([title, content])]\n",
    "    chunk_ids = [doc_id]\n",
    "\n",
    "    if doc_chunk_size:\n",
    "        text_to_embed = split_text(text_to_embed[0], doc_chunk_size)\n",
    "        chunk_ids = [uuid.uuid4().hex[:8] for _ in text_to_embed]\n",
    "\n",
    "    text_embeddings = [\n",
    "        x.embedding for x in aoai_client.embeddings.create(input=text_to_embed, model=embedding_model).data\n",
    "    ]\n",
    "\n",
    "    return chunk_ids, text_to_embed, text_embeddings\n",
    "\n",
    "\n",
    "def index_dataset(search_client: SearchClient) -> None:\n",
    "    chunk_size = 100\n",
    "    documents_processed = 0\n",
    "    for i in range(0, len(corpus), chunk_size):\n",
    "        chunk = corpus[i : i + chunk_size]\n",
    "        df = pd.DataFrame(chunk)\n",
    "        _df = df.copy()\n",
    "        _df.rename(columns={\"_id\": \"doc_id\"}, inplace=True)\n",
    "        _df.set_index(\"doc_id\")\n",
    "\n",
    "        # If integrated vectorization is enabled, we'll chunk the data and vectorize it before uploading.\n",
    "        if use_integrated_vectorization:\n",
    "            start = time.time()\n",
    "            _df[[\"chunk_id\", \"chunk\", vector_field_name]] = _df.apply(\n",
    "                lambda q: get_embedding(aoai_client, search_vectorizer_model_name, q[\"doc_id\"], q[\"title\"], q[\"text\"]),\n",
    "                axis=1,\n",
    "                result_type=\"expand\",\n",
    "            )\n",
    "            end = time.time()\n",
    "            documents_processed += len(_df)\n",
    "            print(\n",
    "                f\"Chunked and vectorized {documents_processed} of {len(corpus)} documents (last 100 docs took: {end - start:.2f} seconds)\"\n",
    "            )\n",
    "            _df = _df.explode([\"chunk_id\", \"chunk\", vector_field_name])\n",
    "            _df.drop(\"text\", axis=1, inplace=True)\n",
    "            _df.rename(columns={\"chunk\": \"text\"}, inplace=True)\n",
    "            _df.set_index(\"chunk_id\")\n",
    "        else:\n",
    "            _df[\"chunk_id\"] = _df[\"doc_id\"]\n",
    "\n",
    "        documents = _df.to_dict(orient=\"records\")\n",
    "        search_client.upload_documents(documents=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056e87de-7829-4bee-bdd8-df0cb015dcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_dataset(search_client)  # This can take ~10mins with vectorization on. Much faster with vectorization off."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6524a243-30e3-42dc-9e13-2ace764be286",
   "metadata": {},
   "source": [
    "### Get search results and merge with qrels\n",
    "The `DocumentRetrievalEvaluator` from the Azure AI Evaluations SDK requires both search results and groundtruth labels in JSON-lines format.  In the next section, we will choose a search configuration to evaluate, generate search results for that configuration, and join the search results with their corresponding qrels from the Scidocs dataset to form our JSON-lines input for the evaluator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eb0cd4-e6d6-48a5-b20b-cadcd7d679ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(\n",
    "    query: str,\n",
    "    search_client: SearchClient,\n",
    "    score_field: str = \"@search.score\",\n",
    "    **search_configuration: dict[str, object],\n",
    ") -> list[dict[str, object]]:\n",
    "    search_text = query\n",
    "    vector_queries = None\n",
    "    if \"vector_queries\" in search_configuration:\n",
    "        search_text = None\n",
    "        vector_queries = [\n",
    "            VectorizableTextQuery(text=query, **vector_query_config)\n",
    "            for vector_query_config in search_configuration[\"vector_queries\"]\n",
    "        ]\n",
    "        search_configuration.pop(\"vector_queries\")\n",
    "\n",
    "    results = search_client.search(search_text=search_text, vector_queries=vector_queries, **search_configuration)\n",
    "    return [{\"document_id\": result[\"doc_id\"], \"relevance_score\": result.get(score_field, None)} for result in results]\n",
    "\n",
    "\n",
    "def prepare_dataset(search_configuration: dict[str, object], qrels: pd.DataFrame) -> tuple[pd.DataFrame, Path]:\n",
    "    qrels.rename(\n",
    "        columns={\"corpus-id\": \"document_id\", \"score\": \"query_relevance_label\", \"query-id\": \"query_id\"}, inplace=True\n",
    "    )\n",
    "\n",
    "    # Group qrels by query ID and generate groundtruth set per query\n",
    "    qrels_grouped = qrels.groupby(\"query_id\")\n",
    "    qrels_aggregated = qrels_grouped[[\"document_id\", \"query_relevance_label\"]].agg(lambda x: list(x))\n",
    "    qrels_aggregated[\"retrieval_ground_truth\"] = [\n",
    "        [{\"document_id\": doc_id, \"query_relevance_label\": label} for doc_id, label in zip(doc_ids, labels)]\n",
    "        for doc_ids, labels in zip(qrels_aggregated[\"document_id\"], qrels_aggregated[\"query_relevance_label\"])\n",
    "    ]\n",
    "\n",
    "    # Join the queryset and qrels on query ID and doc ID\n",
    "    merged = queries.merge(qrels_aggregated, left_on=\"_id\", right_on=\"query_id\")\n",
    "\n",
    "    # Generate search results for each query - this can take some time.\n",
    "    search_configuration_name = search_configuration.pop(\"name\")\n",
    "    score_field = search_configuration.pop(\"score_field\")\n",
    "    merged[\"retrieved_documents\"] = merged.apply(\n",
    "        lambda row: search(\n",
    "            query=row[\"text\"], search_client=search_client, score_field=score_field, **search_configuration\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    merged_final = merged[[\"retrieved_documents\", \"retrieval_ground_truth\"]]\n",
    "    jsonl_path = Path(f\"evaluate-beir-{search_configuration_name}.jsonl\")\n",
    "    merged_final.to_json(jsonl_path, lines=True, orient=\"records\")\n",
    "\n",
    "    return (merged_final, jsonl_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb22d6c7-91f2-47f1-a07e-caf42855e6cb",
   "metadata": {},
   "source": [
    "### Run document retrieval evaluation\n",
    "After our datasets are uploaded, we will configure and run the document retrieval evaluator for each uploaded dataset.  The init params `ground_truth_label_min` and `ground_truth_label_max` help us to configure the qrels scaling for some metrics which depend on a count of labels, such as Fidelity.  In this case, the Scidocs dataset ground truth set has 0 and 1 as possible labels, so we set the values of those init params accordingly. The thresholds define whether to mark a metric as passing or failing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0420d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ids = []\n",
    "config_list = [text_search_configuration, semantic_search_configuration]\n",
    "if use_integrated_vectorization:\n",
    "    config_list.extend([vector_search_configuration, semantic_vector_hybrid_search_configuration])\n",
    "\n",
    "for config in config_list:\n",
    "    config_name = config[\"name\"]\n",
    "    print(f\"Running searches with config '{config_name}'\")\n",
    "    dataset, jsonl_path = prepare_dataset(copy.deepcopy(config), qrels)\n",
    "    print(f\"Made file {jsonl_path}\")\n",
    "    print(\"Data content summary:\")\n",
    "    print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5ba4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evaluation_locally() -> dict[str, object]:\n",
    "    results = {}\n",
    "    files_to_evaluate = [\n",
    "        (\"Text Search\", \"evaluate-beir-text.jsonl\"),\n",
    "        (\"Semantic Search\", \"evaluate-beir-semantic.jsonl\"),\n",
    "    ]\n",
    "    if use_integrated_vectorization:\n",
    "        files_to_evaluate.extend(\n",
    "            [(\"Vector Search\", \"evaluate-beir-vector.jsonl\"), (\"Hybrid Search\", \"evaluate-beir-hybrid.jsonl\")]\n",
    "        )\n",
    "    for config_name, sample_data_file_name in files_to_evaluate:\n",
    "        doc_retrieve = DocumentRetrievalEvaluator(ground_truth_label_min=0, ground_truth_label_max=1)\n",
    "        response = evaluate(\n",
    "            data=sample_data_file_name,\n",
    "            evaluation_name=f\"Doc retrieval eval demo - {config_name} run\",\n",
    "            evaluators={\n",
    "                \"DocumentRetrievalEvaluator\": doc_retrieve,\n",
    "            },\n",
    "            evaluator_config={\n",
    "                \"document_retrieval\": {\n",
    "                    \"column_mapping\": {\n",
    "                        \"retrieval_ground_truth\": \"${data.retrieval_ground_truth}\",\n",
    "                        \"retrieved_documents\": \"${data.retrieved_documents}\",\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            azure_ai_project=azure_project_endpoint,  # This line uploads evaluation results to the Foundry Evaluations portal\n",
    "        )\n",
    "        results[config_name] = response\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "res = run_evaluation_locally()\n",
    "print(\"Check Foundry Evaluations portal for results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c616e48-2fab-4493-977e-ec51c7e6951b",
   "metadata": {},
   "source": [
    "### Comparing results\n",
    "\n",
    "To compare across the different evaluations, once they are complete, you can click the \"Evaluations\" tab on the left-side of the Azure AI Foundry project page, select the runs for comparison, and then click the \"Compare\" button to see metric results side-by-side. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f50716-1924-460a-ba42-9db11fffad1b",
   "metadata": {},
   "source": [
    "## Cleaning Up\n",
    "\n",
    "To clean up the resources used in this sample, delete your Azure Search Service, Azure Foundry Project, and optionally your vectorizer deployment, wherever that may be hosted.\n",
    "\n",
    "If you made a resource group specifically to run this example, you could instead [delete the resource group](https://learn.microsoft.com/en-us/azure/azure-resource-manager/management/delete-resource-group).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
