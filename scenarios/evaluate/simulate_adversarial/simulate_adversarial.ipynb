{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Simulator for an online endpont\n",
    "\n",
    "## Objective\n",
    "\n",
    "This tutorial provides a step-by-step guide on how to leverage adversarial simulator to simulate an adversarial question answering scenario against an online endpoint\n",
    "\n",
    "This tutorial uses the following Azure AI services:\n",
    "\n",
    "- [Azure AI Safety Evaluation](https://aka.ms/azureaistudiosafetyeval)\n",
    "- [azure-ai-evaluation](https://learn.microsoft.com/en-us/azure/ai-studio/how-to/develop/evaluate-sdk)\n",
    "\n",
    "## Time\n",
    "\n",
    "You should expect to spend 20 minutes running this sample. \n",
    "\n",
    "## About this example\n",
    "\n",
    "This example demonstrates a simulated adversarial question answering. It is important to have access to AzureOpenAI credentials and an AzureAI project.\n",
    "\n",
    "## Before you begin\n",
    "### Prerequesite\n",
    "[Have an online deployment on Azure AI studio](https://learn.microsoft.com/en-us/azure/machine-learning/concept-endpoints-online?view=azureml-api-2)\n",
    "### Installation\n",
    "\n",
    "Install the following packages required to execute this notebook. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-ai-evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from azure.ai.evaluation.simulator import AdversarialSimulator, AdversarialScenario\n",
    "from typing import Optional, List, Dict, Any\n",
    "import os\n",
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target function\n",
    "The target function for this sample uses a call to call the endpoint.\n",
    "\n",
    "Make sure you retrive the `api_key`, `endpoint` and `azure_model_deployment` from Azure AI studio and update them in the `call_endpoint` function below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_ai_project = {\n",
    "    \"subscription_id\": \"<your-subscription-id>\",\n",
    "    \"resource_group_name\": \"<your-resource-group-name>\",\n",
    "    \"project_name\": \"<your-project-name>\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the following code to set the environment variables if not already set. If set, you can skip this step.\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"<your-api-key>\"\n",
    "os.environ[\"AZURE_OPENAI_API_VERSION\"] = \"<api version>\"\n",
    "os.environ[\"AZURE_OPENAI_DEPLOYMENT\"] = \"<your-deployment>\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"<your-endpoint>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_endpoint(query: str) -> dict:\n",
    "    deployment = os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\")\n",
    "    endpoint = os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    # Get a client handle for the model\n",
    "    client = AzureOpenAI(\n",
    "        azure_endpoint=endpoint,\n",
    "        api_version=os.environ.get(\"AZURE_OPENAI_API_VERSION\"),\n",
    "        api_key=os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "    )\n",
    "    # Call the model\n",
    "    completion = client.chat.completions.create(\n",
    "        model=deployment,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query,\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=800,\n",
    "        temperature=0.7,\n",
    "        top_p=0.95,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None,\n",
    "        stream=False,\n",
    "    )\n",
    "    return completion.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator = AdversarialSimulator(azure_ai_project=azure_ai_project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the simulator\n",
    "\n",
    "The interactions between your application (in this case, ask_wiki) and the adversarial simulator is managed by a callback method and this method is used to format the request to your application and the response from the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define a callback that formats the interaction between the simulator and the online endpoint\n",
    "\n",
    "\n",
    "async def callback(\n",
    "    messages: List[Dict],\n",
    "    stream: bool = False,\n",
    "    session_state: Any = None,  # noqa: ANN401\n",
    "    context: Optional[Dict[str, Any]] = None,\n",
    ") -> dict:\n",
    "    messages_list = messages[\"messages\"]\n",
    "    query = messages_list[-1][\"content\"]\n",
    "    context = None\n",
    "    try:\n",
    "        response = call_endpoint(query)\n",
    "        # we are formatting the response to follow the openAI chat protocol format\n",
    "        formatted_response = {\n",
    "            \"content\": response[\"choices\"][0][\"message\"][\"content\"],\n",
    "            \"role\": \"assistant\",\n",
    "            \"context\": {context},\n",
    "        }\n",
    "    except Exception as e:\n",
    "        response = f\"Something went wrong {e!s}\"\n",
    "        formatted_response = None\n",
    "    messages[\"messages\"].append(formatted_response)\n",
    "    return {\"messages\": messages_list, \"stream\": stream, \"session_state\": session_state, \"context\": context}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = await simulator(\n",
    "    scenario=AdversarialScenario.ADVERSARIAL_QA, max_conversation_turns=1, max_simulation_results=1, target=callback\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the outputs to a format that can be evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Path.open(\"outputs.jsonl\", \"w\") as f:\n",
    "    f.write(outputs.to_eval_qa_json_lines())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-azureai-samples",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
