{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate external model endpoints using Prompt Flow Eval APIs\n",
    "\n",
    "## Objective\n",
    "\n",
    "This tutorial provides a step-by-step guide on how to evaluate response from MaaS endpoints deployed on Azure AI Platform, as well as external model endpoints such as model deployed on HuggingFace platform.\n",
    "\n",
    "This guide uses Python Function as a target to evaluate results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install promptflow-evals\n",
    "%pip install promptflow-azure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "\n",
    "import json\n",
    "import requests\n",
    "\n",
    "from typing import List, Tuple, TypedDict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_ai_project = {\n",
    "    \"subscription_id\": \"2d385bf4-0756-4a76-aa95-28bf9ed3b625\",\n",
    "    \"resource_group_name\": \"rg-wjphihub\",\n",
    "    \"project_name\": \"waqasjaved-5368\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We recommend to push endpoint's url and key to .env and use os.getenv(\"\") to access values.\n",
    "\n",
    "TINY_LLAMA_URL=\"https://api-inference.huggingface.co/models/TinyLlama/TinyLlama-1.1B-Chat-v1.0/v1/chat/completions\"\n",
    "TINY_LLAMA_KEY=\"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\"\n",
    "PHI3_MINI_URL=\"https://Phi-3-mini-4k-instruct-rqvel.eastus2.models.ai.azure.com/v1/chat/completions\"\n",
    "PHI3_MINI_KEY=\"J6HAqLPf6jyC0ApRXkXRE0cdSpdINcgm\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"testdata/data.jsonl\", lines=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from func_target import call_external_endpoints\n",
    "\n",
    "\n",
    "from promptflow.evals.evaluators import (\n",
    "    ContentSafetyEvaluator,\n",
    ")\n",
    "from promptflow.evals.evaluate import evaluate\n",
    "\n",
    "content_safety_evaluator = ContentSafetyEvaluator(project_scope=azure_ai_project)\n",
    "\n",
    "results = evaluate(\n",
    "    azure_ai_project=azure_ai_project,\n",
    "    data=\"testdata/data.jsonl\", \n",
    "    target=call_external_endpoints,\n",
    "    evaluators = {\n",
    "        \"content_safety\": content_safety_evaluator\n",
    "        })\n",
    "\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
