{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference a fine-tuned model with function calling - hallucination scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll demonstrate how to inference our fine-tuned model with function calling for the token reduction scenario. \n",
    "\n",
    "After your fine-tuned model is deployed, you can use it like any other deployed model via the chat completion API. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should expect to sepnd 5-10 min running this sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before you begin\n",
    "#### Installation\n",
    "The following packages are required to execute this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the packages\\\n",
    "%pip install requests openai~=1.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_endpoint = \"https://<YOUR_RESOURCE_NAME>.openai.azure.com\"\n",
    "api_version = \"2024-02-15-preview\"\n",
    "aoai_api_key = \"<AOAI_RESOURCE_API_KEY>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run this example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define gpt_test function for inference and initialize an Azure OpenAI client for interaction with the Azure OpenAI service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_test() -> None:\n",
    "    print(\"gpt_inference\")\n",
    "\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_key=aoai_api_key,\n",
    "    api_version=api_version,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets declare function schema. This schema can contain multiple functions which can perform multiple intents. Our stock use case features two functions: the first one retrieves the current stock price, and the second one gets the stock price of last n days. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_current_stock_price\",\n",
    "        \"description\": \"Get the current stock price\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\"symbol\": {\"type\": \"string\", \"description\": \"The stock symbol\"}},\n",
    "            \"required\": [\"symbol\"],\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"get_last_nday_stock_price\",\n",
    "        \"description\": \"Get stock price last n days\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"symbol\": {\"type\": \"string\", \"description\": \"The stock symbol\"},\n",
    "                \"period\": {\"type\": \"string\", \"description\": \"Valid periods: 1d,5d,1mo,3mo,6mo,1y,2y,5y,10y,ytd,max\"},\n",
    "            },\n",
    "            \"required\": [\"symbol\", \"period\"],\n",
    "        },\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets add the content of our test dataset (stock-test-hallucination.jsonl) into a list of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Replace 'Data/stock-test-token-reduction.jsonl' with the actual path to your file\n",
    "file_path = Path(\"Data/stock-test-hallucination.jsonl\")\n",
    "\n",
    "with file_path.open(errors=\"ignore\") as json_file:\n",
    "    json_list = list(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define the message with the question that we want to ask to gpt.\n",
    "\n",
    "This code extracts system and user content from the JSON string, creates a list of messages to be sent to the Azure OpenAI model for completion, sends messages for completion and finally prints the model's completion response along with any errors encountered.\n",
    "\n",
    "we set tempretre as 0 to reduce randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatch_count = 0\n",
    "for i, json_str in enumerate(json_list[:1]):\n",
    "    print(\"starting on \", i)\n",
    "    result = json.loads(json_str)\n",
    "    if len(result[\"messages\"]) > 2:\n",
    "        system_content = result[\"messages\"][0][\"content\"]\n",
    "        user_content = result[\"messages\"][1][\"content\"]\n",
    "    else:\n",
    "        user_content = result[\"messages\"][0][\"content\"]\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_content},\n",
    "        # {\"role\": \"user\", \"content\": user_content},\n",
    "        {\"role\": \"user\", \"content\": \"What was the closing price of Titan Robotics' stock last Friday\"},  # fake company\n",
    "        # {\"role\": \"user\", \"content\": \"What was the highest price that walmart's stock reached last quarter?\"}, # real company\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"<DEPLOYMENT_NAME>\",  # add the fine-tuned model deployment name\n",
    "            messages=messages,\n",
    "            temperature=0.0,  # to reduce randomness\n",
    "            functions=functions,\n",
    "            function_call=\"auto\",\n",
    "        )\n",
    "        try:\n",
    "            response_message = completion.choices[0].message\n",
    "            print(completion.choices[0].message.model_dump_json(indent=2))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Error\", i, completion)\n",
    "            print(e)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error\", i)\n",
    "        print(e)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gpt_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now check the entire test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store results for all examples\n",
    "all_results = []\n",
    "\n",
    "for i, json_str in enumerate(json_list):\n",
    "    print(\"Processing example \", i)\n",
    "    result = json.loads(json_str)\n",
    "    if len(result[\"messages\"]) > 2:\n",
    "        system_content = result[\"messages\"][0][\"content\"]\n",
    "        user_content = result[\"messages\"][1][\"content\"]\n",
    "    else:\n",
    "        user_content = result[\"messages\"][0][\"content\"]\n",
    "\n",
    "    # Construct user message dynamically from the dataset\n",
    "    user_messages = [\n",
    "        {\"role\": \"system\", \"content\": system_content},\n",
    "    ]\n",
    "    for message in result[\"messages\"]:\n",
    "        if message[\"role\"] == \"user\":\n",
    "            user_messages.append({\"role\": \"user\", \"content\": message[\"content\"]})\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"<DEPLOYMENT_NAME>\",  # add the fine-tuned model deployment name\n",
    "            messages=user_messages,\n",
    "            temperature=0.0,  # to reduce randomness\n",
    "            functions=functions,\n",
    "            function_call=\"auto\",\n",
    "        )\n",
    "        try:\n",
    "            response_message = completion.choices[0].message\n",
    "            # Store the result for this example\n",
    "            all_results.append(response_message.model_dump_json(indent=2))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Error\", i, completion)\n",
    "            print(e)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error\", i)\n",
    "        print(e)\n",
    "\n",
    "# Now you have results for all examples in `all_results`\n",
    "# You can save this to a file or process it further as needed\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gpt_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "microsoft": {
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
