{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference a fine-tuned model with function calling - token reduction scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll demonstrate how to inference our fine-tuned model with function calling for the token reduction scenario. \n",
    "\n",
    "After your fine-tuned model is deployed, you can use it like any other deployed model via the chat completion API. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should expect to sepnd 5-10 min running this sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before you begin\n",
    "#### Installation\n",
    "The following packages are required to execute this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the packages\\\n",
    "%pip install requests openai~=1.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "gather": {
     "logged": 1706131730240
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run this example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define gpt_test function for inference and initialize an Azure OpenAI client for interaction with the Azure OpenAI service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "def gpt_test():\n",
    "    print('gpt_inference')\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    #azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    azure_endpoint=\"https://<YOUR_RESOURCE_NAME>.openai.azure.com\",\n",
    "    api_key= \"<AOAI_RESOURCE_API_KEY>\", \n",
    "    api_version=\"2023-07-01-preview\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets declare function schema. This schema can contain multiple functions which can perform multiple intents. Our stock use case features two functions: the first one retrieves the current stock price, and the second one gets the stock price of last n days. \n",
    "\n",
    "This is the shortened version of the function where descriptions and properties from the parameters object have been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "            {\n",
    "                \"name\": \"get_current_stock_price\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                    },\n",
    "                    \"required\": [\n",
    "                        \"symbol\"\n",
    "                    ]\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"get_last_nday_stock_price\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                },\n",
    "                \"required\": [\"symbol\", \"period\"]\n",
    "                }\n",
    "            }\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets add the content of our test dataset (stock-test-token-reduction.jsonl) into a list of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data/stock-test-token-reduction.jsonl', errors='ignore') as json_file:\n",
    "    json_list = list(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define the message with the question that we want to ask to gpt.\n",
    "\n",
    "This code extracts system and user content from the JSON string, creates a list of messages to be sent to the Azure OpenAI model for completion, sends messages for completion and finally prints the model's completion response along with any errors encountered.\n",
    "\n",
    "we set tempretre as 0 to reduce randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatch_count = 0\n",
    "for i, json_str in enumerate(json_list[:1]):\n",
    "    print('starting on ', i)\n",
    "    result = json.loads(json_str)\n",
    "    if len(result['messages']) > 2:\n",
    "        system_content = result['messages'][0]['content']\n",
    "        user_content = result['messages'][1]['content']\n",
    "    else:\n",
    "        user_content = result['messages'][0]['content']\n",
    "\n",
    "    messages = [\n",
    "                    {\"role\": \"system\", \"content\": system_content},\n",
    "                    #{\"role\": \"user\", \"content\": user_content},\n",
    "                    {\"role\": \"user\", \"content\": \"what is the current price of Uber?\"}, \n",
    "                    #{\"role\": \"user\", \"content\": \"What was the highest price that walmart's stock reached last quarter?\"},\n",
    "                ]\n",
    " \n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"<DEPLOYMENT_NAME>\", # add the fine-tuned model deployment name\n",
    "            messages=messages,\n",
    "            temperature=0.0,  # to reduce randomness\n",
    "            functions=functions,\n",
    "            function_call=\"auto\",\n",
    "        )\n",
    "        try:\n",
    "            response_message = completion.choices[0].message\n",
    "            print(completion.choices[0].message.model_dump_json(indent=2))\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print('Error', i, completion)\n",
    "            print(e)\n",
    "\n",
    "    except Exception as e:\n",
    "        print('Error', i)\n",
    "        print(e)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    gpt_test()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "microsoft": {
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
