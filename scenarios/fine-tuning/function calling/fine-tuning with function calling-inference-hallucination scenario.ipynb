{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning with function calling - hallucination scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll demonstrate how to fine-tune an AOAI model using function calling to for hallucination use case.\n",
    "\n",
    "Apart from the dataset, the experience for fine tuning and function calling is the same as training any other model for fine tuning. See the [documentation](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/fine-tuning-functions) for more details.\n",
    "\n",
    "Once the model is fine-tuned, you can utilize the steps outlined below to perform inference with your model.\n",
    "\n",
    "Please note, fine-tuning with function calling is currently available for the gpt-35-turbo (0613) and gpt-35-turbo-16k (1106) models. With support for function calling, you can incorporate functions into your training data, and have your fine-tuned model make function calls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before you begin\n",
    "#### Installation\n",
    "The following packages are required to execute this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the packages\\\n",
    "%pip install requests openai~=1.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "gather": {
     "logged": 1706131730240
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define gpt_test function for inference and initialize an Azure OpenAI client for interaction with the Azure OpenAI service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_test():\n",
    "    print('gpt_inference')\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    #azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    azure_endpoint=\"https://<YOUR_RESOURCE_NAME>.openai.azure.com\",\n",
    "    api_key= \"<AOAI_RESOURCE_API_KEY>\", \n",
    "    api_version=\"2023-07-01-preview\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets declare function schema. This schema can contain multiple functions which can perform multiple intents. Our stock use case features two functions: the first one retrieves the current stock price, and the second one gets the stock price of last n days. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "        {\n",
    "            \"name\": \"get_current_stock_price\",\n",
    "            \"description\": \"Get the current stock price\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"symbol\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The stock symbol\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\n",
    "                    \"symbol\"\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"get_last_nday_stock_price\",\n",
    "            \"description\": \"Get stock price last n days\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"symbol\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The stock symbol\"\n",
    "                    },\n",
    "                    \"period\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Valid periods: 1d,5d,1mo,3mo,6mo,1y,2y,5y,10y,ytd,max\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"symbol\", \"period\"]\n",
    "            }\n",
    "        },\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets add the content of our test dataset (stock-test-hallucination.jsonl) into a list of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('<provide path to test dataset>', errors='ignore') as json_file:\n",
    "    json_list = list(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define the message with the question that we want to ask to gpt.\n",
    "\n",
    "This code extracts system and user content from the JSON string, creates a list of messages to be sent to the Azure OpenAI model for completion, sends messages for completion and finally prints the model's completion response along with any errors encountered.\n",
    "\n",
    "we set tempretre as 0 to reduce randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatch_count = 0\n",
    "for i, json_str in enumerate(json_list[:1]):\n",
    "    print('starting on ', i)\n",
    "    result = json.loads(json_str)\n",
    "    if len(result['messages']) > 2:\n",
    "        system_content = result['messages'][0]['content']\n",
    "        user_content = result['messages'][1]['content']\n",
    "    else:\n",
    "        user_content = result['messages'][0]['content']\n",
    "\n",
    "    messages = [\n",
    "                    {\"role\": \"system\", \"content\": system_content},\n",
    "                    #{\"role\": \"user\", \"content\": user_content},\n",
    "                    {\"role\": \"user\", \"content\": \"What was the closing price of Titan Robotics' stock last Friday\"}, # fake company\n",
    "                    #{\"role\": \"user\", \"content\": \"What was the highest price that walmart's stock reached last quarter?\"}, # real company\n",
    "                ]\n",
    " \n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"<DEPLOYMENT_NAME>\",\n",
    "            messages=messages,\n",
    "            temperature=0.0,  # to reduce randomness\n",
    "            functions=functions,\n",
    "            function_call=\"auto\",\n",
    "        )\n",
    "        try:\n",
    "            response_message = completion.choices[0].message\n",
    "            print(completion.choices[0].message.model_dump_json(indent=2))\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print('Error', i, completion)\n",
    "            print(e)\n",
    "\n",
    "    except Exception as e:\n",
    "        print('Error', i)\n",
    "        print(e)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    gpt_test()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "microsoft": {
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
