{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using fine-tuned function calling models in an e2e application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function calling only creates the call to an external API – it doesn’t execute it. To actually execute the request, you’ll need to extract the function name and arguments from the LLM response and proceed to call the function with those arguments. The function's output is in JSON format, which is then passed back to gpt-35-turbo to generate an appropriate result message for the user. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should expect to sepnd 5-10 min running this sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before you begin\n",
    "#### Installation\n",
    "The following packages are required to execute this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the packages\\\n",
    "%pip install requests openai~=1.10 yfinance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_endpoint = \"https://<YOUR_RESOURCE_NAME>.openai.azure.com\"\n",
    "api_version = \"2024-02-15-preview\"\n",
    "aoai_api_key = \"<AOAI_RESOURCE_API_KEY>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the E2E example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the below two functions:\n",
    "\n",
    "**get_current_stock_price(symbol):** This function takes a stock symbol as input, retrieves information about the current stock price using the yfinance library (yf), and returns a JSON-formatted string containing the symbol and current price.\n",
    "\n",
    "**get_last_nday_stock_price(symbol, period):** This function takes a stock symbol and a period as inputs, retrieves historical stock price data for the specified period using the yfinance library (yf), converts the data to a Pandas DataFrame, and then converts the DataFrame to a JSON-formatted string before returning it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_stock_price(symbol: str) -> str:\n",
    "    ticker = yf.Ticker(symbol).info\n",
    "    info = {}\n",
    "    if \"currentPrice\" in ticker:\n",
    "        market_price = ticker[\"currentPrice\"]\n",
    "        info = {\"symbol\": symbol, \"current_price\": market_price}\n",
    "    else:\n",
    "        print(f\"{symbol} is not valid.\")\n",
    "    return json.dumps(info)\n",
    "\n",
    "\n",
    "def get_last_nday_stock_price(symbol: str, period: str) -> str:\n",
    "    stock = yf.Ticker(symbol)\n",
    "    data = stock.history(period=period)\n",
    "    df = pd.DataFrame(data)\n",
    "    return df.to_json(orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define gpt_test function for inference and initialize an Azure OpenAI client for interaction with the Azure OpenAI service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_test() -> None:\n",
    "    print(\"gpt_inference\")\n",
    "\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_key=aoai_api_key,\n",
    "    api_version=api_version,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets declare function schema. This schema can contain multiple functions which can perform multiple intents. Our stock use case features two functions: the first one retrieves the current stock price, and the second one gets the stock price of last n days. \n",
    "\n",
    "For the hallucination use case, you should select the full function, whereas for the token reduction scenario, you should select the shortened function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full function for hallucination use case\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_current_stock_price\",\n",
    "        \"description\": \"Get the current stock price\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\"symbol\": {\"type\": \"string\", \"description\": \"The stock symbol\"}},\n",
    "            \"required\": [\"symbol\"],\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"get_last_nday_stock_price\",\n",
    "        \"description\": \"Get stock price last n days\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"symbol\": {\"type\": \"string\", \"description\": \"The stock symbol\"},\n",
    "                \"period\": {\"type\": \"string\", \"description\": \"Valid periods: 1d,5d,1mo,3mo,6mo,1y,2y,5y,10y,ytd,max\"},\n",
    "            },\n",
    "            \"required\": [\"symbol\", \"period\"],\n",
    "        },\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# short function for token reduction use case\n",
    "functions = [\n",
    "    {\"name\": \"get_current_stock_price\", \"parameters\": {\"type\": \"object\", \"properties\": {}, \"required\": [\"symbol\"]}},\n",
    "    {\n",
    "        \"name\": \"get_last_nday_stock_price\",\n",
    "        \"parameters\": {\"type\": \"object\", \"properties\": {}, \"required\": [\"symbol\", \"period\"]},\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets add the content of our test dataset into a list of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Replace '<provide path to test dataset>' with the actual path to your test dataset\n",
    "file_path = Path(\"<provide path to test dataset>\")\n",
    "\n",
    "with file_path.open(errors=\"ignore\") as json_file:\n",
    "    json_list = list(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we would like to use our fine-tuned function calling models in an e2e application. Here is the steps:\n",
    "- Define the message with the question that you want to ask to GPT.\n",
    "- Extract the system and user content from the JSON string.\n",
    "- Create a list of messages to be sent to the Azure OpenAI model for completion.\n",
    "- Send the messages for completion, setting the temperature as 0 to reduce randomness.\n",
    "- Retrieve the function name and its arguments from the response_message object.\n",
    "- Call the \"get_current_stock_price\" or \"get_last_nday_stock_price\" functions by passing those arguments.\n",
    "- As the function’s output is still in JSON format, pass the JSON back to gpt-35-turbo model so that it can generate the appropriate result message for display to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatch_count = 0\n",
    "for i, json_str in enumerate(json_list[:1]):\n",
    "    print(\"starting on \", i)\n",
    "    result = json.loads(json_str)\n",
    "    if len(result[\"messages\"]) > 2:\n",
    "        system_content = result[\"messages\"][0][\"content\"]\n",
    "        user_content = result[\"messages\"][1][\"content\"]\n",
    "    else:\n",
    "        user_content = result[\"messages\"][0][\"content\"]\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_content},\n",
    "        # {\"role\": \"user\", \"content\": user_content},\n",
    "        {\"role\": \"user\", \"content\": \"what is the current price of Uber?\"},  # token reduction\n",
    "        # {\"role\": \"user\", \"content\": \"What was the highest price that walmart's stock reached last quarter?\"}, #token reduction\n",
    "        # {\"role\": \"user\", \"content\": \"What was the closing price of Titan Robotics' stock last Friday\"}, #hallucination\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"<DEPLOYMENT_NAME>\",\n",
    "            messages=messages,\n",
    "            temperature=0.0,  # to reduce randomness\n",
    "            functions=functions,\n",
    "            function_call=\"auto\",\n",
    "        )\n",
    "        try:\n",
    "            response_message = completion.choices[0].message\n",
    "            print(completion.choices[0].message.model_dump_json(indent=2))\n",
    "\n",
    "            # Check if the model wants to call a function\n",
    "            function_calls = response_message.function_call\n",
    "            if function_calls:\n",
    "                function_name = response_message.function_call.name\n",
    "                available_functions = {\n",
    "                    \"get_current_stock_price\": get_current_stock_price,\n",
    "                    \"get_last_nday_stock_price\": get_last_nday_stock_price,\n",
    "                }\n",
    "                function_to_call = available_functions[function_name]\n",
    "\n",
    "                function_args = json.loads(response_message.function_call.arguments)\n",
    "                function_response = function_to_call(**function_args)\n",
    "\n",
    "                # Add the assistant response and function response to the messages\n",
    "                messages.append(  # adding assistant response to messages\n",
    "                    {\n",
    "                        \"role\": response_message.role,\n",
    "                        \"function_call\": {\n",
    "                            \"name\": function_name,\n",
    "                            \"arguments\": response_message.function_call.arguments,\n",
    "                        },\n",
    "                        \"content\": None,\n",
    "                    }\n",
    "                )\n",
    "                messages.append(  # adding function response to messages\n",
    "                    {\n",
    "                        \"role\": \"function\",\n",
    "                        \"name\": function_name,\n",
    "                        \"content\": function_response,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                # Call the API again to get the final response from the model\n",
    "                second_response = client.chat.completions.create(\n",
    "                    model=\"<DEPLOYMENT_NAME>\",  # gpt-35-turbo-0613\n",
    "                    messages=messages,\n",
    "                )\n",
    "                print(second_response.choices[0].message.content)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Error\", i, completion)\n",
    "            print(e)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error\", i)\n",
    "        print(e)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gpt_test()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "microsoft": {
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
