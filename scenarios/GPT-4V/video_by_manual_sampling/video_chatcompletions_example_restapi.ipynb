{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "759f9ec0",
   "metadata": {},
   "source": [
    "# REST API Video Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0cfcba",
   "metadata": {},
   "source": [
    "## Objective\n",
    "Conducting Q&A with video inputs in GPT-4 Turbo with Vision.\t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbbcb1f",
   "metadata": {},
   "source": [
    "## Time\n",
    "\n",
    "You should expect to spend 5-10 minutes running this sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13636fdc",
   "metadata": {},
   "source": [
    "## Before you begin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bbb7da",
   "metadata": {},
   "source": [
    "### Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c52a354",
   "metadata": {},
   "source": [
    "- An Azure subscription - [Create one for free](https://azure.microsoft.com/free/cognitive-services/)\n",
    "- An Azure AI resource. For guidance on setting up an Azure AI resource, see: [How to create and manage an Azure AI resource](https://review.learn.microsoft.com/en-us/azure/ai-studio/how-to/create-azure-ai-resource?branch=main)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1232525c",
   "metadata": {},
   "source": [
    "#### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970ab502",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2d4a0f",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "You need to set a series of configurations such as GPT-4V_DEPLOYMENT_NAME, OPENAI_API_BASE, OPENAI_API_VERSION.\n",
    "\n",
    "Add \"OPENAI_API_KEY\" as variable name and \\<Your API Key Value\\> as variable value in the environment variables.\n",
    " <br>\n",
    "      \n",
    "      WINDOWS Users: \n",
    "         setx OPENAI_API_KEY \"REPLACE_WITH_YOUR_KEY_VALUE_HERE\"\n",
    "         \n",
    "      MACOS/LINUX Users: \n",
    "         export OPENAI_API_KEY=\"REPLACE_WITH_YOUR_KEY_VALUE_HERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57086a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the deployment name\n",
    "deployment_name: str = \"<your GPT-4 Turbo with Vision deployment name>\"\n",
    "# The base URL for your Azure OpenAI resource. e.g. \"https://<your resource name>.openai.azure.com\"\n",
    "openai_api_base: str = \"<your resource base URL>\"\n",
    "# Currently OPENAI API have the following versions available: 2022-12-01.\n",
    "# All versions follow the YYYY-MM-DD date structure.\n",
    "openai_api_version: str = \"<your OpenAI API version>\"\n",
    "\n",
    "# Insert your video SAS URL, e.g. https://<your-storage-account-name>.blob.core.windows.net/<your-container-name>/<your-video-name>?<SAS-token>\n",
    "video_SAS_url: str = \"https://gpt4vsamples.blob.core.windows.net/videos/Microsoft%20Copilot%20Short.mp4\"\n",
    "\n",
    "should_cleanup: bool = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b0f8ef",
   "metadata": {},
   "source": [
    "## Connect to your project\n",
    "To start with let us create a config file with your project details. This file can be used in this sample or other samples to connect to your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3d52d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "config = {\n",
    "    \"GPT-4V_DEPLOYMENT_NAME\": deployment_name,\n",
    "    \"OPENAI_API_BASE\": openai_api_base,\n",
    "    \"OPENAI_API_VERSION\": openai_api_version,\n",
    "}\n",
    "\n",
    "p = Path(\"../config.json\")\n",
    "\n",
    "with p.open(mode=\"w\") as file:\n",
    "    file.write(json.dumps(config))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b60b2a",
   "metadata": {},
   "source": [
    "## Run this Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd85fb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "\n",
    "parent_dir = Path(Path.cwd()).parent\n",
    "sys.path.append(str(parent_dir))\n",
    "from shared_functions import call_GPT4V, sample_frames, download_video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feabcd3f",
   "metadata": {},
   "source": [
    "### Call GPT-4 Turbo with Vision API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6165c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "# System messages and user prompt\n",
    "sys_message = \"\"\"\n",
    "Your task is to assist in analyzing and optimizing creative assets. \n",
    "You will be presented with advertisement videos for products. \n",
    "First describe the video in detail paying close attention to Product characteristics highlighted, \n",
    "Background images, Lighting, Color Palette and Human characteristics for persons in the video. \n",
    "Finally provide a summary of the video and talk about the main message the advertisement video tries to convey to the viewer. \n",
    "\"\"\"\n",
    "user_prompt = \"Summarize the ad video.\"\n",
    "\n",
    "local_file_path = \"downloaded_video.mp4\"\n",
    "assert download_video(video_SAS_url, local_file_path), \"Failed to download video.\"\n",
    "\n",
    "num_frames_to_sample = 10\n",
    "video = VideoFileClip(local_file_path)\n",
    "base64_frames = sample_frames(video, num_frames_to_sample)\n",
    "content = [{\"type\": \"text\", \"text\": user_prompt}]\n",
    "content.append({\"type\": \"text\", \"text\": f\"Below are {num_frames_to_sample} frames uniformly sampled from the video.\"})\n",
    "for frame in base64_frames:\n",
    "    content.append({\"type\": \"text\", \"text\": f\"Frame at time {frame[0]} seconds:\"})\n",
    "    content.append({\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpg;base64,{frame[1]}\", \"detail\": \"low\"}})\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": sys_message}]},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": content,\n",
    "    },  # Prompt for the user\n",
    "]\n",
    "\n",
    "# Call GPT-4 Turbo with Vision API and print the response\n",
    "try:\n",
    "    response = call_GPT4V(messages)\n",
    "    text = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    sentences = re.split(r\"(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s\", text)\n",
    "    for sentence in sentences:  # Print the content of the response\n",
    "        print(sentence)\n",
    "except Exception as e:\n",
    "    print(f\"Failed to call GPT-4 Turbo with Vision API. Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154e4343",
   "metadata": {},
   "source": [
    "## Cleaning up\n",
    "\n",
    "To clean up all Azure ML resources used in this example, you can delete the individual resources you created in this tutorial.\n",
    "\n",
    "If you made a resource group specifically to run this example, you could instead [delete the resource group](https://learn.microsoft.com/en-us/azure/azure-resource-manager/management/delete-resource-group)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb64f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "if should_cleanup:\n",
    "    Path(local_file_path).unlink()  # Delete the downloaded video\n",
    "    # {{TODO: Add resource cleanup}}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
