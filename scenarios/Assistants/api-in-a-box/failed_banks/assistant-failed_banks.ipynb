{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Failed Banks Information Assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "This notebook demonstrates the following:\n",
    "\n",
    "- Using Assistant tools Code Interpreter and Function calling, this bot can get a CSV file, gather a list of failed banks by state, and generate a chart to visually represent the data.\n",
    "\n",
    "This tutorial uses the following Azure AI services:\n",
    "- Access to Azure OpenAI Service - you can apply for access [here](https://aka.ms/oai/access)\n",
    "- Azure OpenAI service - you can create it from instructions [here](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/create-resource)\n",
    "- Azure OpenAI Studio - go to [https://oai.azure.com/](https://oai.azure.com/) to work with the Assistants API Playground\n",
    "- A connection to the Azure OpenAI Service with a [Key and Endpoint](https://learn.microsoft.com/en-us/azure/ai-services/openai/chatgpt-quickstart)\n",
    "\n",
    "Reference:\n",
    "- Learn more about how to use Assistants with our [How-to guide on Assistants](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/assistant)\n",
    "- [Assistants OpenAI Overview](https://platform.openai.com/docs/assistants/overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time\n",
    "\n",
    "You should expect to spend 5-10 minutes running this sample. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this example\n",
    "\n",
    "This sample demonstrates the creation of an Azure OpenAI Assistant named \"Failed Banks Assistant\" through the Azure OpenAI API. The assistant is tailored to aid users in retrieving information about failed banks from a CSV file, the assistant efficiently processes user messages, interacts with the designated file, and promptly delivers pertinent information in response.\n",
    "\n",
    "### Data\n",
    "This sample uses files from the folder [`data/`](./data/) in this repo. You can clone this repo or copy this folder to make sure you have access to these files when running the sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation\n",
    "\n",
    "Install the following packages required to execute this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the packages\n",
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../.env\")  # make sure to have the .env file in the root directory of the project\n",
    "\n",
    "api_endpoint = os.getenv(\"OPENAI_URI\")\n",
    "api_key = os.getenv(\"OPENAI_KEY\")\n",
    "api_version = os.getenv(\"OPENAI_VERSION\")\n",
    "api_deployment_name = os.getenv(\"OPENAI_GPT_DEPLOYMENT\")\n",
    "email_URI = os.getenv(\"EMAIL_URI\")\n",
    "\n",
    "should_cleanup: bool = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run this Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Iterable\n",
    "\n",
    "from openai import AzureOpenAI\n",
    "from openai.types import FileObject\n",
    "from openai.types.beta.threads.message_content_image_file import MessageContentImageFile\n",
    "from openai.types.beta.threads.message_content_text import MessageContentText\n",
    "from openai.types.beta.threads.messages import MessageFile\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an Azure OpenAI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AzureOpenAI(api_key=api_key, api_version=api_version, azure_endpoint=api_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the tools for function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_list = [\n",
    "    {\"type\": \"code_interpreter\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"data/\"\n",
    "\n",
    "def upload_file(client: AzureOpenAI, path: str) -> FileObject:\n",
    "    with Path(path).open(\"rb\") as f:\n",
    "        return client.files.create(file=f, purpose=\"assistants\")\n",
    "\n",
    "arr = os.listdir(DATA_FOLDER)\n",
    "assistant_files = []\n",
    "for file in arr:\n",
    "    filePath = DATA_FOLDER + file\n",
    "    assistant_files.append(upload_file(client, filePath))\n",
    "\n",
    "file_ids = [file.id for file in assistant_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an Assistant and a Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "    name=\"Failed Banks Assistant\",\n",
    "    instructions=\"You are an assistant that can help find information about failed banks. \"\n",
    "    + \"Use the provided file only.\",\n",
    "    tools=tools_list,\n",
    "    model=api_deployment_name,\n",
    "    file_ids=file_ids,\n",
    ")\n",
    "\n",
    "thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format and display the Assistant Messages for text and images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_assistant_file(file_id:str):\n",
    "    response_content = client.files.content(file_id)\n",
    "    return response_content.read()\n",
    "\n",
    "def print_messages(messages: Iterable[MessageFile]) -> None:\n",
    "    message_list = []\n",
    "\n",
    "    # Get all the messages till the last user message\n",
    "    for message in messages:\n",
    "        message_list.append(message)\n",
    "        if message.role == \"user\":\n",
    "            break\n",
    "\n",
    "    # Reverse the messages to show the last user message first\n",
    "    message_list.reverse()\n",
    "\n",
    "    # Print the user or Assistant messages or images\n",
    "    for message in message_list:\n",
    "        for item in message.content:\n",
    "            # Determine the content type\n",
    "            if isinstance(item, MessageContentText):\n",
    "                print(f\"{message.role}:\\n{item.text.value}\\n\")\n",
    "                file_annotations = item.text.annotations\n",
    "                if file_annotations:\n",
    "                    for annotation in file_annotations:\n",
    "                        file_id = annotation.file_path.file_id\n",
    "                        content = read_assistant_file(file_id)\n",
    "                        print(f\"Annotation Content:\\n{str(content)}\\n\")\n",
    "            elif isinstance(item, MessageContentImageFile):\n",
    "                # Retrieve image from file id                \n",
    "                data_in_bytes = read_assistant_file(item.image_file.file_id)\n",
    "                # Convert bytes to image\n",
    "                readable_buffer = io.BytesIO(data_in_bytes)\n",
    "                image = Image.open(readable_buffer)\n",
    "                # Resize image to fit in terminal\n",
    "                width, height = image.size\n",
    "                image = image.resize((width // 2, height // 2), Image.LANCZOS)\n",
    "                # Display image\n",
    "                image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the user messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_prompt(prompt: str) -> None:\n",
    "    client.beta.threads.messages.create(thread_id=thread.id, role=\"user\", content=prompt)\n",
    "    run = client.beta.threads.runs.create(\n",
    "        thread_id=thread.id,\n",
    "        assistant_id=assistant.id,\n",
    "        instructions=\"Please address the user as Jane Doe. The user has a premium account. Be assertive, accurate, and polite. Ask if the user has further questions. \"\n",
    "        + \"The current date and time is: \"\n",
    "        + datetime.now().strftime(\"%x %X\")\n",
    "        + \". \",\n",
    "    )\n",
    "    print(\"processing ...\")\n",
    "    while True:\n",
    "        run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "        if run.status == \"completed\":\n",
    "            # Handle completed\n",
    "            messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "            print_messages(messages)\n",
    "            break\n",
    "        if run.status == \"failed\":\n",
    "            messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "            answer = messages.data[0].content[0].text.value\n",
    "            print(f\"Failed User:\\n{prompt}\\nAssistant:\\n{answer}\\n\")\n",
    "            # Handle failed\n",
    "            break\n",
    "        if run.status == \"expired\":\n",
    "            # Handle expired\n",
    "            print(run)\n",
    "            break\n",
    "        if run.status == \"cancelled\":\n",
    "            # Handle cancelled\n",
    "            print(run)\n",
    "            break\n",
    "        if run.status == \"requires_action\":\n",
    "            # Handle function calling and continue processing\n",
    "            pass\n",
    "        else:\n",
    "            time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process user requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_prompt(\"Create a chart of failed banks by state.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_prompt(\"What was the last bank to fail?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_prompt(\"Which state has the most bank failures?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_prompt(\"Which banks failed in Florida in between 2020-2023?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if should_cleanup:\n",
    "    client.beta.assistants.delete(assistant.id)\n",
    "    client.beta.threads.delete(thread.id)\n",
    "    for file in assistant_files:\n",
    "        client.files.delete(file.id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
