{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Failed Banks Information Assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "This notebook demonstrates the following:\n",
    "\n",
    "- Using Assistant tools Code Interpreter and Function calling, this bot can get a CSV file, gather a list of failed banks by state, and generate a chart to visually represent the data.\n",
    "\n",
    "This tutorial uses the following Azure AI services:\n",
    "- Access to Azure OpenAI Service - you can apply for access [here](https://aka.ms/oai/access)\n",
    "- Azure OpenAI service - you can create it from instructions [here](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/create-resource)\n",
    "- Azure OpenAI Studio - go to [https://oai.azure.com/](https://oai.azure.com/) to work with the Assistants API Playground\n",
    "- A connection to the Azure OpenAI Service with a [Key and Endpoint](https://learn.microsoft.com/en-us/azure/ai-services/openai/chatgpt-quickstart)\n",
    "\n",
    "Reference:\n",
    "- Learn more about how to use Assistants with our [How-to guide on Assistants](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/assistant).\n",
    "- [Assistants OpenAI Overview](https://platform.openai.com/docs/assistants/overview)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time\n",
    "\n",
    "You should expect to spend 5-10 minutes running this sample. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this example\n",
    "\n",
    "This sample demonstrates the creation of an Azure OpenAI Assistant named \"Failed Banks Assistant\" through the Azure OpenAI API. The assistant is tailored to aid users in retrieving information about failed banks from a CSV file, the assistant efficiently processes user messages, interacts with the designated file, and promptly delivers pertinent information in response.\n",
    "\n",
    "### Data\n",
    "This sample uses files from the folder [`data/`](./data/) in this repo. You can clone this repo or copy this folder to make sure you have access to these files when running the sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you begin\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation\n",
    "\n",
    "Install the following packages required to execute this notebook. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the packages\n",
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../.env\")\n",
    "\n",
    "api_endpoint = os.getenv(\"OPENAI_URI\")\n",
    "api_key = os.getenv(\"OPENAI_KEY\")\n",
    "api_version = os.getenv(\"OPENAI_VERSION\")\n",
    "api_deployment_name = os.getenv(\"OPENAI_GPT_DEPLOYMENT\")\n",
    "email_URI = os.getenv(\"EMAIL_URI\")\n",
    "\n",
    "should_cleanup: bool = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run this Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Iterable\n",
    "from PIL import Image\n",
    "\n",
    "from openai import AzureOpenAI\n",
    "from openai.types import FileObject\n",
    "from openai.types.beta.threads import Message, TextContentBlock, ImageFileContentBlock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an AzureOpenAI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AzureOpenAI(api_key=api_key, api_version=api_version, azure_endpoint=api_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the tools for function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_list = [\n",
    "    {\"type\": \"code_interpreter\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"data/\"\n",
    "\n",
    "\n",
    "def upload_file(client: AzureOpenAI, path: str) -> FileObject:\n",
    "    with Path(path).open(\"rb\") as f:\n",
    "        return client.files.create(file=f, purpose=\"assistants\")\n",
    "\n",
    "\n",
    "arr = os.listdir(DATA_FOLDER)\n",
    "assistant_files = []\n",
    "for file in arr:\n",
    "    filePath = DATA_FOLDER + file\n",
    "    assistant_files.append(upload_file(client, filePath))\n",
    "\n",
    "file_ids = [file.id for file in assistant_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "    name=\"Failed Banks Assistant\",\n",
    "    instructions=\"You are an assistant that can help find information about failed banks. \"\n",
    "    + \"Use the provided file only.\",\n",
    "    tools=tools_list,\n",
    "    model=api_deployment_name,\n",
    "    tool_resources={\"code_interpreter\": {\"file_ids\": file_ids}},\n",
    ")\n",
    "\n",
    "thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_messages(messages: Iterable[Message]) -> None:\n",
    "    message_list = []\n",
    "\n",
    "    # Get all the messages till the last user message\n",
    "    for message in messages:\n",
    "        message_list.append(message)\n",
    "        if message.role == \"user\":\n",
    "            break\n",
    "\n",
    "    # Reverse the messages to show the last user message first\n",
    "    message_list.reverse()\n",
    "\n",
    "    # Print the user or Assistant messages or images\n",
    "    for message in message_list:\n",
    "        for item in message.content:\n",
    "            # Determine the content type\n",
    "            if isinstance(item, TextContentBlock):\n",
    "                print(f\"{message.role}:\\n{item.text.value}\\n\")\n",
    "            elif isinstance(item, ImageFileContentBlock):\n",
    "                # Retrieve image from file id\n",
    "                response_content = client.files.content(item.image_file.file_id)\n",
    "                data_in_bytes = response_content.read()\n",
    "                # Convert bytes to image\n",
    "                readable_buffer = io.BytesIO(data_in_bytes)\n",
    "                image = Image.open(readable_buffer)\n",
    "                # Resize image to fit in terminal\n",
    "                width, height = image.size\n",
    "                image = image.resize((width // 2, height // 2), Image.LANCZOS)\n",
    "                # Display image\n",
    "                image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_message(content: str) -> None:\n",
    "    client.beta.threads.messages.create(thread_id=thread.id, role=\"user\", content=content)\n",
    "\n",
    "    run = client.beta.threads.runs.create(\n",
    "        thread_id=thread.id,\n",
    "        assistant_id=assistant.id,\n",
    "        instructions=\"The current date and time is: \" + datetime.now().strftime(\"%x %X\") + \".\",\n",
    "    )\n",
    "\n",
    "    print(\"processing ...\")\n",
    "    completed_run = client.beta.threads.runs.poll(run_id=run.id, thread_id=thread.id)\n",
    "\n",
    "    # Check final status and handle accordingly\n",
    "    if completed_run.status == \"completed\":\n",
    "        print(\"Run completed successfully.\")\n",
    "        messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "        format_messages(messages)\n",
    "    elif completed_run.status == \"failed\":\n",
    "        print(\"Run failed.\")\n",
    "        messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "        format_messages(messages)\n",
    "    else:\n",
    "        print(f\"Unexpected run status: {completed_run.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process user requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_message(\"Create a chart of failed banks by state.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_message(\"What was the last bank to fail?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_message(\"Which state has the most bank failures?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_message(\"Which banks failed in Florida in between 2020-2023?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if should_cleanup:\n",
    "    client.beta.assistants.delete(assistant.id)\n",
    "    client.beta.threads.delete(thread.id)\n",
    "    for file in assistant_files:\n",
    "        client.files.delete(file.id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
