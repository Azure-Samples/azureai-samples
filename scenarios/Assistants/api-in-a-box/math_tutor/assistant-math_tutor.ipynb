{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math Tutor Assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "This notebook demonstrates the following:\n",
    "\n",
    "- Showcases the foundational concepts of Assistants such as Threads, Messages, Runs, Tools, and lifecycle management.\n",
    "\n",
    "This tutorial uses the following Azure AI services:\n",
    "- Access to Azure OpenAI Service - you can apply for access [here](https://aka.ms/oai/access)\n",
    "- Azure OpenAI service - you can create it from instructions [here](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/create-resource)\n",
    "- Azure OpenAI Studio - go to [https://oai.azure.com/](https://oai.azure.com/) to work with the Assistants API Playground\n",
    "- A connection to the Azure OpenAI Service with a [Key and Endpoint](https://learn.microsoft.com/en-us/azure/ai-services/openai/chatgpt-quickstart)\n",
    "\n",
    "Reference:\n",
    "- Learn more about how to use Assistants with our [How-to guide on Assistants](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/assistant)\n",
    "- [Assistants OpenAI Overview](https://platform.openai.com/docs/assistants/overview)\n",
    "- [Github-OpenAI Python/examples/Assistant demo notebook](https://github.com/openai/openai-python/blob/main/examples/assistant.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time\n",
    "\n",
    "You should expect to spend 5-10 minutes running this sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this example\n",
    "\n",
    "This sample shows users how to create an Azure OpenAI Assistant named \"Math Tutor\" using the Azure OpenAI API. The assistant is designed to function as a personal math tutor, capable of answering math questions through code interpretation. The script initiates a conversation with the assistant, guiding it through various mathematical queries and scenarios to showcase its capabilities.\n",
    "\n",
    "This sample provides developers with a clear demonstration of how to leverage the core concepts of the Assistants API into their projects, highlighting its simplicity and effectiveness in leveraging foundational concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation\n",
    "\n",
    "Install the following packages required to execute this notebook. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the packages\n",
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../.env\")  # make sure to have the .env file in the root directory of the project\n",
    "\n",
    "api_endpoint = os.getenv(\"OPENAI_URI\")\n",
    "api_key = os.getenv(\"OPENAI_KEY\")\n",
    "api_version = os.getenv(\"OPENAI_VERSION\")\n",
    "api_deployment_name = os.getenv(\"OPENAI_GPT_DEPLOYMENT\")\n",
    "\n",
    "should_cleanup: bool = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run this Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import time\n",
    "from datetime import datetime\n",
    "from typing import Iterable\n",
    "\n",
    "from openai import AzureOpenAI\n",
    "from openai.types.beta.threads.message_content_image_file import MessageContentImageFile\n",
    "from openai.types.beta.threads.message_content_text import MessageContentText\n",
    "from openai.types.beta.threads.messages import MessageFile\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an Azure OpenAI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AzureOpenAI(api_key=api_key, api_version=api_version, azure_endpoint=api_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an Assistant and a Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "    name=\"Math Tutor\",\n",
    "    instructions=\"You are a personal math tutor. Write and run code to answer math questions.\",\n",
    "    tools=[{\"type\": \"code_interpreter\"}],\n",
    "    model=api_deployment_name,\n",
    ")\n",
    "\n",
    "thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format and display the Assistant Messages for text and images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_assistant_file(file_id:str):\n",
    "    response_content = client.files.content(file_id)\n",
    "    return response_content.read()\n",
    "\n",
    "def print_messages(messages: Iterable[MessageFile]) -> None:\n",
    "    message_list = []\n",
    "\n",
    "    # Get all the messages till the last user message\n",
    "    for message in messages:\n",
    "        message_list.append(message)\n",
    "        if message.role == \"user\":\n",
    "            break\n",
    "\n",
    "    # Reverse the messages to show the last user message first\n",
    "    message_list.reverse()\n",
    "\n",
    "    # Print the user or Assistant messages or images\n",
    "    for message in message_list:\n",
    "        for item in message.content:\n",
    "            # Determine the content type\n",
    "            if isinstance(item, MessageContentText):\n",
    "                print(f\"{message.role}:\\n{item.text.value}\\n\")\n",
    "                file_annotations = item.text.annotations\n",
    "                if file_annotations:\n",
    "                    for annotation in file_annotations:\n",
    "                        file_id = annotation.file_path.file_id\n",
    "                        content = read_assistant_file(file_id)\n",
    "                        print(f\"Annotation Content:\\n{str(content)}\\n\")\n",
    "            elif isinstance(item, MessageContentImageFile):\n",
    "                # Retrieve image from file id                \n",
    "                data_in_bytes = read_assistant_file(item.image_file.file_id)\n",
    "                # Convert bytes to image\n",
    "                readable_buffer = io.BytesIO(data_in_bytes)\n",
    "                image = Image.open(readable_buffer)\n",
    "                # Resize image to fit in terminal\n",
    "                width, height = image.size\n",
    "                image = image.resize((width // 2, height // 2), Image.LANCZOS)\n",
    "                # Display image\n",
    "                image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the user messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_prompt(prompt: str) -> None:\n",
    "    client.beta.threads.messages.create(thread_id=thread.id, role=\"user\", content=prompt)\n",
    "    run = client.beta.threads.runs.create(\n",
    "        thread_id=thread.id,\n",
    "        assistant_id=assistant.id,\n",
    "        instructions=\"Please address the user as Jane Doe. The user has a premium account. Be assertive, accurate, and polite. Ask if the user has further questions. \"\n",
    "        + \"The current date and time is: \"\n",
    "        + datetime.now().strftime(\"%x %X\")\n",
    "        + \". \",\n",
    "    )\n",
    "    print(\"processing ...\")\n",
    "    while True:\n",
    "        run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "        if run.status == \"completed\":\n",
    "            # Handle completed\n",
    "            messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "            print_messages(messages)\n",
    "            break\n",
    "        if run.status == \"failed\":\n",
    "            messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "            answer = messages.data[0].content[0].text.value\n",
    "            print(f\"Failed User:\\n{prompt}\\nAssistant:\\n{answer}\\n\")\n",
    "            # Handle failed\n",
    "            break\n",
    "        if run.status == \"expired\":\n",
    "            # Handle expired\n",
    "            print(run)\n",
    "            break\n",
    "        if run.status == \"cancelled\":\n",
    "            # Handle cancelled\n",
    "            print(run)\n",
    "            break\n",
    "        if run.status == \"requires_action\":\n",
    "            # Handle function calling and continue processing\n",
    "            pass\n",
    "        else:\n",
    "            time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Have a conversation with the Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_prompt(\"What is the linear equation when two (x,y) points are (1,1) and (5,10)?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_prompt(\"I need to solve the equation `3x + 11 = 14`. Can you help me?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_prompt(\"\"\"x=r*cos(u)sin(v), y=r*sin(u)sin(v), r=2+sin(7*u+5*v) for 0<u<2π and 0<v<π.\n",
    "Create a graph of the equation z=r*cos(v).\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_prompt(\"create a csv file with 10 customer names\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if should_cleanup:\n",
    "    client.beta.assistants.delete(assistant.id)\n",
    "    client.beta.threads.delete(thread.id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
