{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-ai-inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage\n",
    "from azure.ai.inference.models import UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "\n",
    "from azure.ai.inference.models import TextContentItem, ImageContentItem, ImageUrl, ImageDetailLevel\n",
    "\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=\"\",\n",
    "    credential=AzureKeyCredential(\"\"),\n",
    ")\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        UserMessage(\n",
    "            content=[\n",
    "                TextContentItem(text=\"What do you see in these images?\"),\n",
    "                ImageContentItem(\n",
    "                    image_url=ImageUrl.load(\n",
    "                        image_file=\"image1.jpg\",\n",
    "                        image_format=\"png\",\n",
    "                        detail=ImageDetailLevel.HIGH,\n",
    "                    ),\n",
    "                ),\n",
    "                ImageContentItem(\n",
    "                    image_url=ImageUrl(\n",
    "                        url=\"https://raw.githubusercontent.com/Azure/azure-sdk-for-python/main/sdk/ai/azure-ai-inference/samples/sample1.png\",\n",
    "                        detail=ImageDetailLevel.HIGH,\n",
    "                    ),\n",
    "                ),\n",
    "            ],\n",
    "        ),\n",
    "    ],\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=1,\n",
    "    max_tokens=4096,\n",
    "    top_p=1,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "\n",
    "from azure.ai.inference.models import UserMessage, TextContentItem, ImageContentItem, ImageUrl, ImageDetailLevel\n",
    "\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=\"\",\n",
    "    credential=AzureKeyCredential(\"\"),\n",
    ")\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        SystemMessage(content=\"You are an AI assistant that describes images in details.\"),\n",
    "        UserMessage(\n",
    "            content=[\n",
    "                TextContentItem(text=\"How many images are these?\"),\n",
    "                ImageContentItem(\n",
    "                    image_url=ImageUrl(\n",
    "                        url=\"https://cdn.britannica.com/68/178268-050-5B4E7FB6/Tom-Cruise-2013.jpg\",\n",
    "                        detail=ImageDetailLevel.HIGH,\n",
    "                    ),\n",
    "                ),\n",
    "                ImageContentItem(\n",
    "                    image_url=ImageUrl(\n",
    "                        url=\"https://cdn.britannica.com/68/178268-050-5B4E7FB6/Tom-Cruise-2013.jpg\",\n",
    "                        detail=ImageDetailLevel.HIGH,\n",
    "                    ),\n",
    "                ),\n",
    "            ],\n",
    "        ),\n",
    "    ],\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=1,\n",
    "    max_tokens=4096,\n",
    "    top_p=1,\n",
    ")\n",
    "\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage\n",
    "from azure.ai.inference.models import UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "\n",
    "from azure.ai.inference.models import (\n",
    "    SystemMessage,\n",
    "    UserMessage,\n",
    "    TextContentItem,\n",
    "    ImageContentItem,\n",
    "    ImageUrl,\n",
    "    ImageDetailLevel,\n",
    ")\n",
    "\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=\"\",\n",
    "    credential=AzureKeyCredential(\"\"),\n",
    ")\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        SystemMessage(content=\"You are an AI assistant that describes images in details.\"),\n",
    "        UserMessage(\n",
    "            content=[\n",
    "                TextContentItem(text=\"How many images are these?\"),\n",
    "                ImageContentItem(\n",
    "                    image_url=ImageUrl.load(\n",
    "                        image_file=\"sample1.png\",\n",
    "                        image_format=\"png\",\n",
    "                        detail=ImageDetailLevel.HIGH,\n",
    "                    ),\n",
    "                ),\n",
    "                ImageContentItem(\n",
    "                    image_url=ImageUrl(\n",
    "                        url=\"https://cdn.britannica.com/68/178268-050-5B4E7FB6/Tom-Cruise-2013.jpg\",\n",
    "                        detail=ImageDetailLevel.HIGH,\n",
    "                    ),\n",
    "                ),\n",
    "            ],\n",
    "        ),\n",
    "    ],\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=1,\n",
    "    max_tokens=4096,\n",
    "    top_p=1,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import base64\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from azure.ai.inference.models import (\n",
    "    SystemMessage,\n",
    "    UserMessage,\n",
    "    TextContentItem,\n",
    "    ImageContentItem,\n",
    "    ImageUrl,\n",
    "    ImageDetailLevel,\n",
    ")\n",
    "\n",
    "image_file_path = \"image1.jpg\"\n",
    "\n",
    "# Encode the image in base64\n",
    "with Path(image_file_path).open(\"rb\") as image_file:\n",
    "    encoded_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "sys_message = \"Generate a list of descriptive tags for the following image. Analyze the image carefully and produce tags that accurately represent the image. Ensure the tags are relevant.\"\n",
    "user_prompt = \"How many images are there?\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=\"\",\n",
    "    credential=AzureKeyCredential(\"\"),\n",
    ")\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": sys_message}]},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": user_prompt},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{encoded_image}\"}},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{encoded_image}\"}},\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=1,\n",
    "    max_tokens=4096,\n",
    "    top_p=1,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import base64\n",
    "from pathlib import Path\n",
    "\n",
    "sys_message = \"Analyze the image carefully and produce description that accurately represent the image.\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=\"\",\n",
    "    credential=AzureKeyCredential(\"\"),\n",
    ")\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": sys_message}]},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"Do you know if this \"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": \"https://cdn.britannica.com/68/178268-050-5B4E7FB6/Tom-Cruise-2013.jpg\"},\n",
    "                },\n",
    "                {\"type\": \"text\", \"text\": \" is same as this \"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": \"https://cdn.britannica.com/68/178268-050-5B4E7FB6/Tom-Cruise-2013.jpg\"},\n",
    "                },\n",
    "                {\"type\": \"text\", \"text\": \" .\"},\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=1,\n",
    "    max_tokens=4096,\n",
    "    top_p=1,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage\n",
    "from azure.ai.inference.models import UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import base64\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from azure.ai.inference.models import (\n",
    "    SystemMessage,\n",
    "    UserMessage,\n",
    "    TextContentItem,\n",
    "    ImageContentItem,\n",
    "    ImageUrl,\n",
    "    ImageDetailLevel,\n",
    ")\n",
    "\n",
    "image_file_path = \"image1.jpg\"\n",
    "\n",
    "# Encode the image in base64\n",
    "with Path(image_file_path).open(\"rb\") as image_file:\n",
    "    encoded_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=\"\",\n",
    "    credential=AzureKeyCredential(\"\"),\n",
    ")\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{encoded_image}\"}},\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=1,\n",
    "    max_tokens=4096,\n",
    "    top_p=1,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To generate image from text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_version=\"2024-05-01-preview\",\n",
    "    azure_endpoint=\"\",\n",
    "    api_key=\"\",\n",
    ")\n",
    "\n",
    "result = client.images.generate(\n",
    "    model=\"dall-e-3\",  # the name of your DALL-E 3 deployment\n",
    "    prompt=\"Create an image of the astronaut in desert. \",\n",
    "    n=1,\n",
    "    size=\"1024x1024\",\n",
    ")\n",
    "\n",
    "print(result.data[0].url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using OPEN AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "import base64\n",
    "\n",
    "MODEL = \"gpt-4o\"\n",
    "client = OpenAI(api_key=\"\")\n",
    "\n",
    "image_file_path = \"image1.jpg\"\n",
    "\n",
    "# Encode the image in base64\n",
    "with Path(image_file_path).open(\"rb\") as image_file:\n",
    "    encoded_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "sys_message = \"You are an AI assistant that describes images in details\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": sys_message}]},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"Can you describe this image?\"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": \"https://cdn.britannica.com/68/178268-050-5B4E7FB6/Tom-Cruise-2013.jpg\"},\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Assistant1: \" + completion.choices[0].message.content)\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": sys_message}]},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"Can you describe this image \"},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{encoded_image}\"}},\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Assistant2: \" + completion.choices[0].message.content)\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": sys_message}]},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"What do you see in this image \"},\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{encoded_image}\"}},\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Assistant3: \" + completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is using [Image] link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "import base64\n",
    "\n",
    "MODEL = \"gpt-4o\"\n",
    "client = OpenAI(api_key=\"\")\n",
    "\n",
    "image_file_path = \"image1.jpg\"\n",
    "\n",
    "# Encode the image in base64\n",
    "with Path(image_file_path).open(\"rb\") as image_file:\n",
    "    encoded_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "sys_message = \"You are an AI assistant that describes images in details\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": sys_message}]},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"Explain this image \"},\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"![Image](https://cdn.britannica.com/68/178268-050-5B4E7FB6/Tom-Cruise-2013.jpg)\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Assistant1: \" + completion.choices[0].message.content)\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": sys_message}]},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"Explain this image \"},\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"![Image](https://cdn.britannica.com/68/178268-050-5B4E7FB6/Tom-Cruise-2013.jpg)\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Assistant2: \" + completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "import base64\n",
    "\n",
    "MODEL = \"gpt-4o\"\n",
    "client = OpenAI(api_key=\"\")\n",
    "\n",
    "\n",
    "sys_message = \"You are an AI assistant that describes images in details\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": sys_message}]},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": \"https://cdn.britannica.com/68/178268-050-5B4E7FB6/Tom-Cruise-2013.jpg\"},\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"Can you describe this pictures?\"},\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"The image shows a person smiling. They have light brown hair and are wearing a dark gray shirt. The background is dark, and the lighting highlights their face, giving a clear view of their expression.\",\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"Can you describe this picture again?\"},\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Assistant1: \" + completion.choices[0].message.content)\n",
    "\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": sys_message}]},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"Create an image for astronaut\"},\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": \"https://cdn.britannica.com/68/178268-050-5B4E7FB6/Tom-Cruise-2013.jpg\"},\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Assistant2: \" + completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spec Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage\n",
    "from azure.ai.inference.models import UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "\n",
    "from azure.ai.inference.models import (\n",
    "    SystemMessage,\n",
    "    UserMessage,\n",
    "    TextContentItem,\n",
    "    ImageContentItem,\n",
    "    ImageUrl,\n",
    "    ImageDetailLevel,\n",
    ")\n",
    "\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=\"https://models.inference.ai.azure.com\",\n",
    "    credential=AzureKeyCredential(\"\"),\n",
    ")\n",
    "\n",
    "image_file_path = \"image1.jpg\"\n",
    "\n",
    "# Encode the image in base64\n",
    "with Path(image_file_path).open(\"rb\") as image_file:\n",
    "    encoded_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "sys_message = \"Analyze the image carefully and produce description that accurately represent the image.\"\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": sys_message}]},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"Do you know if this \"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": \"https://cdn.britannica.com/68/178268-050-5B4E7FB6/Tom-Cruise-2013.jpg\"},\n",
    "                },\n",
    "                {\"type\": \"text\", \"text\": \" is same as this \"},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{encoded_image}\"}},\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=1,\n",
    "    max_tokens=4096,\n",
    "    top_p=1,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "import base64\n",
    "\n",
    "MODEL = \"gpt-4o\"\n",
    "client = OpenAI(api_key=\"\")\n",
    "\n",
    "\n",
    "sys_message = \"You are an AI assistant who can describe pictures.\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": sys_message}]},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": \"https://cdn.britannica.com/68/178268-050-5B4E7FB6/Tom-Cruise-2013.jpg\"},\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Assistant1: \" + completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# # Define the input and output file paths\n",
    "# input_file_path = 'evaluate_multimodal_messages.jsonl'\n",
    "# output_file_path = 'out.jsonl'\n",
    "\n",
    "# # Read the entire JSON file as a dictionary\n",
    "# with open(input_file_path, 'r') as file:\n",
    "#     data = json.load(file)\n",
    "\n",
    "# # Normalize the nested structure into a flat table\n",
    "# df = pd.json_normalize(data)\n",
    "\n",
    "# # Save the flattened structure into a new JSONL file\n",
    "# df.to_json(output_file_path, orient='records', lines=True)\n",
    "\n",
    "# print(f\"Flattened JSON saved to {output_file_path}\")\n",
    "\n",
    "dd = pd.read_json(\"out.jsonl\", lines=True)\n",
    "\n",
    "dd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
