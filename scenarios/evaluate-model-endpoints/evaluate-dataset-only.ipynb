{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model endpoints\n",
    "\n",
    "## Objective\n",
    "\n",
    "This tutorial provides a step-by-step guide on how to evaluate response from MaaS endpoints deployed on Azure AI Platform, as well as external model endpoints such as model deployed on HuggingFace platform.\n",
    "\n",
    "This guide uses Data file as an input to evaluate results. It does not take any target function or class.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install promptflow-evals\n",
    "%pip install promptflow-azure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "\n",
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_ai_project = {\n",
    "    \"subscription_id\": \"\",\n",
    "    \"resource_group_name\": \"\",\n",
    "    \"project_name\": \"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We recommend to push endpoint and url to env and use os.get_env()\n",
    "env = {\n",
    "    \"tiny_llama\" : {\n",
    "        \"endpoint\" : \"https://api-inference.huggingface.co/models/TinyLlama/TinyLlama-1.1B-Chat-v1.0/v1/chat/completions\",\n",
    "\t    \"key\" : \"\",\n",
    "    },\n",
    "    \"phi3_mini\" : {\n",
    "        \"endpoint\" : \"https://Phi-3-mini-4k-instruct-rqvel.eastus2.models.ai.azure.com/v1/chat/completions\",\n",
    "\t    \"key\" : \"\",\n",
    "    },\n",
    "    \"gpt2\" : {\n",
    "        \"endpoint\" : \"https://api-inference.huggingface.co/models/openai-community/gpt2\",\n",
    "\t    \"key\" : \"\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def call_tiny_llama_endpoint(question: str) -> str:\n",
    "\n",
    "\tendpoint = env[\"tiny_llama\"][\"endpoint\"]\n",
    "\tkey = env[\"tiny_llama\"][\"key\"]\n",
    "\n",
    "\theaders = {'Content-Type':'application/json', 'Authorization':('Bearer '+ key) }\n",
    "\n",
    "\tdef query(payload):\n",
    "\t\tprint(payload)\n",
    "\t\tresponse = requests.post(endpoint, headers=headers, json=payload)\n",
    "\t\treturn response.json()\n",
    "\t\t\n",
    "\toutput = query({\n",
    "\t\t\"model\": \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
    "\t\t\"messages\": [{\n",
    "\t\t\t\"role\": \"user\", \n",
    "\t\t\t\"content\": question\n",
    "\t\t\t}],\n",
    "\t\t\"max_tokens\": 500,\n",
    "\t\t\"stream\": False\n",
    "\t\t})\n",
    "\n",
    "\tanswer = output[\"choices\"][0][\"message\"][\"content\"]\n",
    "\treturn \"{ \\\"question\\\" : \\\" \" + question + \"\\\" , \\\"answer\\\" : \\\" \" + answer + \" \\\"}\"\n",
    "\n",
    "def call_phi3_mini_endpoint(question: str) -> str:\n",
    "\n",
    "\tendpoint = env[\"phi3_mini\"][\"endpoint\"]\n",
    "\tkey = env[\"phi3_mini\"][\"key\"]\n",
    "\n",
    "\theaders = {'Content-Type':'application/json', 'Authorization':('Bearer '+ key) }\n",
    "\n",
    "\tdef query(payload):\n",
    "\t\tprint(payload)\n",
    "\t\tresponse = requests.post(endpoint, headers=headers, json=payload)\n",
    "\t\treturn response.json()\n",
    "\t\t\n",
    "\toutput = query({\n",
    "\t\t\"messages\": [{\n",
    "\t\t\t\"role\": \"user\", \n",
    "\t\t\t\"content\": question\n",
    "\t\t\t}],\n",
    "\t\t\"max_tokens\": 500\n",
    "\t\t})\n",
    "\t\n",
    "\tanswer = output[\"choices\"][0][\"message\"][\"content\"]\n",
    "\treturn \"{ \\\"question\\\" : \\\" \" + question + \"\\\" , \\\"answer\\\" : \\\" \" + answer + \" \\\"}\"\n",
    "\n",
    "def call_default_endpoint(): \n",
    "\treturn \"{ \\\"question\\\" : \\\"What is capital of France?\\\" , \\\"answer\\\" : \\\"Paris\\\"}\"\n",
    "\t\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_external_endpoints(question: str, model_type: str) -> str:\n",
    "\n",
    "    if (model_type == \"tiny_llama\"): \n",
    "        output = call_tiny_llama_endpoint(question)\n",
    "    else:\n",
    "        output = call_default_endpoint(question)\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = call_external_endpoints(\"What is the capital of France?\", \"tiny_llama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from promptflow.evals.evaluators import (\n",
    "    ContentSafetyEvaluator,\n",
    ")\n",
    "from promptflow.evals.evaluate import evaluate\n",
    "\n",
    "content_safety_evaluator = ContentSafetyEvaluator(project_scope=azure_ai_project)\n",
    "\n",
    "json_line_as_json = json.loads(output)\n",
    "json_line_as_json\n",
    "\n",
    "\n",
    "content_safety_eval_result = content_safety_evaluator(\n",
    "    question=json_line_as_json[\"question\"], answer=json_line_as_json[\"answer\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling Eval API using output file\n",
    "\n",
    "results = evaluate(\n",
    "    azure_ai_project=azure_ai_project,\n",
    "    data=\"outputs.jsonl\", \n",
    "    evaluators = {\n",
    "        \"content_safety\": content_safety_evaluator\n",
    "        })\n",
    "\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
