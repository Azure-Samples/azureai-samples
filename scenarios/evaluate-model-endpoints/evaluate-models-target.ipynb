{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model endpoints using Prompt Flow Eval APIs\n",
    "\n",
    "## Objective\n",
    "\n",
    "This tutorial provides a step-by-step guide on how to evaluate response from MaaS endpoints deployed on Azure AI Platform, as well as external model endpoints such as model deployed on HuggingFace platform.\n",
    "\n",
    "This guide uses Python Class as a target to evaluate results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install promptflow-evals\n",
    "%pip install promptflow-azure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install promptflow-evals\n",
    "%pip install promptflow-azure\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "\n",
    "import json\n",
    "import requests\n",
    "\n",
    "from typing import List, Tuple, TypedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Please provide Azure AI Project details so that traces and eval results are pushing in the project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_ai_project = {\n",
    "    \"subscription_id\": \"***\",\n",
    "    \"resource_group_name\": \"***\",\n",
    "    \"project_name\": \"***\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For simplicity, we have provided endpoints and keys in the code below. \n",
    "We do recommend keeping these endpoints and keys in env variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_var = {\n",
    "    \"tiny_llama\" : {\n",
    "        \"endpoint\" : \"https://api-inference.huggingface.co/models/TinyLlama/TinyLlama-1.1B-Chat-v1.0/v1/chat/completions\",\n",
    "\t    \"key\" : \"***\",\n",
    "    },\n",
    "    \"phi3_mini_serverless\" : {\n",
    "        \"endpoint\" : \"https://Phi-3-mini-4k-instruct-rqvel.eastus2.models.ai.azure.com/v1/chat/completions\",\n",
    "\t    \"key\" : \"***\",\n",
    "    },\n",
    "    \"gpt2\" : {\n",
    "        \"endpoint\" : \"https://api-inference.huggingface.co/models/openai-community/gpt2\",\n",
    "\t    \"key\" : \"***\",\n",
    "    },\n",
    "    \"mistral7b\" : {\n",
    "        \"endpoint\" : \"https://mistral-7b-east1092381.eastus2.inference.ml.azure.com/chat/completions\",\n",
    "\t    \"key\" : \"***\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Following code reads Json file \"data.jsonl\" which contains inputs of the Target function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"testdata/data.jsonl\", lines=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following code runs Evaluate API and uses Content Safety Evaluator to evaluate results.\n",
    "Test data is provided in json file 'data.jsonl' for Target Function. \n",
    "It contains 'question' and the model type. \n",
    "Target function uses the questions to call specific endpoints and retrive answer from response to evaluate using Evaluate API from Promoptflow SDK. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app_target import ModelEndpoints\n",
    "import random\n",
    "\n",
    "from promptflow.core import AzureOpenAIModelConfiguration\n",
    "from promptflow.evals.evaluate import evaluate\n",
    "from promptflow.evals.evaluators import ContentSafetyEvaluator, RelevanceEvaluator, CoherenceEvaluator\n",
    "\n",
    "configuration = AzureOpenAIModelConfiguration(\n",
    "    azure_endpoint=\"https://ai-***.openai.azure.com\",\n",
    "    api_key=\"***\",\n",
    "    api_version=\"2023-03-15-preview\",\n",
    "    azure_deployment=\"gpt-35-turbo\",\n",
    ")\n",
    "\n",
    "\n",
    "content_safety_evaluator = ContentSafetyEvaluator(project_scope=azure_ai_project)\n",
    "relevance_evaluator = RelevanceEvaluator(model_config=configuration)\n",
    "coherence_evaluator = CoherenceEvaluator(model_config=configuration)\n",
    "\n",
    "models = [\"tiny_llama\", \"phi3_mini_serverless\", \"gpt2\", \"mistral7b\"]\n",
    "\n",
    "path = os.path.join(os.getcwd(), \"testdata\", \"data.jsonl\")\n",
    "\n",
    "for model in models:\n",
    "    randomNum = random.randint(1111, 9999)\n",
    "    results = evaluate(\n",
    "        azure_ai_project=azure_ai_project,\n",
    "        evaluation_name=\"Eval-Run-\"+str(randomNum)+\"-\"+model.title(),\n",
    "        data=path,\n",
    "        target=ModelEndpoints(env_var, model),\n",
    "        evaluators = {\n",
    "            \"content_safety\": content_safety_evaluator,\n",
    "            \"coherence\": coherence_evaluator,\n",
    "            \"relevance\": relevance_evaluator,\n",
    "        },\n",
    "        evaluator_config={\n",
    "            \"content_safety\": {\n",
    "                \"question\": \"${data.question}\",\n",
    "                \"answer\": \"${target.answer}\"\n",
    "            },\n",
    "            \"coherence\": {\n",
    "                \"answer\": \"${target.answer}\",\n",
    "                \"question\": \"${data.question}\"\n",
    "            },\n",
    "            \"relevance\": {\n",
    "                \"answer\": \"${target.answer}\",\n",
    "                \"context\": \"${data.context}\",\n",
    "                \"question\": \"${data.question}\"\n",
    "            }\n",
    "        })\n",
    "    results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
