{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Index from various sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "This notebook demonstrates the following:\n",
    "\n",
    "- Create an index from\n",
    "    - Your local files/folders\n",
    "    - Git Repo\n",
    "    - Remote sources like S3, OneLake\n",
    "\n",
    "This tutorial uses the following Azure AI services:\n",
    "\n",
    "- Access to Azure OpenAI Service - you can apply for access [here](https://go.microsoft.com/fwlink/?linkid=2222006)\n",
    "- Azure Cognitive Search service - you can create it from instructions [here](https://learn.microsoft.com/azure/search/search-create-service-portal)\n",
    "- An Azure AI Studio project - go to [aka.ms/azureaistudio](https://aka.ms/azureaistudio) to create a project\n",
    "- A connection to the Azure Cognitive Service in your project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time\n",
    "\n",
    "You should expect to spend 15-30 minutes running this sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this example\n",
    "\n",
    "This sample shows how to create an index from different sources like local files and remote sources like a git repo and cloud storage URLs. It adds an index to an Azure Cognitive Search Index.\n",
    "\n",
    "This sample is useful for developers and data scientists who wish to use their data to create an Index which can be used in the RAG pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "For this sample we will use data from the blob https://azuremlexamples.blob.core.windows.net/datasets/product-info/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you begin\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation\n",
    "\n",
    "Install the following packages required to execute this notebook. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the packages\n",
    "!pip3 install azure-identity azure-ai-generative azure-ai-resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project details\n",
    "subscription_id: str = \"<your-subscription-id>\"\n",
    "resource_group_name: str = \"<your-resource-group>\"\n",
    "project_name: str = \"<your-project-name>\"\n",
    "\n",
    "# Azure Cognitive Search Connection\n",
    "acs_connection_name: str = \"<your-acs-connection>\"\n",
    "\n",
    "# model used for embedding\n",
    "embedding_model_deployment: str = \"text-embedding-ada-002\"\n",
    "\n",
    "# names of indexes we will create\n",
    "local_index_local_files_index_name = \"local-index-local-files-index\"\n",
    "cloud_index_git_index_name = \"cloud-index-git-index\"\n",
    "cloud_index_remote_url_index_name = \"cloud-index-remote-url-index\"\n",
    "cloud_index_local_files_index_name = \"cloud-index-local_files-index\"\n",
    "\n",
    "should_cleanup: bool = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to your project\n",
    "\n",
    "To start with let us create a config file with your project details. This file can be used in this sample or other samples to connect to your workspace. To get the required details, you can go to the Project Overview page in the AI Studio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "config = {\n",
    "    \"subscription_id\": subscription_id,\n",
    "    \"resource_group\": resource_group_name,\n",
    "    \"project_name\": project_name,\n",
    "}\n",
    "\n",
    "p = Path(\"config.json\")\n",
    "\n",
    "with p.open(mode=\"w\") as file:\n",
    "    file.write(json.dumps(config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us connect to the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.resources.client import AIClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# connects to project defined in the first config.json found in this or parent folders\n",
    "client = AIClient.from_config(DefaultAzureCredential())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Azure OpenAI and Cognitive Services Connections\n",
    "We will use an Azure Open AI service to access the LLM and embedding model. We will also use an Azure Cognitive Search to store the index. Let us get the details of these from your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the default Azure Open AI connection for your project\n",
    "default_aoai_connection = client.get_default_aoai_connection()\n",
    "default_aoai_connection.set_current_environment()\n",
    "\n",
    "# Get the Azure Cognitive Search connection by name\n",
    "default_acs_connection = client.connections.get(acs_connection_name)\n",
    "default_acs_connection.set_current_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Build an Index locally from local files or folders\n",
    "\n",
    "You can build an index from your local files or folders. We will build an index using the `build_index` function. This will create an index on the machine where this sample is run. The local index can then be added/registered to your AI Studio project.\n",
    "\n",
    "You can index files of type `.md, .txt, .html, .htm, .py, .doc, .docx, .ppt, .pptx, .pdf, .xls, .xlsx`. All other file types will be ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In this notebook, we will use Azure Cognitive Search (ACS) as the index store for all our scenarios. You could also use FAISS/Pinecone for index store."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Build the Index locally\n",
    "The below step will chunk and embed your documents locally and then add it to an index in the Azure Cognitive Search Service. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.resources.operations import LocalSource, ACSOutputConfig\n",
    "from azure.ai.generative.index import build_index\n",
    "\n",
    "# build the index\n",
    "acs_index = build_index(\n",
    "    output_index_name=local_index_local_files_index_name,  # name of your index\n",
    "    vector_store=\"azure_cognitive_search\",  # the type of vector store - in our case it is ACS\n",
    "    # we are using ada 002 for embedding\n",
    "    embeddings_model=f\"azure_open_ai://deployment/{embedding_model_deployment}/model/text-embedding-ada-002\",\n",
    "    index_input_config=LocalSource(input_data=\"data/product-info/\"),  # the location of your file/folders\n",
    "    acs_config=ACSOutputConfig(\n",
    "        acs_index_name=local_index_local_files_index_name\n",
    "        + \"-store\",  # the name of the index store inside the azure cognitive search service\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Register the index\n",
    "Register the index so that it shows up in the AI Studio Project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.indexes.create_or_update(acs_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build an index on the Cloud\n",
    "\n",
    "You can build an index directly on the cloud (your AI Studio project) from local files or folders as well as remote sources like a Git Repo, [OneLake](https://learn.microsoft.com/fabric/onelake/onelake-overview), [Amazon S3](https://docs.aws.amazon.com/AmazonS3/latest/userguide), generic cloud URLs.\n",
    "\n",
    "In this section we will use the `build_ml_index_on_cloud` function. This function will create an index directly in your AI Studio project by running a job to perform the required steps directly in your project.\n",
    "\n",
    "> In this notebook, we will use Azure Cognitive Search (ACS) as the index store for all our scenarios. You could also use FAISS/Pinecone for index store."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Build an index on cloud from a git repo\n",
    "\n",
    "Let us build an index from the rust github repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Configure the source\n",
    "\n",
    "Let us configure the git repo from where we will get the data. In this case we are using a public repo. If you need to use a private repo, you could add **New Connection** of type `Git` in the AI Studio and use that name for `git_connection_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.resources.operations import GitSource\n",
    "\n",
    "git_config = GitSource(git_url=\"https://github.com/rust-lang/book.git\", git_branch_name=\"main\", git_connection_id=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Configure the index store\n",
    "\n",
    "Let us configure index name and connection to Azure Cognitive Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.resources.operations import ACSOutputConfig\n",
    "\n",
    "index_output_config = ACSOutputConfig(\n",
    "    acs_index_name=cloud_index_git_index_name\n",
    "    + \"-store\",  # the name of the index store inside the azure cognitive search service\n",
    "    acs_connection_id=default_acs_connection.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3 Build the index\n",
    "\n",
    "We will use the `build_ml_index_on_cloud` function. This function will create an index directly in your AI Studio project by running a job to perform the required steps directly in your project. The output of this cell will provide a link to the job which will create the index. Click on the link to track status. You need to wait for the job to complete before using the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.build_ml_index_on_cloud(\n",
    "    output_index_name=cloud_index_git_index_name,\n",
    "    vector_store=\"azure_cognitive_search\",\n",
    "    embeddings_model=\"text-embedding-ada-002\",\n",
    "    aoai_connection_id=default_aoai_connection.id,\n",
    "    data_source_url=\"https://github.com/rust-lang/book/blob/main\",\n",
    "    input_source=git_config,\n",
    "    acs_config=index_output_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Build an index on cloud from storage URLs\n",
    "\n",
    "Let us build an index from storage URLs (cloud locations). You can build an index from the following types of storage locations:\n",
    "\n",
    "|Location|URL Examples|\n",
    "|--|--|\n",
    "|Blob|wasb[s]://<container_name>@<account_name>.blob.core.windows.net/<path_to_folder>|\n",
    "|OneLake (Lakehouse)|abfss://<workspace-name>@onelake.dfs.fabric.microsoft.com/<LakehouseName>.Lakehouse/Files/<path_to_folder>|\n",
    "|OneLake (Warehouse)|abfss://<workspace-name>@onelake.dfs.fabric.microsoft.com/<warehouseName>.warehouse/Files/<path_to_folder>|\n",
    "|Amazon S3 (link as OneLakeShortcut)|abfss://<workspace-name>@onelake.dfs.fabric.microsoft.com/<LakehouseName>.Lakehouse/Files/<path_to_S3_folder>|\n",
    "|ADLS|abfss://<filesystem>@<accountname>.dfs.core.windows.net/<path_to_folder>|\n",
    "\n",
    "You will need to ensure, that either you or your Studio project has access to these specific resources to be able to get data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Configure the source\n",
    "\n",
    "In this notebook we use a publicly accessible blob URL since it is simple to setup without specific user permissions. Let us configure the blob URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_source = \"wasbs://datasets@azuremlexamples.blob.core.windows.net/product-info\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Configure the index store\n",
    "Let us configure index name and connection to Azure Cognitive Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.resources.operations import ACSOutputConfig\n",
    "\n",
    "index_output_config = ACSOutputConfig(\n",
    "    acs_index_name=cloud_index_remote_url_index_name\n",
    "    + \"-store\",  # the name of the index store inside the azure cognitive search service\n",
    "    acs_connection_id=default_acs_connection.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 Build the index\n",
    "\n",
    "We will use the `build_ml_index_on_cloud` function. This function will create an index directly in your AI Studio project by running a job to perform the required steps directly in your project. The output of this cell will provide a link to the job which will create the index. Click on the link to track status. You need to wait for the job to complete before using the index.\n",
    "\n",
    "Since we are using a publicly accessible storage location, we will not configure the identity. However, you can create an index using your credentials (the person submitting the command) by using the [UserIdentityConfiguration](https://learn.microsoft.com/python/api/azure-ai-ml/azure.ai.ml.useridentityconfiguration). This could be useful in cases where only you have access to the storgae location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from azure.ai.ml import UserIdentityConfiguration\n",
    "\n",
    "client.build_ml_index_on_cloud(\n",
    "    output_index_name=cloud_index_remote_url_index_name,\n",
    "    vector_store=\"azure_cognitive_search\",\n",
    "    embeddings_model=\"text-embedding-ada-002\",\n",
    "    aoai_connection_id=default_aoai_connection.id,\n",
    "    data_source_url=\"https://azuremlexamples.blob.core.windows.net/product-info\",\n",
    "    input_source=remote_source,\n",
    "    acs_config=index_output_config,\n",
    "    # identity=UserIdentityConfiguration(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Build an index on cloud from local files\n",
    "\n",
    "Let us build an index on the cloud from local files or folders. In this case the index will directly get created on the cloud and not the local machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Configure the source\n",
    "\n",
    "Use the local files/folders as the source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.resources.operations import LocalSource\n",
    "\n",
    "local_source = LocalSource(input_data=\"data/product-info/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 Configure the index store\n",
    "Let us configure index name and connection to Azure Cognitive Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.resources.operations import ACSOutputConfig\n",
    "\n",
    "index_output_config = ACSOutputConfig(\n",
    "    acs_index_name=cloud_index_local_files_index_name\n",
    "    + \"-store\",  # the name of the index store inside the azure cognitive search service\n",
    "    acs_connection_id=default_acs_connection.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3 Build the index\n",
    "\n",
    "We will use the `build_ml_index_on_cloud` function. This function will create an index directly in your AI Studio project by running a job to perform the required steps directly in your project. The output of this cell will provide a link to the job which will create the index. Click on the link to track status. You need to wait for the job to complete before using the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from azure.ai.ml import UserIdentityConfiguration\n",
    "\n",
    "client.build_ml_index_on_cloud(\n",
    "    output_index_name=cloud_index_local_files_index_name,\n",
    "    vector_store=\"azure_cognitive_search\",\n",
    "    embeddings_model=\"text-embedding-ada-002\",\n",
    "    aoai_connection_id=default_aoai_connection.id,\n",
    "    input_source=local_source,\n",
    "    acs_config=index_output_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consuming an Index\n",
    "\n",
    "Any of these indexes can be consumed in the same way. Refer to the [Retrieval Augmented Generation (RAG) using Azure AI SDK](../rag-e2e/rag-qna.ipynb) notebook for details on consuming the index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up\n",
    "\n",
    "To clean up all Azure ML resources used in this example, you can delete the individual resources you created in this tutorial.\n",
    "\n",
    "If you made a resource group specifically to run this example, you could instead [delete the resource group](https://learn.microsoft.com/en-us/azure/azure-resource-manager/management/delete-resource-group)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if should_cleanup:\n",
    "    # {{TODO: Add resource cleanup}}\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "notebook_template.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
