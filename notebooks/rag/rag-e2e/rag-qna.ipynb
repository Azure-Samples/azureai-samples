{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation (RAG) using Azure AI SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "This notebook demonstrates the following:\n",
    "\n",
    "- Create an index on Azure Cognitive search or FAISS from your local files\n",
    "- Use the index in a chatbot built using Azure OpenAI and Langchain\n",
    "\n",
    "This tutorial uses the following Azure AI services:\n",
    "\n",
    "- Access to Azure OpenAI Service - you can apply for access [here](https://go.microsoft.com/fwlink/?linkid=2222006)\n",
    "- Azure Cognitive Search service - you can create it from instructions [here](https://learn.microsoft.com/azure/search/search-create-service-portal)\n",
    "- An Azure AI Studio project - go to [aka.ms/azureaistudio](https://aka.ms/azureaistudio) to create a project\n",
    "- A connection to the Azure Cognitive Service in your project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time\n",
    "\n",
    "You should expect to spend 10-20 minutes running this sample. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this example\n",
    "\n",
    "This sample shows how to create an index and consume it to answer questions based on your data (aka RAG pattern). It demonstrates how to create an index from local files and folders, how to store that index in Azure Cognitive Search or in [FAISS](https://ai.meta.com/tools/faiss). The index gets created locally and can then be registered to your AI Studio project. Once registered, it can be retrieved and consumed to answer questions. The sample shows how to build a simple QnA script to answer questions.\n",
    "\n",
    "This sample is useful for developers and data scientists who wish to use their data with LLMs to build QnA bots, co-pilots. Basically anyone interested in using the RAG pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "This sample uses files from the folder `notebooks/rag/rag-e2e/data/product-info` in this repo. You can clone this repo or copy this folder to make sure you have access to these files when running the sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation\n",
    "\n",
    "Install the following packages required to execute this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the packages\n",
    "%pip install azure-identity azure-ai-generative[faiss] azure-search-documents azure-ai-resources\n",
    "%pip install langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "Lets initialize some variables. For `subscription_id`, `resource_group_name` and `project_name`, you can go to the Project Overview page in the AI Studio. Replace the items in <> with values for your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project details\n",
    "subscription_id: str = \"<your-subscription-id>\"\n",
    "resource_group_name: str = \"<your-resource-group>\"\n",
    "project_name: str = \"<your-project-name>\"\n",
    "\n",
    "# Azure Cognitive Search Connection\n",
    "acs_connection_name: str = \"<your-acs-connection>\"\n",
    "\n",
    "# models used for embedding and deployment\n",
    "embedding_model_deployment: str = \"text-embedding-ada-002\"\n",
    "chat_model_deployment: str = \"gpt-35-turbo\"\n",
    "\n",
    "should_cleanup: bool = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to your project\n",
    "\n",
    "To start with let us create a config file with your project details. This file can be used in this sample or other samples to connect to your workspace. To get the required details, you can go to the Project Overview page in the AI Studio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "config = {\n",
    "    \"subscription_id\": subscription_id,\n",
    "    \"resource_group\": resource_group_name,\n",
    "    \"project_name\": project_name,\n",
    "}\n",
    "\n",
    "p = Path(\"config.json\")\n",
    "\n",
    "with p.open(mode=\"w\") as file:\n",
    "    file.write(json.dumps(config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us connect to the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.resources.client import AIClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# connects to project defined in the first config.json found in this or parent folders\n",
    "client = AIClient.from_config(DefaultAzureCredential())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Azure OpenAI and Cognitive Services Connections\n",
    "We will use an Azure Open AI service to access the LLM and embedding model. We will also use an Azure Cognitive Search to store the index. Let us get the details of these from your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the default Azure Open AI connection for your project\n",
    "default_aoai_connection = client.get_default_aoai_connection()\n",
    "default_aoai_connection.set_current_environment()\n",
    "\n",
    "# Get the Azure Cognitive Search connection by name\n",
    "default_acs_connection = client.connections.get(acs_connection_name)\n",
    "default_acs_connection.set_current_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build an Index locally\n",
    "We will use files from the data directory and build an index. The index will be created on the machine where this sample is run.\n",
    "\n",
    "You can index files of type `.md, .txt, .html, .htm, .py, .doc, .docx, .ppt, .pptx, .pdf, .xls, .xlsx`. All other file types will be ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build an Azure Cognitive Search Index\n",
    "Let us create an Azure Cognitive Search Index. The below step will chunk and embed your documents locally and then add it to an index in the Azure Cognitive Search Service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.resources.operations import LocalSource, ACSOutputConfig\n",
    "from azure.ai.generative.index import build_index\n",
    "\n",
    "index_name = \"product-info-acs-index\"\n",
    "# build the index\n",
    "acs_index = build_index(\n",
    "    output_index_name=index_name,  # name of your index\n",
    "    vector_store=\"azure_cognitive_search\",  # the type of vector store - in our case it is ACS\n",
    "    # we are using ada 002 for embedding\n",
    "    embeddings_model=f\"azure_open_ai://deployment/{embedding_model_deployment}/model/text-embedding-ada-002\",\n",
    "    index_input_config=LocalSource(input_data=\"data/product-info/\"),  # the location of your file/folders\n",
    "    acs_config=ACSOutputConfig(\n",
    "        acs_index_name=index_name + \"-store\",  # the name of the index store inside the azure cognitive search service\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a FAISS Index\n",
    "The same index can also be created on FAISS. The below step will chunk and embed your documents locally and then add it a FAISS index which is a file based index stored on your local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.resources.operations import LocalSource\n",
    "from azure.ai.generative.index import build_index\n",
    "\n",
    "faiss_index_name = \"product-info-faiss-index\"\n",
    "# build the index\n",
    "faiss_index = build_index(\n",
    "    output_index_name=faiss_index_name,  # name of your index\n",
    "    vector_store=\"faiss\",  # the type of vector store - in our case it is ACS\n",
    "    # we are using ada 002 for embedding\n",
    "    embeddings_model=f\"azure_open_ai://deployment/{embedding_model_deployment}/model/text-embedding-ada-002\",\n",
    "    index_input_config=LocalSource(input_data=\"data/product-info/\"),  # the location of your file/folders\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register the index\n",
    "Register the index so that it shows up in the AI Studio Project. \n",
    "\n",
    "In the below step we will register the Azure Cognitive Search Index which we created, but the same method can be used to register a FAISS index as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.indexes.create_or_update(acs_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consuming the index\n",
    "To consume an Index, you need to retrieve it from the project. You can then use langchain to query the index. In this sample, we will use the Azure Cognitive Search Index which we created, but the same can be applied to any index in your project.\n",
    "\n",
    "### Retrieve the index from your project as a langchain retriever\n",
    "Let us get the index from your project as a langchain retriever. We will use the langchain retriever to build a chat function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.generative.index import get_langchain_retriever_from_index\n",
    "\n",
    "# retrieve ML Index from your project\n",
    "index_name = \"product-info-acs-index\"\n",
    "# this function needs a path. Convert index name to path by adding -mlindex at the end\n",
    "index_langchain_retriever = get_langchain_retriever_from_index(index_name + \"-mlindex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a QnA function\n",
    "We will build a QnA function which accepts a user question and provides an answer from the index data.\n",
    "This function uses the LLM as defined in the `AzureChatOpenAI` constructor. It uses the index as a langchain_retriever to query the data. We build a prompt Template which accepts a context and a question. We use langchain's `RetrievalQA.from_chain_type` to put all these together and get us the answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qna(question: str, temperature: float = 0.0, prompt_template: object = None) -> str:\n",
    "    from langchain import PromptTemplate\n",
    "    from langchain.chains import RetrievalQA\n",
    "    from langchain.chat_models import AzureChatOpenAI\n",
    "\n",
    "    llm = AzureChatOpenAI(\n",
    "        deployment_name=chat_model_deployment,\n",
    "        model_name=chat_model_deployment,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "\n",
    "    template = \"\"\"\n",
    "    System:\n",
    "    You are an AI assistant helping users with queries related to outdoor outdoor/camping gear and clothing.\n",
    "    Use the following pieces of context to answer the questions about outdoor/camping gear and clothing as completely, \n",
    "    correctly, and concisely as possible.\n",
    "    If the question is not related to outdoor/camping gear and clothing, just say Sorry, I only can answer question \n",
    "    related to outdoor/camping gear and clothing. So how can I help? Don't try to make up an answer.\n",
    "    If the question is related to outdoor/camping gear and clothing but vague ask for clarifying questions.\n",
    "    Do not add documentation reference in the response.\n",
    "\n",
    "    {context}\n",
    "\n",
    "    ---\n",
    "\n",
    "    Question: {question}\n",
    "\n",
    "    Answer:\"\n",
    "    \"\"\"\n",
    "    prompt_template = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "    qa = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=index_langchain_retriever,\n",
    "        return_source_documents=True,\n",
    "        chain_type_kwargs={\n",
    "            \"prompt\": prompt_template,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    response = qa(question)\n",
    "\n",
    "    return {\n",
    "        \"question\": response[\"query\"],\n",
    "        \"answer\": response[\"result\"],\n",
    "        \"context\": \"\\n\\n\".join([doc.page_content for doc in response[\"source_documents\"]]),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us ask a question to make sure we get an answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qna(\"Which tent has the highest rainfly waterproof rating?\")\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up\n",
    "\n",
    "To clean up all Azure ML resources used in this example, you can delete the individual resources you created in this tutorial.\n",
    "\n",
    "If you made a resource group specifically to run this example, you could instead [delete the resource group](https://learn.microsoft.com/azure/azure-resource-manager/management/delete-resource-group)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if should_cleanup:\n",
    "    # add cleanup steps if needed\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aigensdk_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
