{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "759f9ec0",
   "metadata": {},
   "source": [
    "# REST API Mutiple Image Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61534b8b",
   "metadata": {},
   "source": [
    "## Objective\n",
    "Managing multiple image inputs in GPT-4V."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdbfe5c",
   "metadata": {},
   "source": [
    "## Time\n",
    "\n",
    "You should expect to spend 5-10 minutes running this sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce7f3b6",
   "metadata": {},
   "source": [
    "## Before you begin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c23ddd2",
   "metadata": {},
   "source": [
    "#### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5e936f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560ed1ea",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "You need to set a series of configurations such as GPT-4V_DEPLOYMENT_NAME, OPENAI_API_BASE, OPENAI_API_VERSION.\n",
    "\n",
    "Add \"OPENAI_API_KEY\" as variable name and \\<Your API Key Value\\> as variable value in the environment variables.\n",
    " <br>\n",
    "      \n",
    "      WINDOWS Users: \n",
    "         setx OPENAI_API_KEY \"REPLACE_WITH_YOUR_KEY_VALUE_HERE\"\n",
    "\n",
    "      MACOS/LINUX Users: \n",
    "         export OPENAI_API_KEY=\"REPLACE_WITH_YOUR_KEY_VALUE_HERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e24746c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the deployment name\n",
    "deployment_name: str = \"<your GPT-4V deployment name>\"\n",
    "# The base URL for your Azure OpenAI resource. e.g. \"https://<your resource name>.openai.azure.com\"\n",
    "openai_api_base: str = \"<your resource base URL>\"\n",
    "# Currently OPENAI API have the following versions available: 2022-12-01.\n",
    "# All versions follow the YYYY-MM-DD date structure.\n",
    "openai_api_version: str = \"<your OpenAI API version>\"\n",
    "\n",
    "should_cleanup: bool = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7880d79",
   "metadata": {},
   "source": [
    "## Connect to your project\n",
    "To start with let us create a config file with your project details. This file can be used in this sample or other samples to connect to your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168c75ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "config = {\n",
    "    \"GPT-4V_DEPLOYMENT_NAME\": deployment_name,\n",
    "    \"OPENAI_API_BASE\": openai_api_base,\n",
    "    \"OPENAI_API_VERSION\": openai_api_version,\n",
    "}\n",
    "\n",
    "p = Path(\"../config.json\")\n",
    "\n",
    "with p.open(mode=\"w\") as file:\n",
    "    file.write(json.dumps(config))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aada5e70",
   "metadata": {},
   "source": [
    "## Run this Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef62557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from IPython.display import Image, display\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "parent_dir = Path(Path.cwd()).parent\n",
    "sys.path.append(str(parent_dir))\n",
    "from shared_functions import call_GPT4V_image\n",
    "\n",
    "# Defect Detector\n",
    "reference_image_file_path = \"DefectDetectorReference.jpg\"\n",
    "with Path(reference_image_file_path).open(\"rb\") as image_file:\n",
    "    encoded_reference_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "test_image_file_path = \"DefectDetectorTest.jpg\"\n",
    "with Path(test_image_file_path).open(\"rb\") as image_file:\n",
    "    encoded_test_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "sys_message = \"\"\"\n",
    "You're a professional defect detector.\n",
    "Your job is to compare the test image with reference image, please answer the question with \"No defect detected\" or \"Defect detected\", \n",
    "also explain your decision as detail as possible.\"\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": sys_message}]},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"Here is the reference image\",  # Pass the prompt\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{encoded_reference_image}\"  # Pass the encoded reference image\n",
    "                },\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"Here is the test image\",  # Pass the prompt\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\"url\": f\"data:image/jpeg;base64,{encoded_test_image}\"},  # Pass the encoded test image\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "try:\n",
    "    response_content = call_GPT4V_image(messages)\n",
    "    print(\"Reference image:\")\n",
    "    display(Image(reference_image_file_path))\n",
    "    print(\"Test image:\")\n",
    "    display(Image(test_image_file_path))\n",
    "    print(response_content[\"choices\"][0][\"message\"][\"content\"])  # Print the content of the response\n",
    "except Exception as e:\n",
    "    print(f\"Failed to call GPT-4V API. Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa690d8",
   "metadata": {},
   "source": [
    "## Cleaning up\n",
    "\n",
    "To clean up all Azure ML resources used in this example, you can delete the individual resources you created in this tutorial.\n",
    "\n",
    "If you made a resource group specifically to run this example, you could instead [delete the resource group](https://learn.microsoft.com/en-us/azure/azure-resource-manager/management/delete-resource-group)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e2c873",
   "metadata": {},
   "outputs": [],
   "source": [
    "if should_cleanup:\n",
    "    # {{TODO: Add resource cleanup}}\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
