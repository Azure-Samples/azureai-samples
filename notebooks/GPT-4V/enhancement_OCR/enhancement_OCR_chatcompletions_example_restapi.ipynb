{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "759f9ec0",
   "metadata": {},
   "source": [
    "# REST API OCR Enhanchment Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb770f62",
   "metadata": {},
   "source": [
    "## Objective\n",
    "Incorporating Optical Character Recognition (OCR) with image inputs in GPT-4V.\t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbddd5a",
   "metadata": {},
   "source": [
    "## Time\n",
    "\n",
    "You should expect to spend 5-10 minutes running this sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6607b239",
   "metadata": {},
   "source": [
    "## Before you begin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef48ab3",
   "metadata": {},
   "source": [
    "#### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef92231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97be382f",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "You need to set a series of configurations such as GPT-4V_DEPLOYMENT_NAME, OPENAI_API_BASE, OPENAI_API_VERSION, VISION_API_ENDPOINT in _config.json_ file.\n",
    "\n",
    "```js\n",
    "{\n",
    "    \"GPT-4V_DEPLOYMENT_NAME\":\"<GPT-4V Deployment Name>\",\n",
    "    \"OPENAI_API_BASE\":\"https://<Your Azure Resource Name>.openai.azure.com\",\n",
    "    \"OPENAI_API_VERSION\":\"<OpenAI API Version>\",\n",
    "\n",
    "    \"VISION_API_ENDPOINT\": \"https://<Your Azure Vision Resource Name>.cognitiveservices.azure.com\"    \n",
    "}\n",
    "```\n",
    "Add \"OPENAI_API_KEY\" and \"VISION_API_KEY\" as variable name and \\<Your API Key Value\\> and \\<Your VISION Key Value\\> as variable value in the environment variables.\n",
    " <br>\n",
    "      \n",
    "      WINDOWS Users: \n",
    "         setx OPENAI_API_KEY \"REPLACE_WITH_YOUR_KEY_VALUE_HERE\"\n",
    "         setx VISION_API_KEY \"REPLACE_WITH_YOUR_KEY_VALUE_HERE\"\n",
    "\n",
    "      MACOS/LINUX Users: \n",
    "         export OPENAI_API_KEY=\"REPLACE_WITH_YOUR_KEY_VALUE_HERE\"\n",
    "         export VISION_API_KEY=\"REPLACE_WITH_YOUR_KEY_VALUE_HERE\"\n",
    "\n",
    "\n",
    "And then you will load the configurations from _config.json_ file to setup vision_api_key, and vision_api_endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fa3ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "import os\n",
    "from IPython.display import Image, display\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "parent_dir = Path(Path.cwd()).parent\n",
    "sys.path.append(str(parent_dir))\n",
    "from shared_functions import call_GPT4V_image\n",
    "\n",
    "should_cleanup: bool = False\n",
    "\n",
    "current_script_dir = Path(parent_dir)\n",
    "\n",
    "# Load config values\n",
    "with Path(current_script_dir / \"config.json\").open() as config_file:\n",
    "    config_details = json.load(config_file)\n",
    "\n",
    "# Setting up the vision resource key\n",
    "vision_api_key = os.getenv(\"VISION_API_KEY\")\n",
    "\n",
    "# The base URL for your vision resource endpoint, e.g. \"https://<your-resource-name>.cognitiveservices.azure.com\"\n",
    "vision_api_endpoint = config_details[\"VISION_API_ENDPOINT\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce2863d",
   "metadata": {},
   "source": [
    "## Run this Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef62557",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file_path = \"TravelAssistant.jpg\"  # Update with your image path\n",
    "sys_message = \"You are an AI assistant that helps people find information.\"\n",
    "user_prompt = \"Based on this flight information board, can you provide specifics for my trip to Zurich?\"\n",
    "\n",
    "# Encode the image in base64\n",
    "with Path(image_file_path).open(\"rb\") as image_file:\n",
    "    encoded_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": sys_message}]},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": user_prompt},  # Prompt for the user\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\"url\": f\"data:image/jpeg;base64,{encoded_image}\"},  # Image to be processed\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "vision_api_config = {\"endpoint\": vision_api_endpoint, \"key\": vision_api_key}\n",
    "\n",
    "try:\n",
    "    response_content = call_GPT4V_image(messages, ocr=True, vision_api=vision_api_config)\n",
    "    display(Image(image_file_path))\n",
    "    print(response_content[\"choices\"][0][\"message\"][\"content\"])  # Print the content of the response\n",
    "except Exception as e:\n",
    "    print(f\"Failed to call GPT-4V API. Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2225ab",
   "metadata": {},
   "source": [
    "## Cleaning up\n",
    "\n",
    "To clean up all Azure ML resources used in this example, you can delete the individual resources you created in this tutorial.\n",
    "\n",
    "If you made a resource group specifically to run this example, you could instead [delete the resource group](https://learn.microsoft.com/en-us/azure/azure-resource-manager/management/delete-resource-group)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4781781a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if should_cleanup:\n",
    "    # {{TODO: Add resource cleanup}}\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
