{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "759f9ec0",
   "metadata": {},
   "source": [
    "<h1 align =\"center\"> REST API RAG Samples</h1>\n",
    "<hr>\n",
    "   \n",
    "# Chat Completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b3d21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import base64\n",
    "from IPython.display import Image, display\n",
    "from pathlib import Path\n",
    "from shared_functions import call_GPT4V_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2d4a0f",
   "metadata": {},
   "source": [
    "### Setup Parameters\n",
    "\n",
    "\n",
    "Here we will load the configurations from _config.json_ file to setup vision_api_key, vision_api_endpoint, search_service_endpoint, search_index_name, and search_query_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd85fb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config values\n",
    "with Path(r\"config.json\").open() as config_file:\n",
    "    config_details = json.load(config_file)\n",
    "\n",
    "# Setting up the vision resource key\n",
    "vision_api_key = os.getenv(\"VISION_API_KEY\")\n",
    "\n",
    "# The base URL for your vision resource endpoint, e.g. \"https://<your-resource-name>.cognitiveservices.azure.com\"\n",
    "vision_api_endpoint = config_details[\"VISION_API_ENDPOINT\"]\n",
    "\n",
    "# Setting up the Azure Search service endpoint.e.g. https://<your search service name>.search.windows.net\n",
    "search_service_endpoint = config_details[\"AZURE_SEARCH_SERVICE_ENDPOINT\"]\n",
    "\n",
    "# Setting up the Azure Search service index\n",
    "search_index_name = config_details[\"AZURE_SEARCH_INDEX_NAME\"]\n",
    "\n",
    "# Setting up the Azure Search service query key\n",
    "search_query_key = os.getenv(\"AZURE_SEARCH_QUERY_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c8ca0b",
   "metadata": {},
   "source": [
    "### Create Azure Search Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd94299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the Azure Search service create the index with image embeddings\n",
    "# https://github.com/Azure/azure-search-vector-samples/blob/main/demo-python/code/azure-search-vector-image-index-creation-python-sample.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efffb3f0",
   "metadata": {},
   "source": [
    "### Call GPT-4V API with Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6165c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System messages and user prompt\n",
    "sys_message = \"You are an AI assistant that helps people find information.\"\n",
    "user_prompt = \"What are the types of the apple(s) shown in this image?\"\n",
    "\n",
    "# Encode the image in base64\n",
    "image_file_path = \"images/test_Gala.jpg\"\n",
    "with Path(image_file_path).open(\"rb\") as image_file:\n",
    "    encoded_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": sys_message}]},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": user_prompt},  # Prompt for the user\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\"url\": f\"data:image/jpeg;base64,{encoded_image}\"},  # Image to be processed\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "in_context_config = {\"endpoint\": search_service_endpoint, \"key\": search_query_key, \"indexName\": search_index_name}\n",
    "\n",
    "vision_api_config = {\"endpoint\": vision_api_endpoint, \"key\": vision_api_key}\n",
    "\n",
    "try:\n",
    "    response_content = call_GPT4V_image(messages, in_context=in_context_config, vision_api=vision_api_config)\n",
    "    display(Image(image_file_path))\n",
    "    print(response_content[\"choices\"][0][\"message\"][\"content\"])  # Print the content of the response\n",
    "except Exception as e:\n",
    "    print(f\"Failed to call GPT-4V API. Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
