{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assistants function calling with Bing Search\n",
    "In this notebook, we'll show how you can use the [Bing Search APIs](https://www.microsoft.com/bing/apis/llm) and [function calling](https://learn.microsoft.com/azure/ai-services/openai/how-to/function-calling?tabs=python) to ground Azure OpenAI models on data from the web. This is a great way to give the model access to up to date data from the web.\n",
    "\n",
    "You'll need to create a [Bing Search resource](https://learn.microsoft.com/en-us/bing/search-apis/bing-web-search/create-bing-search-service-resource) before you begin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time\n",
    "\n",
    "You should expect to spend 10 minutes running this sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before you begin\n",
    "#### Installation\n",
    "The following packages are required to execute this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the packages\\\n",
    "%pip install requests openai~=1.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "Update the following config to include details of your Azure OpenAI and Bing Search resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_endpoint = \"https://<YOUR_RESOURCE_NAME>.openai.azure.com\"\n",
    "api_version = \"2024-02-15-preview\"\n",
    "aoai_api_key = \"<AOAI_RESOURCE_API_KEY>\"\n",
    "deployment_name = \"<DEPLOYMENT_NAME>\"\n",
    "bing_search_subscription_key = \"<BING_SEARCH_SUBSCRIPTION_KEY>\"\n",
    "bing_search_url = \"https://api.bing.microsoft.com/v7.0/search\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function to call the Bing Search APIs\n",
    "To learn more about using the Bing Search APIs with Azure OpenAI, see [Bing Search APIs, with your LLM](https://learn.microsoft.com/bing/search-apis/bing-web-search/use-display-requirements-llm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import time\n",
    "\n",
    "from openai import AzureOpenAI\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "def search(query: str) -> list:\n",
    "    \"\"\"\n",
    "    Perform a bing search against the given query\n",
    "\n",
    "    @param query: Search query\n",
    "    @return: List of search results\n",
    "\n",
    "    \"\"\"\n",
    "    headers = {\"Ocp-Apim-Subscription-Key\": bing_search_subscription_key}\n",
    "    params = {\"q\": query, \"textDecorations\": False}\n",
    "    response = requests.get(bing_search_url, headers=headers, params=params)\n",
    "    response.raise_for_status()\n",
    "    search_results = response.json()\n",
    "\n",
    "    output = []\n",
    "\n",
    "    for result in search_results[\"webPages\"][\"value\"]:\n",
    "        output.append({\"title\": result[\"name\"], \"link\": result[\"url\"], \"snippet\": result[\"snippet\"]})\n",
    "\n",
    "    return json.dumps(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search(\"where will the 2032 olympics be held?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get things running end to end\n",
    "In the following cells, we will define some functions essential for assistants with function calling. All these functions come together in our final cell, where we will define a new web search assistant, give it instructions on its functionality and ask a question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poll_run_till_completion(\n",
    "    client: AzureOpenAI,\n",
    "    thread_id: str,\n",
    "    run_id: str,\n",
    "    available_functions: dict,\n",
    "    verbose: bool,\n",
    "    max_steps: int = 10,\n",
    "    wait: int = 3,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Poll a run until it is completed or failed or exceeds a certain number of iterations (MAX_STEPS)\n",
    "    with a preset wait in between polls\n",
    "\n",
    "    @param client: OpenAI client\n",
    "    @param thread_id: Thread ID\n",
    "    @param run_id: Run ID\n",
    "    @param assistant_id: Assistant ID\n",
    "    @param verbose: Print verbose output\n",
    "    @param max_steps: Maximum number of steps to poll\n",
    "    @param wait: Wait time in seconds between polls\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if (client is None and thread_id is None) or run_id is None:\n",
    "        print(\"Client, Thread ID and Run ID are required.\")\n",
    "        return\n",
    "    try:\n",
    "        cnt = 0\n",
    "        while cnt < max_steps:\n",
    "            run = client.beta.threads.runs.retrieve(thread_id=thread_id, run_id=run_id)\n",
    "            if verbose:\n",
    "                print(\"Poll {}: {}\".format(cnt, run.status))\n",
    "            cnt += 1\n",
    "            if run.status == \"requires_action\":\n",
    "                tool_responses = []\n",
    "                if (\n",
    "                    run.required_action.type == \"submit_tool_outputs\"\n",
    "                    and run.required_action.submit_tool_outputs.tool_calls is not None\n",
    "                ):\n",
    "                    tool_calls = run.required_action.submit_tool_outputs.tool_calls\n",
    "\n",
    "                    for call in tool_calls:\n",
    "                        if call.type == \"function\":\n",
    "                            if call.function.name not in available_functions:\n",
    "                                raise Exception(\"Function requested by the model does not exist\")\n",
    "                            function_to_call = available_functions[call.function.name]\n",
    "                            tool_response = function_to_call(**json.loads(call.function.arguments))\n",
    "                            tool_responses.append({\"tool_call_id\": call.id, \"output\": tool_response})\n",
    "\n",
    "                run = client.beta.threads.runs.submit_tool_outputs(\n",
    "                    thread_id=thread_id, run_id=run.id, tool_outputs=tool_responses\n",
    "                )\n",
    "            if run.status == \"failed\":\n",
    "                print(\"Run failed.\")\n",
    "                break\n",
    "            if run.status == \"completed\":\n",
    "                break\n",
    "            time.sleep(wait)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_message(\n",
    "    client: AzureOpenAI,\n",
    "    thread_id: str,\n",
    "    role: str = \"\",\n",
    "    content: str = \"\",\n",
    "    file_ids: Optional[list] = None,\n",
    "    metadata: Optional[dict] = None,\n",
    "    message_id: Optional[str] = None,\n",
    ") -> any:\n",
    "    \"\"\"\n",
    "    Create a message in a thread using the client.\n",
    "\n",
    "    @param client: OpenAI client\n",
    "    @param thread_id: Thread ID\n",
    "    @param role: Message role (user or assistant)\n",
    "    @param content: Message content\n",
    "    @param file_ids: Message file IDs\n",
    "    @param metadata: Message metadata\n",
    "    @param message_id: Message ID\n",
    "    @return: Message object\n",
    "\n",
    "    \"\"\"\n",
    "    if metadata is None:\n",
    "        metadata = {}\n",
    "    if file_ids is None:\n",
    "        file_ids = []\n",
    "\n",
    "    if client is None:\n",
    "        print(\"Client parameter is required.\")\n",
    "        return None\n",
    "\n",
    "    if thread_id is None:\n",
    "        print(\"Thread ID is required.\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        if message_id is not None:\n",
    "            return client.beta.threads.messages.retrieve(thread_id=thread_id, message_id=message_id)\n",
    "\n",
    "        if file_ids is not None and len(file_ids) > 0 and metadata is not None and len(metadata) > 0:\n",
    "            return client.beta.threads.messages.create(\n",
    "                thread_id=thread_id, role=role, content=content, file_ids=file_ids, metadata=metadata\n",
    "            )\n",
    "\n",
    "        if file_ids is not None and len(file_ids) > 0:\n",
    "            return client.beta.threads.messages.create(\n",
    "                thread_id=thread_id, role=role, content=content, file_ids=file_ids\n",
    "            )\n",
    "\n",
    "        if metadata is not None and len(metadata) > 0:\n",
    "            return client.beta.threads.messages.create(\n",
    "                thread_id=thread_id, role=role, content=content, metadata=metadata\n",
    "            )\n",
    "\n",
    "        return client.beta.threads.messages.create(thread_id=thread_id, role=role, content=content)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_and_print_messages(\n",
    "    client: AzureOpenAI, thread_id: str, verbose: bool, out_dir: Optional[str] = None\n",
    ") -> any:\n",
    "    \"\"\"\n",
    "    Retrieve a list of messages in a thread and print it out with the query and response\n",
    "\n",
    "    @param client: OpenAI client\n",
    "    @param thread_id: Thread ID\n",
    "    @param verbose: Print verbose output\n",
    "    @param out_dir: Output directory to save images\n",
    "    @return: Messages object\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if client is None and thread_id is None:\n",
    "        print(\"Client and Thread ID are required.\")\n",
    "        return None\n",
    "    try:\n",
    "        messages = client.beta.threads.messages.list(thread_id=thread_id)\n",
    "        display_role = {\"user\": \"User query\", \"assistant\": \"Assistant response\"}\n",
    "\n",
    "        prev_role = None\n",
    "\n",
    "        if verbose:\n",
    "            print(\"\\n\\nCONVERSATION:\")\n",
    "        for md in reversed(messages.data):\n",
    "            if prev_role == \"assistant\" and md.role == \"user\" and verbose:\n",
    "                print(\"------ \\n\")\n",
    "\n",
    "            for mc in md.content:\n",
    "                # Check if valid text field is present in the mc object\n",
    "                if mc.type == \"text\":\n",
    "                    txt_val = mc.text.value\n",
    "                # Check if valid image field is present in the mc object\n",
    "                elif mc.type == \"image_file\":\n",
    "                    image_data = client.files.content(mc.image_file.file_id)\n",
    "                    if out_dir is not None:\n",
    "                        out_dir_path = Path(out_dir)\n",
    "                        if out_dir_path.exists():\n",
    "                            image_path = out_dir_path / (mc.image_file.file_id + \".png\")\n",
    "                            with image_path.open(\"wb\") as f:\n",
    "                                f.write(image_data.read())\n",
    "\n",
    "                if verbose:\n",
    "                    if prev_role == md.role:\n",
    "                        print(txt_val)\n",
    "                    else:\n",
    "                        print(\"{}:\\n{}\".format(display_role[md.role], txt_val))\n",
    "            prev_role = md.role\n",
    "        return messages\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"websearch-assistant\"\n",
    "instructions = \"\"\"You are an assistant designed to help people answer questions.\n",
    "\n",
    "You have access to query the web using Bing Search. You should call bing search whenever a question requires up to date information or could benefit from web data.\n",
    "\"\"\"\n",
    "\n",
    "message = {\"role\": \"user\", \"content\": \"How tall is mount rainier?\"}\n",
    "\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"search_bing\",\n",
    "            \"description\": \"Searches bing to get up-to-date information from the web.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The search query\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"query\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "available_functions = {\"search_bing\": search}\n",
    "verbose_output = True\n",
    "\n",
    "client = AzureOpenAI(api_key=aoai_api_key, api_version=api_version, azure_endpoint=azure_endpoint)\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "    name=name, description=\"\", instructions=instructions, tools=tools, model=deployment_name\n",
    ")\n",
    "\n",
    "thread = client.beta.threads.create()\n",
    "create_message(client, thread.id, message[\"role\"], message[\"content\"])\n",
    "\n",
    "\n",
    "run = client.beta.threads.runs.create(thread_id=thread.id, assistant_id=assistant.id, instructions=instructions)\n",
    "poll_run_till_completion(\n",
    "    client=client, thread_id=thread.id, run_id=run.id, available_functions=available_functions, verbose=verbose_output\n",
    ")\n",
    "messages = retrieve_and_print_messages(client=client, thread_id=thread.id, verbose=verbose_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
